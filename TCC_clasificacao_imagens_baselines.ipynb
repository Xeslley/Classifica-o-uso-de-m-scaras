{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T04:05:31.125571Z",
     "start_time": "2020-09-19T04:05:29.698106Z"
    }
   },
   "outputs": [],
   "source": [
    "import skimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carrega a base e divide em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T04:05:31.135975Z",
     "start_time": "2020-09-19T04:05:31.125571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\FIA\\TCC\\BASES\\\n"
     ]
    }
   ],
   "source": [
    "inicioGeral = time.time()\n",
    "bases_prontas_path = os.path.join(\"D:\\\\\",\"FIA\",\"TCC\",\"BASES\",\"\")\n",
    "print(bases_prontas_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T04:05:33.031855Z",
     "start_time": "2020-09-19T04:05:31.137971Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(bases_prontas_path+'mask_dataset_vgg16_preprocess_input_224_224_3_feature_extracted.csv')\n",
    "X, y = df.drop(['im_path', 'class'], axis=1), df['class'].values\n",
    "\n",
    "label_transformer = preprocessing.LabelEncoder()\n",
    "label_transformer.fit(y)\n",
    "y = label_transformer.transform(y)\n",
    "\n",
    "#print(list(y))\n",
    "\n",
    "trainX , testX, trainY, testY  = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T04:05:33.058446Z",
     "start_time": "2020-09-19T04:05:33.031855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5436, 512)\n",
      "(5436,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>media precision</th>\n",
       "      <th>media recall</th>\n",
       "      <th>media f1-score</th>\n",
       "      <th>media ponderada precision</th>\n",
       "      <th>media ponderada recall</th>\n",
       "      <th>media ponderada f1-score</th>\n",
       "      <th>tempo fit</th>\n",
       "      <th>tempo predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, accuracy, media precision, media recall, media f1-score, media ponderada precision, media ponderada recall, media ponderada f1-score, tempo fit, tempo predict]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_metricas_modelos = pd.DataFrame(data={\"model\":list(),\n",
    "                                                \"accuracy\":list(),\n",
    "                                                \"media precision\":list(),\n",
    "                                                \"media recall\":list(),\n",
    "                                                \"media f1-score\":list(),\n",
    "                                                \"media ponderada precision\":list(),\n",
    "                                                \"media ponderada recall\":list(),\n",
    "                                                \"media ponderada f1-score\":list(),\n",
    "                                                \"tempo fit\":list(),\n",
    "                                                \"tempo predict\":list()})\n",
    "\n",
    "print(testX.shape)\n",
    "print(testY.shape) \n",
    "print(type(dataframe_metricas_modelos))\n",
    "dataframe_metricas_modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação dos Modelos\n",
    "\n",
    "[classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T04:05:33.079371Z",
     "start_time": "2020-09-19T04:05:33.060417Z"
    }
   },
   "outputs": [],
   "source": [
    "def avalia_lista_modelos(lista_modelos,lista_tempos,testX, testY):\n",
    "    zip_modelo_tempo = list(zip(lista_modelos,lista_tempos))\n",
    "    tabela_metricas_modelos = {\"model\":list(),\n",
    "                               \"accuracy\":list(),\n",
    "                               \"media precision\":list(),\n",
    "                               \"media recall\":list(),\n",
    "                               \"media f1-score\":list(),\n",
    "                               \"media ponderada precision\":list(),\n",
    "                               \"media ponderada recall\":list(),\n",
    "                               \"media ponderada f1-score\":list(),\n",
    "                               \"tempo fit\":list(),\n",
    "                               \"tempo predict\":list()}\n",
    "#     print(f\"Lista de modelos = {list(lista_modelos)}\")\n",
    "    contador_para_nome_do_modelo = 1\n",
    "    for model, tempo in zip_modelo_tempo:\n",
    "#         print(f\"Iniciando modelo {str(type(model))}\")\n",
    "        try:\n",
    "            nome_modelo = f\"{str(type(model)).split('.')[3][:-2]} {contador_para_nome_do_modelo}\"\n",
    "        except:\n",
    "            nome_modelo = f\"{str(type(model)).split('.')[2][:-2]} {contador_para_nome_do_modelo}\"\n",
    "        contador_para_nome_do_modelo+=1\n",
    "        try:\n",
    "            #Se tiver dado algum problema na hora de treinar_modelos, então tempo vai ser zero\n",
    "            if tempo == 0:\n",
    "                raise Exception(\"Propagando erro no treinamento!!\")\n",
    "            teste, tempo_predict = Avaliando_modelo(model, nome_modelo, None, testX, testY)\n",
    "            tabela_metricas_modelos[\"model\"].append(nome_modelo[:-2])\n",
    "            tabela_metricas_modelos[\"accuracy\"].append(teste[\"accuracy\"])\n",
    "            tabela_metricas_modelos[\"media precision\"].append(teste[\"macro avg\"][\"precision\"])\n",
    "            tabela_metricas_modelos[\"media recall\"].append(teste[\"macro avg\"][\"recall\"])\n",
    "            tabela_metricas_modelos[\"media f1-score\"].append(teste[\"macro avg\"][\"f1-score\"])\n",
    "            tabela_metricas_modelos[\"media ponderada precision\"].append(teste[\"weighted avg\"][\"precision\"])\n",
    "            tabela_metricas_modelos[\"media ponderada recall\"].append(teste[\"weighted avg\"][\"recall\"])\n",
    "            tabela_metricas_modelos[\"media ponderada f1-score\"].append(teste[\"weighted avg\"][\"f1-score\"])\n",
    "            tabela_metricas_modelos[\"tempo fit\"].append(tempo)\n",
    "            tabela_metricas_modelos[\"tempo predict\"].append(tempo_predict)\n",
    "            print(f\"accuracy = {teste['accuracy']} e predict demorou {round(tempo_predict,2)} segundos \\n\")\n",
    "            \n",
    "        except:\n",
    "            tabela_metricas_modelos[\"model\"].append(nome_modelo)\n",
    "            tabela_metricas_modelos[\"accuracy\"].append(np.nan)\n",
    "            tabela_metricas_modelos[\"media precision\"].append(np.nan)\n",
    "            tabela_metricas_modelos[\"media recall\"].append(np.nan)\n",
    "            tabela_metricas_modelos[\"media f1-score\"].append(np.nan)\n",
    "            tabela_metricas_modelos[\"media ponderada precision\"].append(np.nan)\n",
    "            tabela_metricas_modelos[\"media ponderada recall\"].append(np.nan)\n",
    "            tabela_metricas_modelos[\"media ponderada f1-score\"].append(np.nan)\n",
    "            tabela_metricas_modelos[\"tempo fit\"].append(np.nan)\n",
    "            tabela_metricas_modelos[\"tempo predict\"].append(np.nan)\n",
    "            \n",
    "#         print(f\"Finalizando modelo {str(type(model))}\")\n",
    "#     print(f\"qtd de modelos = {len(list(tabela_metricas_modelos['model']))}\\n{tabela_metricas_modelos}\")\n",
    "    dataframe_metricas = pd.DataFrame(data=tabela_metricas_modelos, index = [ind+1 for ind in range(len(list(tabela_metricas_modelos['model'])))])\n",
    "    return dataframe_metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T04:05:33.095353Z",
     "start_time": "2020-09-19T04:05:33.081358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. \\n                        Use `zero_division` parameter to control this behavior.\\nEste aviso acima acontece porque o modelo esperava prever 3 classes e acabou prevendo somente 2 classes. \\nNa tabela vai aparecer a metrica 0, porem este alerta é anunciado. Para resolver isso é só colocar o parametro \\nzero_division=0 dentro do método classification_report.\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = label_transformer.classes_ # [\"without_mask\",\"mask_weared_incorrect\",\"with_mask\"]\n",
    "def Avaliando_modelo(model, nome_modelo, NWHead = None,x_test=testX, y_test=testY):\n",
    "    print(f\"Avaliando modelo {nome_modelo} ....\")\n",
    "    tempo_predict =None\n",
    "    try:\n",
    "        inicio = time.time()\n",
    "        predIdxs = model.predict(x_test, batch_size=32)\n",
    "        fim = time.time()\n",
    "        tempo_predict = fim-inicio\n",
    "    except:\n",
    "        inicio = time.time()\n",
    "        predIdxs = model.predict(x_test)\n",
    "        fim = time.time()\n",
    "        tempo_predict = fim-inicio\n",
    "    # for each image in the testing set we need to find the index of the\n",
    "    # label with corresponding largest predicted probability\n",
    "#     print(f\"predIdxs = {type(predIdxs)} {predIdxs.dtype} shape = {predIdxs.shape}\")\n",
    "#     print(f\"y_test = {type(y_test)} {y_test.dtype} shape = {y_test.shape}\")\n",
    "    #predIdxs = np.argmax(predIdxs, axis=1)\n",
    "    #y_test = np.argmax(y_test,axis=1)\n",
    "    \n",
    "#     try:\n",
    "#         print(f\"parametros = {model.get_params()}\")\n",
    "#     except:\n",
    "#         pass\n",
    "    # show a nicely formatted classification report\n",
    "    classification_report_val = classification_report(y_test,\n",
    "                                                      predIdxs,\n",
    "                                                      target_names=lb,\n",
    "                                                      zero_division=0,\n",
    "                                                      output_dict=True)\n",
    "#     print(classification_report_val)\n",
    "\n",
    "    # serialize the model to disk\n",
    "#     print(\"[INFO] saving mask detector model...\")\n",
    "\n",
    "    if NWHead:\n",
    "        # plot the training loss and accuracy\n",
    "        N = EPOCHS\n",
    "        plt.style.use(\"ggplot\")\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(0, N), NWHead.history[\"loss\"], label=\"train_loss\")\n",
    "        plt.plot(np.arange(0, N), NWHead.history[\"val_loss\"], label=\"val_loss\")\n",
    "        plt.plot(np.arange(0, N), NWHead.history[\"accuracy\"], label=\"train_acc\")\n",
    "        plt.plot(np.arange(0, N), NWHead.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "        plt.title(\"Training Loss and Accuracy\")\n",
    "        plt.xlabel(\"Epoch #\")\n",
    "        plt.ylabel(\"Loss/Accuracy\")\n",
    "        plt.legend(loc=\"lower left\")\n",
    "        plt.show()\n",
    "    return classification_report_val, tempo_predict\n",
    "\n",
    "\"\"\"\n",
    "UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. \n",
    "                        Use `zero_division` parameter to control this behavior.\n",
    "Este aviso acima acontece porque o modelo esperava prever 3 classes e acabou prevendo somente 2 classes. \n",
    "Na tabela vai aparecer a metrica 0, porem este alerta é anunciado. Para resolver isso é só colocar o parametro \n",
    "zero_division=0 dentro do método classification_report.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T04:05:33.106292Z",
     "start_time": "2020-09-19T04:05:33.097317Z"
    }
   },
   "outputs": [],
   "source": [
    "# def treinar_modelos(lista_modelos,lista_tempos):\n",
    "def treinar_modelos(lista_modelos):\n",
    "    lista_tempos = list(range(len(lista_modelos)))\n",
    "    for i in range(len(lista_modelos)):\n",
    "        try:\n",
    "            nome_modelo = f\"{str(type(lista_modelos[i])).split('.')[3][:-2]} {i+1}\"\n",
    "        except:\n",
    "            nome_modelo = f\"{str(type(lista_modelos[i])).split('.')[2][:-2]} {i+1}\"\n",
    "        \n",
    "        print(f\"treinando {nome_modelo} . . . \")\n",
    "        inicio = time.time()\n",
    "        try:\n",
    "            aux = lista_modelos[i]\n",
    "            lista_modelos[i] = lista_modelos[i].fit(trainX, trainY)\n",
    "            fim = time.time()\n",
    "            lista_tempos[i] = fim-inicio\n",
    "            if lista_tempos[i] <60:\n",
    "                print(f\"demorou {round(lista_tempos[i],2)} segundos \\n\")#\\ninicio = {inicio}\\nfim = {fim}\\n\")\n",
    "            else:\n",
    "                print(f\"demorou {round(lista_tempos[i]/60,2)} minutos \\n\")#\\ninicio = {inicio}\\nfim = {fim}\\n\")\n",
    "                \n",
    "        except:\n",
    "            print(f\"Falha ao treinar {nome_modelo} . . . \")\n",
    "            lista_tempos[i] = 0\n",
    "        \n",
    "            \n",
    "    print(\"done!! :)\")\n",
    "    return lista_modelos,lista_tempos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T04:05:33.162173Z",
     "start_time": "2020-09-19T04:05:33.109285Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Documentação LinearSVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC)\n",
    "\n",
    "#### [Documentação SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T04:05:33.171121Z",
     "start_time": "2020-09-19T04:05:33.164139Z"
    }
   },
   "outputs": [],
   "source": [
    "# models_svm = (#svm.SVC(kernel='linear',cache_size=10000,decision_function_shape='ovo',max_iter=10000),\n",
    "#               svm.LinearSVC(max_iter=10000, verbose=1),\n",
    "# #               svm.SVC(kernel='rbf', gamma=0.7,cache_size=10000,decision_function_shape='ovo',max_iter=10000),\n",
    "#               svm.SVC(kernel='poly', degree=3, gamma='auto',cache_size=10000,decision_function_shape='ovo',max_iter=1000, verbose=True),\n",
    "# #               svm.SVC(C=1000, kernel='linear',cache_size=10000,decision_function_shape='ovo',max_iter=10000),\n",
    "#               svm.LinearSVC(C=1000, max_iter=10000, verbose=1),\n",
    "# #               svm.SVC(C=1000, kernel='rbf', gamma=0.7,cache_size=10000,decision_function_shape='ovo',max_iter=1000),\n",
    "#               svm.SVC(C=1000, kernel='poly', degree=3, gamma='auto',cache_size=10000,decision_function_shape='ovo',max_iter=1000, verbose=True)\n",
    "#              )\n",
    "# #C=1 não rodou, decision_function_shape 'ovr' tbm não, cache_size 200 tbm não\n",
    "# svm1 = svm.SVC(C=1, kernel='linear',cache_size=10000,decision_function_shape='ovo',max_iter=1000), \n",
    "# # testar com max_iter para não entrar em loop\n",
    "\n",
    "# #LinearSVC == ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
    "# #outros não rodaram, ficaram rodando infinito\n",
    "\n",
    "svm1 = svm.LinearSVC(max_iter=4000)\n",
    "svm2 = svm.SVC(kernel='poly', \n",
    "               degree=3, \n",
    "               gamma='auto',\n",
    "               cache_size=10000,\n",
    "               decision_function_shape='ovo',\n",
    "               max_iter=4000)\n",
    "svm3 = svm.LinearSVC(C=1000, \n",
    "                     max_iter=4000)\n",
    "svm4 = svm.SVC(C=1000, \n",
    "               kernel='poly', \n",
    "               degree=3, \n",
    "               gamma='auto',\n",
    "               cache_size=10000,\n",
    "               decision_function_shape='ovo',\n",
    "               max_iter=4000)\n",
    "\n",
    "svm5 = svm.SVC(C=1000, \n",
    "               cache_size=10000, \n",
    "               decision_function_shape='ovo', \n",
    "               kernel='poly',\n",
    "               max_iter=1000, \n",
    "               random_state=42, \n",
    "               tol=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T04:12:55.689059Z",
     "start_time": "2020-09-19T04:05:33.173114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treinando LinearSVC 1 . . . \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demorou 1.51 minutos \n",
      "\n",
      "treinando SVC 2 . . . \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=4000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demorou 1.84 minutos \n",
      "\n",
      "treinando LinearSVC 3 . . . \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demorou 1.52 minutos \n",
      "\n",
      "treinando SVC 4 . . . \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=4000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demorou 1.84 minutos \n",
      "\n",
      "treinando SVC 5 . . . \n",
      "demorou 39.85 segundos \n",
      "\n",
      "done!! :)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "models_svm_fit = [svm1,\n",
    "                  svm2,\n",
    "                  svm3,\n",
    "                  svm4,\n",
    "                  svm5]\n",
    "\n",
    "models_svm_fit, models_svm_fit_time = treinar_modelos(models_svm_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T04:13:30.685907Z",
     "start_time": "2020-09-19T04:12:55.691053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliando modelo LinearSVC 1 ....\n",
      "accuracy = 0.7910228108903605 e predict demorou 0.03 segundos \n",
      "\n",
      "Avaliando modelo SVC 2 ....\n",
      "accuracy = 0.8281824871228844 e predict demorou 12.59 segundos \n",
      "\n",
      "Avaliando modelo LinearSVC 3 ....\n",
      "accuracy = 0.7141280353200883 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo SVC 4 ....\n",
      "accuracy = 0.8281824871228844 e predict demorou 12.66 segundos \n",
      "\n",
      "Avaliando modelo SVC 5 ....\n",
      "accuracy = 0.7356512141280354 e predict demorou 9.64 segundos \n",
      "\n",
      "tempo para rodar toda a planilha é aproximadamente 442.0 segundos\n"
     ]
    }
   ],
   "source": [
    "dataframe_metricas_modelos = pd.concat([dataframe_metricas_modelos, \n",
    "                                        avalia_lista_modelos(models_svm_fit,\n",
    "                                                             models_svm_fit_time,\n",
    "                                                             testX, \n",
    "                                                             testY)], \n",
    "                                        axis=0)\n",
    "# dataframe_metricas_modelos.dropna().reset_index(drop=False)\n",
    "tempo_para_rodar = dataframe_metricas_modelos[\"tempo fit\"].sum()\n",
    "print(f\"tempo para rodar toda a planilha é aproximadamente {round(tempo_para_rodar)} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T04:13:30.690892Z",
     "start_time": "2020-09-19T04:13:30.687901Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Documentação SGDClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T04:13:30.713832Z",
     "start_time": "2020-09-19T04:13:30.692887Z"
    }
   },
   "outputs": [],
   "source": [
    "sgd_clf1 = SGDClassifier(random_state=42, max_iter=10000, tol=1e-3, loss=\"hinge\", penalty = \"l2\")\n",
    "sgd_clf2 = SGDClassifier(random_state=42, max_iter=10000, tol=1e-3, loss=\"log\", penalty = \"l2\")\n",
    "sgd_clf3 = SGDClassifier(random_state=42, max_iter=10000, tol=1e-3, loss=\"modified_huber\", penalty = \"l2\")\n",
    "sgd_clf4 = SGDClassifier(random_state=42, max_iter=10000, tol=1e-3, loss=\"squared_hinge\", penalty = \"l2\")\n",
    "sgd_clf5 = SGDClassifier(random_state=42, max_iter=10000, tol=1e-3, loss=\"perceptron\", penalty = \"l2\")\n",
    "\n",
    "sgd_clf6 = SGDClassifier(random_state=42, max_iter=1000, tol=1e-3, loss=\"hinge\", penalty = \"l1\")\n",
    "sgd_clf7 = SGDClassifier(random_state=42, max_iter=1000, tol=1e-3, loss=\"log\", penalty = \"l1\")\n",
    "sgd_clf8 = SGDClassifier(random_state=42, max_iter=1000, tol=1e-3, loss=\"modified_huber\", penalty = \"l1\")\n",
    "sgd_clf9 = SGDClassifier(random_state=42, max_iter=1000, tol=1e-3, loss=\"squared_hinge\", penalty = \"l1\")\n",
    "sgd_clf10 = SGDClassifier(random_state=42, max_iter=1000, tol=1e-3, loss=\"perceptron\", penalty = \"l1\")\n",
    "\n",
    "sgd_clf11 = SGDClassifier(random_state=42, max_iter=10000, tol=1e-3, loss=\"hinge\", penalty = \"elasticnet\")\n",
    "sgd_clf12 = SGDClassifier(random_state=42, max_iter=10000, tol=1e-3, loss=\"log\", penalty = \"elasticnet\")\n",
    "sgd_clf13 = SGDClassifier(random_state=42, max_iter=10000, tol=1e-3, loss=\"modified_huber\", penalty = \"elasticnet\")\n",
    "sgd_clf14 = SGDClassifier(random_state=42, max_iter=10000, tol=1e-3, loss=\"squared_hinge\", penalty = \"elasticnet\")\n",
    "sgd_clf15 = SGDClassifier(random_state=42, max_iter=10000, tol=1e-3, loss=\"perceptron\", penalty = \"elasticnet\")\n",
    "\n",
    "sgd_clf16 = SGDClassifier(alpha=0.31622776601683794, max_iter=100, random_state=42,tol=0.0001, loss=\"hinge\", penalty = \"l2\")\n",
    "sgd_clf17 = SGDClassifier(alpha=0.0005298316906283707, max_iter=100, random_state=42,tol=0.0001, loss=\"squared_hinge\", penalty = \"elasticnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T04:20:48.124677Z",
     "start_time": "2020-09-19T04:13:30.715826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treinando SGDClassifier 1 . . . \n",
      "demorou 8.1 segundos \n",
      "\n",
      "treinando SGDClassifier 2 . . . \n",
      "demorou 7.16 segundos \n",
      "\n",
      "treinando SGDClassifier 3 . . . \n",
      "demorou 6.06 segundos \n",
      "\n",
      "treinando SGDClassifier 4 . . . \n",
      "demorou 6.01 segundos \n",
      "\n",
      "treinando SGDClassifier 5 . . . \n",
      "demorou 6.69 segundos \n",
      "\n",
      "treinando SGDClassifier 6 . . . \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:573: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demorou 59.31 segundos \n",
      "\n",
      "treinando SGDClassifier 7 . . . \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:573: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demorou 58.24 segundos \n",
      "\n",
      "treinando SGDClassifier 8 . . . \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:573: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demorou 54.31 segundos \n",
      "\n",
      "treinando SGDClassifier 9 . . . \n",
      "demorou 57.38 segundos \n",
      "\n",
      "treinando SGDClassifier 10 . . . \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:573: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demorou 59.23 segundos \n",
      "\n",
      "treinando SGDClassifier 11 . . . \n",
      "demorou 21.5 segundos \n",
      "\n",
      "treinando SGDClassifier 12 . . . \n",
      "demorou 17.03 segundos \n",
      "\n",
      "treinando SGDClassifier 13 . . . \n",
      "demorou 22.51 segundos \n",
      "\n",
      "treinando SGDClassifier 14 . . . \n",
      "demorou 18.49 segundos \n",
      "\n",
      "treinando SGDClassifier 15 . . . \n",
      "demorou 20.43 segundos \n",
      "\n",
      "treinando SGDClassifier 16 . . . \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:573: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demorou 4.03 segundos \n",
      "\n",
      "treinando SGDClassifier 17 . . . \n",
      "demorou 10.93 segundos \n",
      "\n",
      "done!! :)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:573: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "models_SGD_fit = [sgd_clf1\n",
    "                  ,sgd_clf2\n",
    "                  ,sgd_clf3\n",
    "                  ,sgd_clf4\n",
    "                  ,sgd_clf5\n",
    "                  ,sgd_clf6\n",
    "                  ,sgd_clf7\n",
    "                  ,sgd_clf8\n",
    "                  ,sgd_clf9\n",
    "                  ,sgd_clf10\n",
    "                  ,sgd_clf11\n",
    "                  ,sgd_clf12\n",
    "                  ,sgd_clf13\n",
    "                  ,sgd_clf14\n",
    "                  ,sgd_clf15\n",
    "                  ,sgd_clf16\n",
    "                  ,sgd_clf17]\n",
    "\n",
    "models_SGD_fit, models_SGD_fit_time = treinar_modelos(models_SGD_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T04:20:48.518949Z",
     "start_time": "2020-09-19T04:20:48.126673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliando modelo SGDClassifier 1 ....\n",
      "accuracy = 0.8211920529801324 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo SGDClassifier 2 ....\n",
      "accuracy = 0.7763061074319353 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo SGDClassifier 3 ....\n",
      "accuracy = 0.7454010301692421 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo SGDClassifier 4 ....\n",
      "accuracy = 0.7844002943340692 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo SGDClassifier 5 ....\n",
      "accuracy = 0.7888153053715967 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo SGDClassifier 6 ....\n",
      "accuracy = 0.8083149374540103 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo SGDClassifier 7 ....\n",
      "accuracy = 0.8040838852097131 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo SGDClassifier 8 ....\n",
      "accuracy = 0.8112582781456954 e predict demorou 0.0 segundos \n",
      "\n",
      "Avaliando modelo SGDClassifier 9 ....\n",
      "accuracy = 0.8145695364238411 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo SGDClassifier 10 ....\n",
      "accuracy = 0.7798013245033113 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo SGDClassifier 11 ....\n",
      "accuracy = 0.8232155997056659 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo SGDClassifier 12 ....\n",
      "accuracy = 0.8169610007358352 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo SGDClassifier 13 ....\n",
      "accuracy = 0.8289183222958058 e predict demorou 0.03 segundos \n",
      "\n",
      "Avaliando modelo SGDClassifier 14 ....\n",
      "accuracy = 0.8278145695364238 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo SGDClassifier 15 ....\n",
      "accuracy = 0.7404341427520236 e predict demorou 0.03 segundos \n",
      "\n",
      "Avaliando modelo SGDClassifier 16 ....\n",
      "accuracy = 0.8360927152317881 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo SGDClassifier 17 ....\n",
      "accuracy = 0.8143855776306107 e predict demorou 0.01 segundos \n",
      "\n",
      "tempo para rodar toda a planilha é aproximadamente 437.0 segundos\n"
     ]
    }
   ],
   "source": [
    "dataframe_metricas_modelos = pd.concat([dataframe_metricas_modelos, \n",
    "                                        avalia_lista_modelos(models_SGD_fit, \n",
    "                                                             models_SGD_fit_time,\n",
    "                                                             testX, \n",
    "                                                             testY)], \n",
    "                                       axis=0)\n",
    "# dataframe_metricas_modelos.tail(len(models_SGD_fit)).dropna().reset_index(drop=False)\n",
    "tempo_para_rodar = dataframe_metricas_modelos.tail(len(models_SGD_fit))[\"tempo fit\"].sum()\n",
    "print(f\"tempo para rodar toda a planilha é aproximadamente {round(tempo_para_rodar)} segundos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T04:20:48.574799Z",
     "start_time": "2020-09-19T04:20:48.520944Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Documentação](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T04:20:48.584780Z",
     "start_time": "2020-09-19T04:20:48.576794Z"
    }
   },
   "outputs": [],
   "source": [
    "decision_tree1 = DecisionTreeClassifier(random_state=42, max_depth=2500, criterion = \"gini\", max_features = None)\n",
    "decision_tree2 = DecisionTreeClassifier(random_state=42, max_depth=2500, criterion = \"gini\", max_features = \"sqrt\")\n",
    "decision_tree3 = DecisionTreeClassifier(random_state=42, max_depth=2500, criterion = \"gini\", max_features = \"log2\")\n",
    "\n",
    "decision_tree4 = DecisionTreeClassifier(random_state=42, max_depth=2500, criterion = \"entropy\", max_features = None)\n",
    "decision_tree5 = DecisionTreeClassifier(random_state=42, max_depth=2500, criterion = \"entropy\", max_features = \"sqrt\")\n",
    "decision_tree6 = DecisionTreeClassifier(random_state=42, max_depth=2500, criterion = \"entropy\", max_features = \"log2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T04:21:11.383609Z",
     "start_time": "2020-09-19T04:20:48.586766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treinando DecisionTreeClassifier 1 . . . \n",
      "demorou 10.83 segundos \n",
      "\n",
      "treinando DecisionTreeClassifier 2 . . . \n",
      "demorou 0.43 segundos \n",
      "\n",
      "treinando DecisionTreeClassifier 3 . . . \n",
      "demorou 0.17 segundos \n",
      "\n",
      "treinando DecisionTreeClassifier 4 . . . \n",
      "demorou 10.55 segundos \n",
      "\n",
      "treinando DecisionTreeClassifier 5 . . . \n",
      "demorou 0.54 segundos \n",
      "\n",
      "treinando DecisionTreeClassifier 6 . . . \n",
      "demorou 0.26 segundos \n",
      "\n",
      "done!! :)\n"
     ]
    }
   ],
   "source": [
    "models_decision_tree_fit = [decision_tree1,\n",
    "                            decision_tree2,\n",
    "                            decision_tree3,\n",
    "                            decision_tree4,\n",
    "                            decision_tree5,\n",
    "                            decision_tree6]\n",
    "\n",
    "models_decision_tree_fit, models_decision_tree_fit_time = treinar_modelos(models_decision_tree_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T04:21:11.546540Z",
     "start_time": "2020-09-19T04:21:11.385605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliando modelo DecisionTreeClassifier 1 ....\n",
      "accuracy = 0.7218543046357616 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo DecisionTreeClassifier 2 ....\n",
      "accuracy = 0.6872700515084621 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo DecisionTreeClassifier 3 ....\n",
      "accuracy = 0.6574687270051508 e predict demorou 0.0 segundos \n",
      "\n",
      "Avaliando modelo DecisionTreeClassifier 4 ....\n",
      "accuracy = 0.7196467991169978 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo DecisionTreeClassifier 5 ....\n",
      "accuracy = 0.6903973509933775 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo DecisionTreeClassifier 6 ....\n",
      "accuracy = 0.6624356144223694 e predict demorou 0.02 segundos \n",
      "\n",
      "tempo para rodar toda a planilha é aproximadamente 23.0 segundos\n"
     ]
    }
   ],
   "source": [
    "dataframe_metricas_modelos = pd.concat([dataframe_metricas_modelos, \n",
    "                                        avalia_lista_modelos(models_decision_tree_fit, \n",
    "                                                             models_decision_tree_fit_time,\n",
    "                                                             testX, \n",
    "                                                             testY)], \n",
    "                                       axis=0)\n",
    "# dataframe_metricas_modelos.tail(len(models_decision_tree_fit)).dropna().reset_index(drop=False)\n",
    "tempo_para_rodar = dataframe_metricas_modelos.tail(len(models_decision_tree_fit))[\"tempo fit\"].sum()\n",
    "print(f\"tempo para rodar toda a planilha é aproximadamente {round(tempo_para_rodar)} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T04:21:11.554533Z",
     "start_time": "2020-09-19T04:21:11.548536Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, ComplementNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Documentação GaussianNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB)\n",
    "\n",
    "#### [Documentação ComplementNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.ComplementNB.html#sklearn.naive_bayes.ComplementNB)\n",
    "\n",
    "#### [Documentação MultinomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T04:21:11.563495Z",
     "start_time": "2020-09-19T04:21:11.556513Z"
    }
   },
   "outputs": [],
   "source": [
    "models_NB1 = GaussianNB()\n",
    "models_NB2 = MultinomialNB(fit_prior = True)\n",
    "models_NB3 = ComplementNB(fit_prior = True)\n",
    "models_NB4 = MultinomialNB(fit_prior = False)\n",
    "models_NB5 = ComplementNB(fit_prior = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T04:21:11.895230Z",
     "start_time": "2020-09-19T04:21:11.565490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treinando GaussianNB 1 . . . \n",
      "demorou 0.21 segundos \n",
      "\n",
      "treinando MultinomialNB 2 . . . \n",
      "demorou 0.01 segundos \n",
      "\n",
      "treinando ComplementNB 3 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando MultinomialNB 4 . . . \n",
      "demorou 0.04 segundos \n",
      "\n",
      "treinando ComplementNB 5 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "done!! :)\n"
     ]
    }
   ],
   "source": [
    "models_NB_fit = [models_NB1,\n",
    "                 models_NB2,\n",
    "                 models_NB3,\n",
    "                 models_NB4,\n",
    "                 models_NB5]\n",
    "\n",
    "\n",
    "models_NB_fit, models_NB_fit_time = treinar_modelos(models_NB_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T04:21:12.143736Z",
     "start_time": "2020-09-19T04:21:11.898223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliando modelo GaussianNB 1 ....\n",
      "accuracy = 0.6547093451066961 e predict demorou 0.15 segundos \n",
      "\n",
      "Avaliando modelo MultinomialNB 2 ....\n",
      "accuracy = 0.655813097866078 e predict demorou 0.0 segundos \n",
      "\n",
      "Avaliando modelo ComplementNB 3 ....\n",
      "accuracy = 0.6714495952906548 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo MultinomialNB 4 ....\n",
      "accuracy = 0.655813097866078 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo ComplementNB 5 ....\n",
      "accuracy = 0.6714495952906548 e predict demorou 0.01 segundos \n",
      "\n",
      "tempo para rodar toda a planilha é aproximadamente 0.0 segundos\n"
     ]
    }
   ],
   "source": [
    "dataframe_metricas_modelos = pd.concat([dataframe_metricas_modelos,\n",
    "                                        avalia_lista_modelos(models_NB_fit, \n",
    "                                                             models_NB_fit_time,\n",
    "                                                             testX, \n",
    "                                                             testY)], \n",
    "                                       axis=0)\n",
    "# dataframe_metricas_modelos.tail(len(models_NB_fit)).dropna().reset_index(drop=False)\n",
    "tempo_para_rodar = dataframe_metricas_modelos.tail(len(models_NB_fit))[\"tempo fit\"].sum()\n",
    "print(f\"tempo para rodar toda a planilha é aproximadamente {round(tempo_para_rodar)} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-nearest neighbors algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T04:21:12.149719Z",
     "start_time": "2020-09-19T04:21:12.145730Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import DistanceMetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Documentação RadiusNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.RadiusNeighborsClassifier.html#sklearn.neighbors.RadiusNeighborsClassifier)\n",
    "\n",
    "#### [Documentação KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T12:56:09.984273Z",
     "start_time": "2020-09-19T12:55:39.341822Z"
    }
   },
   "outputs": [],
   "source": [
    "KNN1 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"ball_tree\", p= 1)\n",
    "KNN2 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"ball_tree\", p= 1)\n",
    "\n",
    "KNN3 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"kd_tree\", p= 1)\n",
    "KNN4 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"kd_tree\", p= 1)\n",
    "\n",
    "KNN5 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"brute\", p= 1)\n",
    "KNN6 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"brute\", p= 1)\n",
    "\n",
    "KNN7 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"ball_tree\", p= 2)\n",
    "KNN8 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"ball_tree\", p= 2)\n",
    "\n",
    "KNN9 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"kd_tree\", p= 2)\n",
    "KNN10 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"kd_tree\", p= 2)\n",
    "\n",
    "KNN11 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"brute\", p= 2)\n",
    "KNN12 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"brute\", p= 2)\n",
    "\n",
    "\n",
    "KNN13 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"ball_tree\", p= 1, metric = \"euclidean\")\n",
    "KNN14 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"ball_tree\", p= 1, metric = \"euclidean\")\n",
    "\n",
    "KNN15 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"kd_tree\", p= 1, metric = \"euclidean\")\n",
    "KNN16 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"kd_tree\", p= 1, metric = \"euclidean\")\n",
    "\n",
    "KNN17 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"brute\", p= 1, metric = \"euclidean\")\n",
    "KNN18 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"brute\", p= 1, metric = \"euclidean\")\n",
    "\n",
    "KNN19 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"ball_tree\", p= 2, metric = \"euclidean\")\n",
    "KNN20 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"ball_tree\", p= 2, metric = \"euclidean\")\n",
    "\n",
    "KNN21 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"kd_tree\", p= 2, metric = \"euclidean\")\n",
    "KNN22 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"kd_tree\", p= 2, metric = \"euclidean\")\n",
    "\n",
    "KNN23 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"brute\", p= 2, metric = \"euclidean\")\n",
    "KNN24 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"brute\", p= 2, metric = \"euclidean\")\n",
    "\n",
    "\n",
    "KNN25 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"ball_tree\", p= 1, metric = \"manhattan\")\n",
    "KNN26 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"ball_tree\", p= 1, metric = \"manhattan\")\n",
    "\n",
    "KNN27 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"kd_tree\", p= 1, metric = \"manhattan\")\n",
    "KNN28 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"kd_tree\", p= 1, metric = \"manhattan\")\n",
    "\n",
    "KNN29 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"brute\", p= 1, metric = \"manhattan\")\n",
    "KNN30 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"brute\", p= 1, metric = \"manhattan\")\n",
    "\n",
    "KNN31 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"ball_tree\", p= 2, metric = \"manhattan\")\n",
    "KNN32 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"ball_tree\", p= 2, metric = \"manhattan\")\n",
    "\n",
    "KNN33 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"kd_tree\", p= 2, metric = \"manhattan\")\n",
    "KNN34 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"kd_tree\", p= 2, metric = \"manhattan\")\n",
    "\n",
    "KNN35 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"brute\", p= 2, metric = \"manhattan\")\n",
    "KNN36 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"brute\", p= 2, metric = \"manhattan\")\n",
    "\n",
    "\n",
    "KNN37 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"ball_tree\", p= 1, metric = \"chebyshev\")\n",
    "KNN38 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"ball_tree\", p= 1, metric = \"chebyshev\")\n",
    "\n",
    "KNN39 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"kd_tree\", p= 1, metric = \"chebyshev\")\n",
    "KNN40 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"kd_tree\", p= 1, metric = \"chebyshev\")\n",
    "\n",
    "KNN41 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"brute\", p= 1, metric = \"chebyshev\")\n",
    "KNN42 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"brute\", p= 1, metric = \"chebyshev\")\n",
    "\n",
    "KNN43 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"ball_tree\", p= 2, metric = \"chebyshev\")\n",
    "KNN44 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"ball_tree\", p= 2, metric = \"chebyshev\")\n",
    "\n",
    "KNN45 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"kd_tree\", p= 2, metric = \"chebyshev\")\n",
    "KNN46 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"kd_tree\", p= 2, metric = \"chebyshev\")\n",
    "\n",
    "KNN47 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"brute\", p= 2, metric = \"chebyshev\")\n",
    "KNN48 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"brute\", p= 2, metric = \"chebyshev\")\n",
    "\n",
    "\n",
    "KNN49 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"ball_tree\", p= 1, metric = \"mahalanobis\", metric_params={'V': np.cov(trainX)})\n",
    "KNN50 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"ball_tree\", p= 1, metric = \"mahalanobis\", metric_params={'V': np.cov(trainX)})\n",
    "\n",
    "KNN51 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"brute\", p= 1, metric = \"mahalanobis\", metric_params={'V': np.cov(trainX)})\n",
    "KNN52 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"brute\", p= 1, metric = \"mahalanobis\", metric_params={'V': np.cov(trainX)})\n",
    "\n",
    "KNN53 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"ball_tree\", p= 2, metric = \"mahalanobis\", metric_params={'V': np.cov(trainX)})\n",
    "KNN54 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"ball_tree\", p= 2, metric = \"mahalanobis\", metric_params={'V': np.cov(trainX)})\n",
    "\n",
    "KNN55 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"brute\", p= 2, metric = \"mahalanobis\", metric_params={'V': np.cov(trainX)})\n",
    "KNN56 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"brute\", p= 2, metric = \"mahalanobis\", metric_params={'V': np.cov(trainX)})\n",
    "\n",
    "\n",
    "dist = lambda x,y: DistanceMetric.get_metric('Wminkowski').pairwise(x,y,2)\n",
    "\n",
    "KNN57 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"ball_tree\", p= 1, metric = dist)\n",
    "KNN58 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"ball_tree\", p= 1, metric = dist)\n",
    "\n",
    "KNN59 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"brute\", p= 1, metric = dist)\n",
    "KNN60 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"brute\", p= 1, metric = dist)\n",
    "\n",
    "KNN61 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"ball_tree\", p= 2, metric = dist)\n",
    "KNN62 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"ball_tree\", p= 2, metric = dist)\n",
    "\n",
    "KNN63 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"brute\", p= 2, metric = dist)\n",
    "KNN64 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"brute\", p= 2, metric = dist)\n",
    "\n",
    "\n",
    "KNN65 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"ball_tree\", p= 1, metric = \"cityblock\")\n",
    "KNN66 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"ball_tree\", p= 1, metric = \"cityblock\")\n",
    "\n",
    "KNN67 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"kd_tree\", p= 1, metric = \"cityblock\")\n",
    "KNN68 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"kd_tree\", p= 1, metric = \"cityblock\")\n",
    "\n",
    "KNN69 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"brute\", p= 1, metric = \"cityblock\")\n",
    "KNN70 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"brute\", p= 1, metric = \"cityblock\")\n",
    "\n",
    "KNN71 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"ball_tree\", p= 2, metric = \"cityblock\")\n",
    "KNN72 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"ball_tree\", p= 2, metric = \"cityblock\")\n",
    "\n",
    "KNN73 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"kd_tree\", p= 2, metric = \"cityblock\")\n",
    "KNN74 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"kd_tree\", p= 2, metric = \"cityblock\")\n",
    "\n",
    "KNN75 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"brute\", p= 2, metric = \"cityblock\")\n",
    "KNN76 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"brute\", p= 2, metric = \"cityblock\")\n",
    "\n",
    "\n",
    "\n",
    "KNN77 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"ball_tree\", p= 1, metric = \"canberra\")\n",
    "KNN78 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"ball_tree\", p= 1, metric = \"canberra\")\n",
    "\n",
    "KNN79 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"brute\", p= 1, metric = \"canberra\")\n",
    "KNN80 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"brute\", p= 1, metric = \"canberra\")\n",
    "\n",
    "KNN81 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"ball_tree\", p= 2, metric = \"canberra\")\n",
    "KNN82 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"ball_tree\", p= 2, metric = \"canberra\")\n",
    "\n",
    "KNN83 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"brute\", p= 2, metric = \"canberra\")\n",
    "KNN84 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"brute\", p= 2, metric = \"canberra\")\n",
    "\n",
    "\n",
    "\n",
    "KNN85 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"ball_tree\", p= 1, metric = \"braycurtis\")\n",
    "KNN86 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"ball_tree\", p= 1, metric = \"braycurtis\")\n",
    "\n",
    "KNN87 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"brute\", p= 1, metric = \"braycurtis\")\n",
    "KNN88 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"brute\", p= 1, metric = \"braycurtis\")\n",
    "\n",
    "KNN89 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"ball_tree\", p= 2, metric = \"braycurtis\")\n",
    "KNN90 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"ball_tree\", p= 2, metric = \"braycurtis\")\n",
    "\n",
    "KNN91 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"brute\", p= 2, metric = \"braycurtis\")\n",
    "KNN92 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"brute\", p= 2, metric = \"braycurtis\")\n",
    "\n",
    "KNN93 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"ball_tree\", p= 1, metric = \"hamming\")\n",
    "KNN94 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"ball_tree\", p= 1, metric = \"hamming\")\n",
    "\n",
    "KNN95 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"brute\", p= 1, metric = \"hamming\")\n",
    "KNN96 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"brute\", p= 1, metric = \"hamming\")\n",
    "\n",
    "KNN97 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"ball_tree\", p= 2, metric = \"hamming\")\n",
    "KNN98 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"ball_tree\", p= 2, metric = \"hamming\")\n",
    "\n",
    "KNN99 = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\", algorithm= \"brute\", p= 2, metric = \"hamming\")\n",
    "KNN100 = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm= \"brute\", p= 2, metric = \"hamming\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T13:00:51.122193Z",
     "start_time": "2020-09-19T12:56:09.984273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treinando KNeighborsClassifier 1 . . . \n",
      "demorou 2.59 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 2 . . . \n",
      "demorou 2.65 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 3 . . . \n",
      "demorou 3.54 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 4 . . . \n",
      "demorou 3.6 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 5 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 6 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 7 . . . \n",
      "demorou 2.62 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 8 . . . \n",
      "demorou 2.56 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 9 . . . \n",
      "demorou 3.6 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 10 . . . \n",
      "demorou 3.63 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 11 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 12 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 13 . . . \n",
      "demorou 2.55 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 14 . . . \n",
      "demorou 2.65 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 15 . . . \n",
      "demorou 3.54 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 16 . . . \n",
      "demorou 3.67 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 17 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 18 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 19 . . . \n",
      "demorou 2.67 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 20 . . . \n",
      "demorou 2.58 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 21 . . . \n",
      "demorou 3.61 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 22 . . . \n",
      "demorou 3.63 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 23 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 24 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 25 . . . \n",
      "demorou 2.55 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 26 . . . \n",
      "demorou 2.62 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 27 . . . \n",
      "demorou 3.56 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 28 . . . \n",
      "demorou 3.57 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 29 . . . \n",
      "demorou 0.04 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 30 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 31 . . . \n",
      "demorou 2.63 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 32 . . . \n",
      "demorou 2.55 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 33 . . . \n",
      "demorou 3.61 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 34 . . . \n",
      "demorou 3.62 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 35 . . . \n",
      "demorou 0.04 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 36 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 37 . . . \n",
      "demorou 2.63 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 38 . . . \n",
      "demorou 2.65 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 39 . . . \n",
      "demorou 3.52 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 40 . . . \n",
      "demorou 3.6 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 41 . . . \n",
      "demorou 0.04 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 42 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 43 . . . \n",
      "demorou 2.63 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 44 . . . \n",
      "demorou 2.52 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 45 . . . \n",
      "demorou 3.63 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 46 . . . \n",
      "demorou 3.63 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 47 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 48 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 49 . . . \n",
      "Falha ao treinar KNeighborsClassifier 49 . . . \n",
      "treinando KNeighborsClassifier 50 . . . \n",
      "Falha ao treinar KNeighborsClassifier 50 . . . \n",
      "treinando KNeighborsClassifier 51 . . . \n",
      "demorou 0.02 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 52 . . . \n",
      "demorou 0.02 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 53 . . . \n",
      "Falha ao treinar KNeighborsClassifier 53 . . . \n",
      "treinando KNeighborsClassifier 54 . . . \n",
      "Falha ao treinar KNeighborsClassifier 54 . . . \n",
      "treinando KNeighborsClassifier 55 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 56 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 57 . . . \n",
      "Falha ao treinar KNeighborsClassifier 57 . . . \n",
      "treinando KNeighborsClassifier 58 . . . \n",
      "Falha ao treinar KNeighborsClassifier 58 . . . \n",
      "treinando KNeighborsClassifier 59 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 60 . . . \n",
      "demorou 0.02 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 61 . . . \n",
      "Falha ao treinar KNeighborsClassifier 61 . . . \n",
      "treinando KNeighborsClassifier 62 . . . \n",
      "Falha ao treinar KNeighborsClassifier 62 . . . \n",
      "treinando KNeighborsClassifier 63 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 64 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 65 . . . \n",
      "demorou 2.54 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 66 . . . \n",
      "demorou 2.62 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 67 . . . \n",
      "demorou 3.72 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 68 . . . \n",
      "demorou 3.64 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 69 . . . \n",
      "demorou 0.04 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 70 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 71 . . . \n",
      "demorou 2.66 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 72 . . . \n",
      "demorou 2.55 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 73 . . . \n",
      "demorou 3.65 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 74 . . . \n",
      "demorou 3.6 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 75 . . . \n",
      "demorou 0.04 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 76 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 77 . . . \n",
      "demorou 2.58 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 78 . . . \n",
      "demorou 2.64 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 79 . . . \n",
      "demorou 0.04 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 80 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 81 . . . \n",
      "demorou 2.52 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 82 . . . \n",
      "demorou 2.72 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 83 . . . \n",
      "demorou 0.04 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 84 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 85 . . . \n",
      "demorou 2.74 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 86 . . . \n",
      "demorou 2.66 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 87 . . . \n",
      "demorou 0.04 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 88 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 89 . . . \n",
      "demorou 2.54 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 90 . . . \n",
      "demorou 2.65 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 91 . . . \n",
      "demorou 0.04 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 92 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 93 . . . \n",
      "demorou 2.5 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 94 . . . \n",
      "demorou 2.61 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 95 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 96 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 97 . . . \n",
      "demorou 2.51 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 98 . . . \n",
      "demorou 2.62 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 99 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "treinando KNeighborsClassifier 100 . . . \n",
      "demorou 0.03 segundos \n",
      "\n",
      "done!! :)\n"
     ]
    }
   ],
   "source": [
    "models_KNN_fit =[KNN1,\n",
    "                 KNN2,\n",
    "                 KNN3,\n",
    "                 KNN4,\n",
    "                 KNN5,\n",
    "                 KNN6,\n",
    "                 KNN7,\n",
    "                 KNN8,\n",
    "                 KNN9,\n",
    "                 KNN10,\n",
    "                 KNN11,\n",
    "                 KNN12,\n",
    "                 KNN13,\n",
    "                 KNN14,\n",
    "                 KNN15,\n",
    "                 KNN16,\n",
    "                 KNN17,\n",
    "                 KNN18,\n",
    "                 KNN19,\n",
    "                 KNN20,\n",
    "                 KNN21,\n",
    "                 KNN22,\n",
    "                 KNN23,\n",
    "                 KNN24,\n",
    "                 KNN25,\n",
    "                 KNN26,\n",
    "                 KNN27,\n",
    "                 KNN28,\n",
    "                 KNN29,\n",
    "                 KNN30,\n",
    "                 KNN31,\n",
    "                 KNN32,\n",
    "                 KNN33,\n",
    "                 KNN34,\n",
    "                 KNN35,\n",
    "                 KNN36,\n",
    "                 KNN37,\n",
    "                 KNN38,\n",
    "                 KNN39,\n",
    "                 KNN40,\n",
    "                 KNN41,\n",
    "                 KNN42,\n",
    "                 KNN43,\n",
    "                 KNN44,\n",
    "                 KNN45,\n",
    "                 KNN46,\n",
    "                 KNN47,\n",
    "                 KNN48,\n",
    "                 KNN49,\n",
    "                 KNN50,\n",
    "                 KNN51,\n",
    "                 KNN52,\n",
    "                 KNN53,\n",
    "                 KNN54,\n",
    "                 KNN55,\n",
    "                 KNN56,\n",
    "                 KNN57,\n",
    "                 KNN58,\n",
    "                 KNN59,\n",
    "                 KNN60,\n",
    "                 KNN61,\n",
    "                 KNN62,\n",
    "                 KNN63,\n",
    "                 KNN64,\n",
    "                 KNN65,\n",
    "                 KNN66,\n",
    "                 KNN67,\n",
    "                 KNN68,\n",
    "                 KNN69,\n",
    "                 KNN70,\n",
    "                 KNN71,\n",
    "                 KNN72,\n",
    "                 KNN73,\n",
    "                 KNN74,\n",
    "                 KNN75,\n",
    "                 KNN76,\n",
    "                 KNN77,\n",
    "                 KNN78,\n",
    "                 KNN79,\n",
    "                 KNN80,\n",
    "                 KNN81,\n",
    "                 KNN82,\n",
    "                 KNN83,\n",
    "                 KNN84,\n",
    "                 KNN85,\n",
    "                 KNN86,\n",
    "                 KNN87,\n",
    "                 KNN88,\n",
    "                 KNN89,\n",
    "                 KNN90,\n",
    "                 KNN91,\n",
    "                 KNN92,\n",
    "                 KNN93,\n",
    "                 KNN94,\n",
    "                 KNN95,\n",
    "                 KNN96,\n",
    "                 KNN97,\n",
    "                 KNN98,\n",
    "                 KNN99,\n",
    "                 KNN100]#,\n",
    "#                  KNN101,\n",
    "#                  KNN102,\n",
    "#                  KNN103,\n",
    "#                  KNN104,\n",
    "#                  KNN105,\n",
    "#                  KNN106,\n",
    "#                  KNN107,\n",
    "#                  KNN108,\n",
    "#                  KNN109,\n",
    "#                  KNN110,\n",
    "#                  KNN111,\n",
    "#                  KNN112,\n",
    "#                  KNN113,\n",
    "#                  KNN114,\n",
    "#                  KNN115,\n",
    "#                  KNN116,\n",
    "#                  KNN117,\n",
    "#                  KNN118,\n",
    "#                  KNN119,\n",
    "#                  KNN120,\n",
    "#                  KNN121,\n",
    "#                  KNN122,\n",
    "#                  KNN123,\n",
    "#                  KNN124,\n",
    "#                  KNN125,\n",
    "#                  KNN126,\n",
    "#                  KNN127,\n",
    "#                  KNN128,\n",
    "#                  KNN129,\n",
    "#                  KNN130,\n",
    "#                  KNN131,\n",
    "#                  KNN132]\n",
    "\n",
    "\n",
    "models_KNN_fit, models_KNN_fit_time = treinar_modelos(models_KNN_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T17:38:16.514210Z",
     "start_time": "2020-09-19T13:00:51.124061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliando modelo KNeighborsClassifier 1 ....\n",
      "accuracy = 0.858167770419426 e predict demorou 58.04 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 2 ....\n",
      "accuracy = 0.8655261221486387 e predict demorou 57.52 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 3 ....\n",
      "accuracy = 0.858167770419426 e predict demorou 68.76 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 4 ....\n",
      "accuracy = 0.8655261221486387 e predict demorou 68.46 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 5 ....\n",
      "accuracy = 0.858167770419426 e predict demorou 51.07 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 6 ....\n",
      "accuracy = 0.8655261221486387 e predict demorou 50.99 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 7 ....\n",
      "accuracy = 0.8568800588668138 e predict demorou 59.49 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 8 ....\n",
      "accuracy = 0.8657100809418691 e predict demorou 59.15 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 9 ....\n",
      "accuracy = 0.8568800588668138 e predict demorou 81.48 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 10 ....\n",
      "accuracy = 0.8657100809418691 e predict demorou 81.69 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 11 ....\n",
      "accuracy = 0.8568800588668138 e predict demorou 2.15 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 12 ....\n",
      "accuracy = 0.8657100809418691 e predict demorou 1.94 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 13 ....\n",
      "accuracy = 0.8568800588668138 e predict demorou 59.36 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 14 ....\n",
      "accuracy = 0.8657100809418691 e predict demorou 59.31 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 15 ....\n",
      "accuracy = 0.8568800588668138 e predict demorou 81.71 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 16 ....\n",
      "accuracy = 0.8657100809418691 e predict demorou 81.44 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 17 ....\n",
      "accuracy = 0.8568800588668138 e predict demorou 2.16 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 18 ....\n",
      "accuracy = 0.8657100809418691 e predict demorou 2.03 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 19 ....\n",
      "accuracy = 0.8568800588668138 e predict demorou 59.34 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 20 ....\n",
      "accuracy = 0.8657100809418691 e predict demorou 59.3 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 21 ....\n",
      "accuracy = 0.8568800588668138 e predict demorou 82.15 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 22 ....\n",
      "accuracy = 0.8657100809418691 e predict demorou 81.5 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 23 ....\n",
      "accuracy = 0.8568800588668138 e predict demorou 2.01 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 24 ....\n",
      "accuracy = 0.8657100809418691 e predict demorou 2.18 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 25 ....\n",
      "accuracy = 0.858167770419426 e predict demorou 57.55 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 26 ....\n",
      "accuracy = 0.8655261221486387 e predict demorou 57.61 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 27 ....\n",
      "accuracy = 0.858167770419426 e predict demorou 68.5 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 28 ....\n",
      "accuracy = 0.8655261221486387 e predict demorou 68.65 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 29 ....\n",
      "accuracy = 0.858167770419426 e predict demorou 51.0 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 30 ....\n",
      "accuracy = 0.8655261221486387 e predict demorou 50.81 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 31 ....\n",
      "accuracy = 0.858167770419426 e predict demorou 57.62 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 32 ....\n",
      "accuracy = 0.8655261221486387 e predict demorou 57.53 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 33 ....\n",
      "accuracy = 0.858167770419426 e predict demorou 68.3 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 34 ....\n",
      "accuracy = 0.8655261221486387 e predict demorou 68.35 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 35 ....\n",
      "accuracy = 0.858167770419426 e predict demorou 51.46 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 36 ....\n",
      "accuracy = 0.8655261221486387 e predict demorou 50.94 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 37 ....\n",
      "accuracy = 0.7954378219278881 e predict demorou 46.81 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 38 ....\n",
      "accuracy = 0.8048197203826343 e predict demorou 46.66 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 39 ....\n",
      "accuracy = 0.7954378219278881 e predict demorou 23.13 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 40 ....\n",
      "accuracy = 0.804635761589404 e predict demorou 22.97 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 41 ....\n",
      "accuracy = 0.7948859455481972 e predict demorou 51.13 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 42 ....\n",
      "accuracy = 0.8037159676232524 e predict demorou 50.92 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 43 ....\n",
      "accuracy = 0.7954378219278881 e predict demorou 46.75 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 44 ....\n",
      "accuracy = 0.8048197203826343 e predict demorou 46.44 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 45 ....\n",
      "accuracy = 0.7954378219278881 e predict demorou 23.04 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 46 ....\n",
      "accuracy = 0.804635761589404 e predict demorou 22.91 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 47 ....\n",
      "accuracy = 0.7948859455481972 e predict demorou 51.1 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 48 ....\n",
      "accuracy = 0.8037159676232524 e predict demorou 50.86 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 51 ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1462: FutureWarning: from version 0.25, pairwise_distances for metric='mahalanobis' will require VI to be specified if Y is passed.\n",
      "  \"specified if Y is passed.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.4300956585724798 e predict demorou 24618.47 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 52 ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1462: FutureWarning: from version 0.25, pairwise_distances for metric='mahalanobis' will require VI to be specified if Y is passed.\n",
      "  \"specified if Y is passed.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.43414275202354674 e predict demorou 24385.11 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 55 ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1462: FutureWarning: from version 0.25, pairwise_distances for metric='mahalanobis' will require VI to be specified if Y is passed.\n",
      "  \"specified if Y is passed.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.4300956585724798 e predict demorou 24424.86 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 56 ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1462: FutureWarning: from version 0.25, pairwise_distances for metric='mahalanobis' will require VI to be specified if Y is passed.\n",
      "  \"specified if Y is passed.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.43414275202354674 e predict demorou 24443.65 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 59 ....\n",
      "Avaliando modelo KNeighborsClassifier 60 ....\n",
      "Avaliando modelo KNeighborsClassifier 63 ....\n",
      "Avaliando modelo KNeighborsClassifier 64 ....\n",
      "Avaliando modelo KNeighborsClassifier 65 ....\n",
      "accuracy = 0.858167770419426 e predict demorou 57.76 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 66 ....\n",
      "accuracy = 0.8655261221486387 e predict demorou 57.81 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 67 ....\n",
      "accuracy = 0.858167770419426 e predict demorou 68.54 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 68 ....\n",
      "accuracy = 0.8655261221486387 e predict demorou 68.35 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 69 ....\n",
      "accuracy = 0.858167770419426 e predict demorou 51.16 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 70 ....\n",
      "accuracy = 0.8655261221486387 e predict demorou 51.08 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 71 ....\n",
      "accuracy = 0.858167770419426 e predict demorou 58.17 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 72 ....\n",
      "accuracy = 0.8655261221486387 e predict demorou 57.54 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 73 ....\n",
      "accuracy = 0.858167770419426 e predict demorou 68.31 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 74 ....\n",
      "accuracy = 0.8655261221486387 e predict demorou 68.26 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 75 ....\n",
      "accuracy = 0.858167770419426 e predict demorou 51.06 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 76 ....\n",
      "accuracy = 0.8655261221486387 e predict demorou 51.05 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 77 ....\n",
      "accuracy = 0.8530169242089772 e predict demorou 108.85 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 78 ....\n",
      "accuracy = 0.8612950699043415 e predict demorou 108.71 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 79 ....\n",
      "accuracy = 0.8530169242089772 e predict demorou 100.37 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 80 ....\n",
      "accuracy = 0.8612950699043415 e predict demorou 100.13 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 81 ....\n",
      "accuracy = 0.8530169242089772 e predict demorou 108.85 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 82 ....\n",
      "accuracy = 0.8612950699043415 e predict demorou 108.35 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 83 ....\n",
      "accuracy = 0.8530169242089772 e predict demorou 100.13 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 84 ....\n",
      "accuracy = 0.8612950699043415 e predict demorou 99.98 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 85 ....\n",
      "accuracy = 0.8708609271523179 e predict demorou 59.12 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 86 ....\n",
      "accuracy = 0.8787711552612215 e predict demorou 59.13 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 87 ....\n",
      "accuracy = 0.8708609271523179 e predict demorou 52.92 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 88 ....\n",
      "accuracy = 0.8787711552612215 e predict demorou 52.93 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 89 ....\n",
      "accuracy = 0.8708609271523179 e predict demorou 59.32 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 90 ....\n",
      "accuracy = 0.8787711552612215 e predict demorou 59.32 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 91 ....\n",
      "accuracy = 0.8708609271523179 e predict demorou 53.16 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 92 ....\n",
      "accuracy = 0.8787711552612215 e predict demorou 52.74 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 93 ....\n",
      "accuracy = 0.41740250183958794 e predict demorou 92.97 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 94 ....\n",
      "accuracy = 0.41832229580573954 e predict demorou 92.91 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 95 ....\n",
      "accuracy = 0.42108167770419425 e predict demorou 101.05 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 96 ....\n",
      "accuracy = 0.4214495952906549 e predict demorou 101.89 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 97 ....\n",
      "accuracy = 0.41740250183958794 e predict demorou 93.31 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 98 ....\n",
      "accuracy = 0.41832229580573954 e predict demorou 92.68 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 99 ....\n",
      "accuracy = 0.42108167770419425 e predict demorou 100.15 segundos \n",
      "\n",
      "Avaliando modelo KNeighborsClassifier 100 ....\n",
      "accuracy = 0.4214495952906549 e predict demorou 100.08 segundos \n",
      "\n",
      "tempo para rodar toda a planilha é aproximadamente 157.0 segundos\n"
     ]
    }
   ],
   "source": [
    "dataframe_metricas_modelos = pd.concat([dataframe_metricas_modelos,\n",
    "                                        avalia_lista_modelos(models_KNN_fit, \n",
    "                                                             models_KNN_fit_time,\n",
    "                                                             testX, \n",
    "                                                             testY)], \n",
    "                                       axis=0)\n",
    "# dataframe_metricas_modelos.tail(len(models_KNN_fit)).dropna().reset_index(drop=False)\n",
    "tempo_para_rodar = dataframe_metricas_modelos.tail(len(models_KNN_fit))[\"tempo fit\"].sum()\n",
    "print(f\"tempo para rodar toda a planilha é aproximadamente {round(tempo_para_rodar)} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T17:38:16.523183Z",
     "start_time": "2020-09-20T17:38:16.517201Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Documentação](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T17:38:16.566078Z",
     "start_time": "2020-09-20T17:38:16.526176Z"
    }
   },
   "outputs": [],
   "source": [
    "RegLog1 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"newton-cg\", penalty= \"l2\", C= 1)\n",
    "RegLog2 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"lbfgs\", penalty= \"l2\", C= 1)\n",
    "RegLog3 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"liblinear\", penalty= \"l2\", C= 1)\n",
    "RegLog4 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"sag\", penalty= \"l2\", C= 1)\n",
    "RegLog5 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"saga\", penalty= \"l2\", C= 1)\n",
    "\n",
    "RegLog6 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"newton-cg\", penalty= \"l1\", C= 1)\n",
    "RegLog7 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"lbfgs\", penalty= \"l1\", C= 1)\n",
    "RegLog8 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"liblinear\", penalty= \"l1\", C= 1)\n",
    "RegLog9 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"sag\", penalty= \"l1\", C= 1)\n",
    "RegLog10 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"saga\", penalty= \"l1\", C= 1)\n",
    "\n",
    "RegLog11 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"newton-cg\", penalty= \"elasticnet\", C= 1)\n",
    "RegLog12 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"lbfgs\", penalty= \"elasticnet\", C= 1)\n",
    "RegLog13 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"liblinear\", penalty= \"elasticnet\", C= 1)\n",
    "RegLog14 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"sag\", penalty= \"elasticnet\", C= 1)\n",
    "RegLog15 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"saga\", penalty= \"elasticnet\", C= 1)\n",
    "\n",
    "RegLog16 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"newton-cg\", penalty= \"none\", C= 1)\n",
    "RegLog17 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"lbfgs\", penalty= \"none\", C= 1)\n",
    "RegLog18 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"liblinear\", penalty= \"none\", C= 1)\n",
    "RegLog19 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"sag\", penalty= \"none\", C= 1)\n",
    "RegLog20 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"saga\", penalty= \"none\", C= 1)\n",
    "\n",
    "\n",
    "\n",
    "RegLog21 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"newton-cg\", penalty= \"l2\", C= 100)\n",
    "RegLog22 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"lbfgs\", penalty= \"l2\", C= 100)\n",
    "RegLog23 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"liblinear\", penalty= \"l2\", C= 100)\n",
    "RegLog24 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"sag\", penalty= \"l2\", C= 100)\n",
    "RegLog25 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"saga\", penalty= \"l2\", C= 100)\n",
    "\n",
    "RegLog26 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"newton-cg\", penalty= \"l1\", C= 100)\n",
    "RegLog27 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"lbfgs\", penalty= \"l1\", C= 100)\n",
    "RegLog28 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"liblinear\", penalty= \"l1\", C= 100)\n",
    "RegLog29 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"sag\", penalty= \"l1\", C= 100)\n",
    "RegLog30 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"saga\", penalty= \"l1\", C= 100)\n",
    "\n",
    "RegLog31 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"newton-cg\", penalty= \"elasticnet\", C= 100)\n",
    "RegLog32 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"lbfgs\", penalty= \"elasticnet\", C= 100)\n",
    "RegLog33 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"liblinear\", penalty= \"elasticnet\", C= 100)\n",
    "RegLog34 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"sag\", penalty= \"elasticnet\", C= 100)\n",
    "RegLog35 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"saga\", penalty= \"elasticnet\", C= 100)\n",
    "\n",
    "RegLog36 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"newton-cg\", penalty= \"none\", C= 100)\n",
    "RegLog37 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"lbfgs\", penalty= \"none\", C= 100)\n",
    "RegLog38 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"liblinear\", penalty= \"none\", C= 100)\n",
    "RegLog39 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"sag\", penalty= \"none\", C= 100)\n",
    "RegLog40 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"saga\", penalty= \"none\", C= 100)\n",
    "\n",
    "RegLog41 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"liblinear\", penalty= \"l1\", C= 1, class_weight = \"balanced\")\n",
    "RegLog42 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"liblinear\", penalty= \"l2\", C= 1, class_weight = \"balanced\")\n",
    "\n",
    "RegLog43 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"liblinear\", penalty= \"l1\", C= 200, class_weight = \"balanced\")\n",
    "RegLog44 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"liblinear\", penalty= \"l2\", C= 200, class_weight = \"balanced\")\n",
    "\n",
    "RegLog45 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"liblinear\", penalty= \"l1\", C= 200, class_weight = None)\n",
    "RegLog46 = LogisticRegression(random_state=0, max_iter = 1000, solver = \"liblinear\", penalty= \"l2\", C= 200, class_weight = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T17:48:25.594098Z",
     "start_time": "2020-09-20T17:38:16.569060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treinando LogisticRegression 1 . . . \n",
      "demorou 15.51 segundos \n",
      "\n",
      "treinando LogisticRegression 2 . . . \n",
      "demorou 12.31 segundos \n",
      "\n",
      "treinando LogisticRegression 3 . . . \n",
      "demorou 21.77 segundos \n",
      "\n",
      "treinando LogisticRegression 4 . . . \n",
      "demorou 17.21 segundos \n",
      "\n",
      "treinando LogisticRegression 5 . . . \n",
      "demorou 38.6 segundos \n",
      "\n",
      "treinando LogisticRegression 6 . . . \n",
      "Falha ao treinar LogisticRegression 6 . . . \n",
      "treinando LogisticRegression 7 . . . \n",
      "Falha ao treinar LogisticRegression 7 . . . \n",
      "treinando LogisticRegression 8 . . . \n",
      "demorou 5.58 segundos \n",
      "\n",
      "treinando LogisticRegression 9 . . . \n",
      "Falha ao treinar LogisticRegression 9 . . . \n",
      "treinando LogisticRegression 10 . . . \n",
      "demorou 1.15 minutos \n",
      "\n",
      "treinando LogisticRegression 11 . . . \n",
      "Falha ao treinar LogisticRegression 11 . . . \n",
      "treinando LogisticRegression 12 . . . \n",
      "Falha ao treinar LogisticRegression 12 . . . \n",
      "treinando LogisticRegression 13 . . . \n",
      "Falha ao treinar LogisticRegression 13 . . . \n",
      "treinando LogisticRegression 14 . . . \n",
      "Falha ao treinar LogisticRegression 14 . . . \n",
      "treinando LogisticRegression 15 . . . \n",
      "Falha ao treinar LogisticRegression 15 . . . \n",
      "treinando LogisticRegression 16 . . . \n",
      "demorou 13.99 segundos \n",
      "\n",
      "treinando LogisticRegression 17 . . . \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demorou 12.72 segundos \n",
      "\n",
      "treinando LogisticRegression 18 . . . \n",
      "Falha ao treinar LogisticRegression 18 . . . \n",
      "treinando LogisticRegression 19 . . . \n",
      "demorou 17.52 segundos \n",
      "\n",
      "treinando LogisticRegression 20 . . . \n",
      "demorou 38.5 segundos \n",
      "\n",
      "treinando LogisticRegression 21 . . . \n",
      "demorou 14.31 segundos \n",
      "\n",
      "treinando LogisticRegression 22 . . . \n",
      "demorou 9.8 segundos \n",
      "\n",
      "treinando LogisticRegression 23 . . . \n",
      "demorou 23.22 segundos \n",
      "\n",
      "treinando LogisticRegression 24 . . . \n",
      "demorou 17.29 segundos \n",
      "\n",
      "treinando LogisticRegression 25 . . . \n",
      "demorou 38.56 segundos \n",
      "\n",
      "treinando LogisticRegression 26 . . . \n",
      "Falha ao treinar LogisticRegression 26 . . . \n",
      "treinando LogisticRegression 27 . . . \n",
      "Falha ao treinar LogisticRegression 27 . . . \n",
      "treinando LogisticRegression 28 . . . \n",
      "demorou 5.42 segundos \n",
      "\n",
      "treinando LogisticRegression 29 . . . \n",
      "Falha ao treinar LogisticRegression 29 . . . \n",
      "treinando LogisticRegression 30 . . . \n",
      "demorou 1.37 minutos \n",
      "\n",
      "treinando LogisticRegression 31 . . . \n",
      "Falha ao treinar LogisticRegression 31 . . . \n",
      "treinando LogisticRegression 32 . . . \n",
      "Falha ao treinar LogisticRegression 32 . . . \n",
      "treinando LogisticRegression 33 . . . \n",
      "Falha ao treinar LogisticRegression 33 . . . \n",
      "treinando LogisticRegression 34 . . . \n",
      "Falha ao treinar LogisticRegression 34 . . . \n",
      "treinando LogisticRegression 35 . . . \n",
      "Falha ao treinar LogisticRegression 35 . . . \n",
      "treinando LogisticRegression 36 . . . \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demorou 14.1 segundos \n",
      "\n",
      "treinando LogisticRegression 37 . . . \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demorou 12.6 segundos \n",
      "\n",
      "treinando LogisticRegression 38 . . . \n",
      "Falha ao treinar LogisticRegression 38 . . . \n",
      "treinando LogisticRegression 39 . . . \n",
      "demorou 17.27 segundos \n",
      "\n",
      "treinando LogisticRegression 40 . . . \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demorou 38.39 segundos \n",
      "\n",
      "treinando LogisticRegression 41 . . . \n",
      "demorou 5.5 segundos \n",
      "\n",
      "treinando LogisticRegression 42 . . . \n",
      "demorou 18.35 segundos \n",
      "\n",
      "treinando LogisticRegression 43 . . . \n",
      "demorou 6.42 segundos \n",
      "\n",
      "treinando LogisticRegression 44 . . . \n",
      "demorou 19.01 segundos \n",
      "\n",
      "treinando LogisticRegression 45 . . . \n",
      "demorou 5.34 segundos \n",
      "\n",
      "treinando LogisticRegression 46 . . . \n",
      "demorou 18.46 segundos \n",
      "\n",
      "done!! :)\n"
     ]
    }
   ],
   "source": [
    "RegLog_fit = [RegLog1, \n",
    "              RegLog2, \n",
    "              RegLog3, \n",
    "              RegLog4, \n",
    "              RegLog5, \n",
    "              RegLog6, \n",
    "              RegLog7, \n",
    "              RegLog8, \n",
    "              RegLog9, \n",
    "              RegLog10,\n",
    "              RegLog11,\n",
    "              RegLog12,\n",
    "              RegLog13,\n",
    "              RegLog14,\n",
    "              RegLog15,\n",
    "              RegLog16,\n",
    "              RegLog17,\n",
    "              RegLog18,\n",
    "              RegLog19,\n",
    "              RegLog20,\n",
    "              RegLog21,\n",
    "              RegLog22,\n",
    "              RegLog23,\n",
    "              RegLog24,\n",
    "              RegLog25,\n",
    "              RegLog26,\n",
    "              RegLog27,\n",
    "              RegLog28,\n",
    "              RegLog29,\n",
    "              RegLog30,\n",
    "              RegLog31,\n",
    "              RegLog32,\n",
    "              RegLog33,\n",
    "              RegLog34,\n",
    "              RegLog35,\n",
    "              RegLog36,\n",
    "              RegLog37,\n",
    "              RegLog38,\n",
    "              RegLog39,\n",
    "              RegLog40,\n",
    "              RegLog41,\n",
    "              RegLog42,\n",
    "              RegLog43,\n",
    "              RegLog44,\n",
    "              RegLog45,\n",
    "              RegLog46]\n",
    "\n",
    "RegLog_fit, RegLog_fit_time = treinar_modelos(RegLog_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T17:48:26.174431Z",
     "start_time": "2020-09-20T17:48:25.596094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliando modelo LogisticRegression 1 ....\n",
      "accuracy = 0.8403237674760854 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 2 ....\n",
      "accuracy = 0.8403237674760854 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 3 ....\n",
      "accuracy = 0.8410596026490066 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 4 ....\n",
      "accuracy = 0.8390360559234732 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 5 ....\n",
      "accuracy = 0.8390360559234732 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 8 ....\n",
      "accuracy = 0.8410596026490066 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 10 ....\n",
      "accuracy = 0.8390360559234732 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 16 ....\n",
      "accuracy = 0.8403237674760854 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 17 ....\n",
      "accuracy = 0.8401398086828551 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 19 ....\n",
      "accuracy = 0.8390360559234732 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 20 ....\n",
      "accuracy = 0.8390360559234732 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 21 ....\n",
      "accuracy = 0.8403237674760854 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 22 ....\n",
      "accuracy = 0.8401398086828551 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 23 ....\n",
      "accuracy = 0.8403237674760854 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 24 ....\n",
      "accuracy = 0.8390360559234732 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 25 ....\n",
      "accuracy = 0.8390360559234732 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 28 ....\n",
      "accuracy = 0.8408756438557763 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 30 ....\n",
      "accuracy = 0.8390360559234732 e predict demorou 0.0 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 36 ....\n",
      "accuracy = 0.8403237674760854 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 37 ....\n",
      "accuracy = 0.8401398086828551 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 39 ....\n",
      "accuracy = 0.8390360559234732 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 40 ....\n",
      "accuracy = 0.8390360559234732 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 41 ....\n",
      "accuracy = 0.8423473142016188 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 42 ....\n",
      "accuracy = 0.8408756438557763 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 43 ....\n",
      "accuracy = 0.8416114790286976 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 44 ....\n",
      "accuracy = 0.8412435614422369 e predict demorou 0.0 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 45 ....\n",
      "accuracy = 0.8408756438557763 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo LogisticRegression 46 ....\n",
      "accuracy = 0.8408756438557763 e predict demorou 0.02 segundos \n",
      "\n",
      "tempo para rodar toda a planilha é aproximadamente 10.0 minutos\n"
     ]
    }
   ],
   "source": [
    "dataframe_metricas_modelos = pd.concat([dataframe_metricas_modelos, \n",
    "                                        avalia_lista_modelos(RegLog_fit, \n",
    "                                                             RegLog_fit_time,\n",
    "                                                             testX, \n",
    "                                                             testY)], axis=0)\n",
    "# dataframe_metricas_modelos.tail(len(RegLog_fit)).dropna().reset_index(drop=False)\n",
    "tempo_para_rodar = dataframe_metricas_modelos.tail(len(RegLog_fit))[\"tempo fit\"].sum()\n",
    "print(f\"tempo para rodar toda a planilha é aproximadamente {round(tempo_para_rodar/60,0)} minutos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T17:48:26.205143Z",
     "start_time": "2020-09-20T17:48:26.176425Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Documentação](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T17:48:26.256199Z",
     "start_time": "2020-09-20T17:48:26.207331Z"
    }
   },
   "outputs": [],
   "source": [
    "clf_MLP1 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(50, 3), random_state=42, max_iter=200000,learning_rate=\"constant\",learning_rate_init= 0.01, activation = \"relu\")\n",
    "clf_MLP2 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(50, 3), random_state=42, max_iter=200000,learning_rate=\"invscaling\",learning_rate_init= 0.01, activation = \"relu\")\n",
    "clf_MLP3 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(50, 3), random_state=42, max_iter=200000,learning_rate=\"adaptive\",learning_rate_init= 0.01, activation = \"relu\")\n",
    "\n",
    "clf_MLP4 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 50, 3), random_state=42, max_iter=200000,learning_rate=\"constant\",learning_rate_init= 0.1, activation = \"relu\")\n",
    "clf_MLP5 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 50, 3), random_state=42, max_iter=200000,learning_rate=\"invscaling\",learning_rate_init= 0.1, activation = \"relu\")\n",
    "clf_MLP6 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 50, 3), random_state=42, max_iter=200000,learning_rate=\"adaptive\",learning_rate_init= 0.1, activation = \"relu\")\n",
    "\n",
    "clf_MLP7 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(224, 100, 3), random_state=42, max_iter=200000,learning_rate=\"constant\",learning_rate_init= 0.01, activation = \"relu\")\n",
    "clf_MLP8 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(224, 100, 3), random_state=42, max_iter=200000,learning_rate=\"invscaling\",learning_rate_init= 0.01, activation = \"relu\")\n",
    "clf_MLP9 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(224, 100, 3), random_state=42, max_iter=200000,learning_rate=\"adaptive\",learning_rate_init= 0.01, activation = \"relu\")\n",
    "\n",
    "\n",
    "\n",
    "clf_MLP10 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(50, 3), random_state=42, max_iter=200000,learning_rate=\"constant\",learning_rate_init= 0.0001)\n",
    "clf_MLP11 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(50, 3), random_state=42, max_iter=200000,learning_rate=\"invscaling\",learning_rate_init= 0.0001)\n",
    "clf_MLP12 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(50, 3), random_state=42, max_iter=200000,learning_rate=\"adaptive\",learning_rate_init= 0.0001)\n",
    "\n",
    "clf_MLP13 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 50, 3), random_state=42, max_iter=200000,learning_rate=\"constant\",learning_rate_init= 0.0001)\n",
    "clf_MLP14 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 50, 3), random_state=42, max_iter=200000,learning_rate=\"invscaling\",learning_rate_init= 0.0001)\n",
    "clf_MLP15 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 50, 3), random_state=42, max_iter=200000,learning_rate=\"adaptive\",learning_rate_init= 0.0001)\n",
    "\n",
    "clf_MLP16 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(224, 100, 3), random_state=42, max_iter=200000,learning_rate=\"constant\",learning_rate_init= 0.0001)\n",
    "clf_MLP17 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(224, 100, 3), random_state=42, max_iter=200000,learning_rate=\"invscaling\",learning_rate_init= 0.0001)\n",
    "clf_MLP18 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(224, 100, 3), random_state=42, max_iter=200000,learning_rate=\"adaptive\",learning_rate_init= 0.0001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf_MLP19 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(50, 3), random_state=42, max_iter=200000,learning_rate=\"constant\",learning_rate_init= 0.01, activation = \"tanh\")\n",
    "clf_MLP20 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(50, 3), random_state=42, max_iter=200000,learning_rate=\"invscaling\",learning_rate_init= 0.01, activation = \"tanh\")\n",
    "clf_MLP21 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(50, 3), random_state=42, max_iter=200000,learning_rate=\"adaptive\",learning_rate_init= 0.01, activation = \"tanh\")\n",
    "\n",
    "clf_MLP22 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 50, 3), random_state=42, max_iter=200000,learning_rate=\"constant\",learning_rate_init= 0.1, activation = \"tanh\")\n",
    "clf_MLP23 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 50, 3), random_state=42, max_iter=200000,learning_rate=\"invscaling\",learning_rate_init= 0.1, activation = \"tanh\")\n",
    "clf_MLP24 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 50, 3), random_state=42, max_iter=200000,learning_rate=\"adaptive\",learning_rate_init= 0.1, activation = \"tanh\")\n",
    "\n",
    "clf_MLP25 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(224, 100, 3), random_state=42, max_iter=200000,learning_rate=\"constant\",learning_rate_init= 0.01, activation = \"tanh\")\n",
    "clf_MLP26 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(224, 100, 3), random_state=42, max_iter=200000,learning_rate=\"invscaling\",learning_rate_init= 0.01, activation = \"tanh\")\n",
    "clf_MLP27 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(224, 100, 3), random_state=42, max_iter=200000,learning_rate=\"adaptive\",learning_rate_init= 0.01, activation = \"tanh\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf_MLP28 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(50, 3), random_state=42, max_iter=200000,learning_rate=\"constant\",learning_rate_init= 0.01, activation = \"logistic\")\n",
    "clf_MLP29 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(50, 3), random_state=42, max_iter=200000,learning_rate=\"invscaling\",learning_rate_init= 0.01, activation = \"logistic\")\n",
    "clf_MLP30 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(50, 3), random_state=42, max_iter=200000,learning_rate=\"adaptive\",learning_rate_init= 0.01, activation = \"logistic\")\n",
    "\n",
    "clf_MLP31 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 50, 3), random_state=42, max_iter=200000,learning_rate=\"constant\",learning_rate_init= 0.1, activation = \"logistic\")\n",
    "clf_MLP32 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 50, 3), random_state=42, max_iter=200000,learning_rate=\"invscaling\",learning_rate_init= 0.1, activation = \"logistic\")\n",
    "clf_MLP33 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 50, 3), random_state=42, max_iter=200000,learning_rate=\"adaptive\",learning_rate_init= 0.1, activation = \"logistic\")\n",
    "\n",
    "clf_MLP34 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(224, 100, 3), random_state=42, max_iter=200000,learning_rate=\"constant\",learning_rate_init= 0.01, activation = \"logistic\")\n",
    "clf_MLP35 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(224, 100, 3), random_state=42, max_iter=200000,learning_rate=\"invscaling\",learning_rate_init= 0.01, activation = \"logistic\")\n",
    "clf_MLP36 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(224, 100, 3), random_state=42, max_iter=200000,learning_rate=\"adaptive\",learning_rate_init= 0.01, activation = \"logistic\")\n",
    "\n",
    "\n",
    "\n",
    "clf_MLP28 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(50, 3), random_state=42, max_iter=200000,learning_rate=\"constant\",learning_rate_init= 0.01, activation = \"identity\")\n",
    "clf_MLP29 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(50, 3), random_state=42, max_iter=200000,learning_rate=\"invscaling\",learning_rate_init= 0.01, activation = \"identity\")\n",
    "clf_MLP30 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(50, 3), random_state=42, max_iter=200000,learning_rate=\"adaptive\",learning_rate_init= 0.01, activation = \"identity\")\n",
    "\n",
    "clf_MLP31 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 50, 3), random_state=42, max_iter=200000,learning_rate=\"constant\",learning_rate_init= 0.1, activation = \"identity\")\n",
    "clf_MLP32 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 50, 3), random_state=42, max_iter=200000,learning_rate=\"invscaling\",learning_rate_init= 0.1, activation = \"identity\")\n",
    "clf_MLP33 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 50, 3), random_state=42, max_iter=200000,learning_rate=\"adaptive\",learning_rate_init= 0.1, activation = \"identity\")\n",
    "\n",
    "clf_MLP34 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(224, 100, 3), random_state=42, max_iter=200000,learning_rate=\"constant\",learning_rate_init= 0.01, activation = \"identity\")\n",
    "clf_MLP35 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(224, 100, 3), random_state=42, max_iter=200000,learning_rate=\"invscaling\",learning_rate_init= 0.01, activation = \"identity\")\n",
    "clf_MLP36 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(224, 100, 3), random_state=42, max_iter=200000,learning_rate=\"adaptive\",learning_rate_init= 0.01, activation = \"identity\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T20:27:46.941739Z",
     "start_time": "2020-09-20T17:48:26.259288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treinando MLPClassifier 1 . . . \n",
      "demorou 2.35 minutos \n",
      "\n",
      "treinando MLPClassifier 2 . . . \n",
      "demorou 2.36 minutos \n",
      "\n",
      "treinando MLPClassifier 3 . . . \n",
      "demorou 2.39 minutos \n",
      "\n",
      "treinando MLPClassifier 4 . . . \n",
      "demorou 4.06 minutos \n",
      "\n",
      "treinando MLPClassifier 5 . . . \n",
      "demorou 4.05 minutos \n",
      "\n",
      "treinando MLPClassifier 6 . . . \n",
      "demorou 4.05 minutos \n",
      "\n",
      "treinando MLPClassifier 7 . . . \n",
      "demorou 2.68 segundos \n",
      "\n",
      "treinando MLPClassifier 8 . . . \n",
      "demorou 2.57 segundos \n",
      "\n",
      "treinando MLPClassifier 9 . . . \n",
      "demorou 2.58 segundos \n",
      "\n",
      "treinando MLPClassifier 10 . . . \n",
      "demorou 2.36 minutos \n",
      "\n",
      "treinando MLPClassifier 11 . . . \n",
      "demorou 2.37 minutos \n",
      "\n",
      "treinando MLPClassifier 12 . . . \n",
      "demorou 2.39 minutos \n",
      "\n",
      "treinando MLPClassifier 13 . . . \n",
      "demorou 4.07 minutos \n",
      "\n",
      "treinando MLPClassifier 14 . . . \n",
      "demorou 4.07 minutos \n",
      "\n",
      "treinando MLPClassifier 15 . . . \n",
      "demorou 4.08 minutos \n",
      "\n",
      "treinando MLPClassifier 16 . . . \n",
      "demorou 2.48 segundos \n",
      "\n",
      "treinando MLPClassifier 17 . . . \n",
      "demorou 2.53 segundos \n",
      "\n",
      "treinando MLPClassifier 18 . . . \n",
      "demorou 2.59 segundos \n",
      "\n",
      "treinando MLPClassifier 19 . . . \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demorou 13.27 minutos \n",
      "\n",
      "treinando MLPClassifier 20 . . . \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demorou 13.25 minutos \n",
      "\n",
      "treinando MLPClassifier 21 . . . \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demorou 13.25 minutos \n",
      "\n",
      "treinando MLPClassifier 22 . . . \n",
      "demorou 12.98 minutos \n",
      "\n",
      "treinando MLPClassifier 23 . . . \n",
      "demorou 13.02 minutos \n",
      "\n",
      "treinando MLPClassifier 24 . . . \n",
      "demorou 13.05 minutos \n",
      "\n",
      "treinando MLPClassifier 25 . . . \n",
      "demorou 4.98 minutos \n",
      "\n",
      "treinando MLPClassifier 26 . . . \n",
      "demorou 4.95 minutos \n",
      "\n",
      "treinando MLPClassifier 27 . . . \n",
      "demorou 4.93 minutos \n",
      "\n",
      "treinando MLPClassifier 28 . . . \n",
      "demorou 1.47 minutos \n",
      "\n",
      "treinando MLPClassifier 29 . . . \n",
      "demorou 1.46 minutos \n",
      "\n",
      "treinando MLPClassifier 30 . . . \n",
      "demorou 1.48 minutos \n",
      "\n",
      "treinando MLPClassifier 31 . . . \n",
      "demorou 4.14 minutos \n",
      "\n",
      "treinando MLPClassifier 32 . . . \n",
      "demorou 4.12 minutos \n",
      "\n",
      "treinando MLPClassifier 33 . . . \n",
      "demorou 4.13 minutos \n",
      "\n",
      "treinando MLPClassifier 34 . . . \n",
      "demorou 3.33 minutos \n",
      "\n",
      "treinando MLPClassifier 35 . . . \n",
      "demorou 3.35 minutos \n",
      "\n",
      "treinando MLPClassifier 36 . . . \n",
      "demorou 3.33 minutos \n",
      "\n",
      "done!! :)\n"
     ]
    }
   ],
   "source": [
    "clf_MLP_fit =  [clf_MLP1,\n",
    "                clf_MLP2,\n",
    "                clf_MLP3,\n",
    "                clf_MLP4,\n",
    "                clf_MLP5,\n",
    "                clf_MLP6,\n",
    "                clf_MLP7,\n",
    "                clf_MLP8,\n",
    "                clf_MLP9,\n",
    "                clf_MLP10,\n",
    "                clf_MLP11,\n",
    "                clf_MLP12,\n",
    "                clf_MLP13,\n",
    "                clf_MLP14,\n",
    "                clf_MLP15,\n",
    "                clf_MLP16,\n",
    "                clf_MLP17,\n",
    "                clf_MLP18,\n",
    "                clf_MLP19,\n",
    "                clf_MLP20,\n",
    "                clf_MLP21,\n",
    "                clf_MLP22,\n",
    "                clf_MLP23,\n",
    "                clf_MLP24,\n",
    "                clf_MLP25,\n",
    "                clf_MLP26,\n",
    "                clf_MLP27,\n",
    "                clf_MLP28,\n",
    "                clf_MLP29,\n",
    "                clf_MLP30,\n",
    "                clf_MLP31,\n",
    "                clf_MLP32,\n",
    "                clf_MLP33,\n",
    "                clf_MLP34,\n",
    "                clf_MLP35,\n",
    "                clf_MLP36]\n",
    "\n",
    "clf_MLP_fit, clf_MLP_fit_time = treinar_modelos(clf_MLP_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T20:27:48.547717Z",
     "start_time": "2020-09-20T20:27:46.943807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliando modelo MLPClassifier 1 ....\n",
      "accuracy = 0.8631346578366446 e predict demorou 0.03 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 2 ....\n",
      "accuracy = 0.8631346578366446 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 3 ....\n",
      "accuracy = 0.8631346578366446 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 4 ....\n",
      "accuracy = 0.6455114054451803 e predict demorou 0.03 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 5 ....\n",
      "accuracy = 0.6455114054451803 e predict demorou 0.03 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 6 ....\n",
      "accuracy = 0.6455114054451803 e predict demorou 0.04 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 7 ....\n",
      "accuracy = 0.41096394407652687 e predict demorou 0.07 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 8 ....\n",
      "accuracy = 0.41096394407652687 e predict demorou 0.06 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 9 ....\n",
      "accuracy = 0.41096394407652687 e predict demorou 0.07 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 10 ....\n",
      "accuracy = 0.8631346578366446 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 11 ....\n",
      "accuracy = 0.8631346578366446 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 12 ....\n",
      "accuracy = 0.8631346578366446 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 13 ....\n",
      "accuracy = 0.6455114054451803 e predict demorou 0.03 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 14 ....\n",
      "accuracy = 0.6455114054451803 e predict demorou 0.04 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 15 ....\n",
      "accuracy = 0.6455114054451803 e predict demorou 0.03 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 16 ....\n",
      "accuracy = 0.41096394407652687 e predict demorou 0.07 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 17 ....\n",
      "accuracy = 0.41096394407652687 e predict demorou 0.06 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 18 ....\n",
      "accuracy = 0.41096394407652687 e predict demorou 0.06 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 19 ....\n",
      "accuracy = 0.8438189845474614 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 20 ....\n",
      "accuracy = 0.8438189845474614 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 21 ....\n",
      "accuracy = 0.8438189845474614 e predict demorou 0.03 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 22 ....\n",
      "accuracy = 0.8467623252391464 e predict demorou 0.03 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 23 ....\n",
      "accuracy = 0.8467623252391464 e predict demorou 0.03 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 24 ....\n",
      "accuracy = 0.8467623252391464 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 25 ....\n",
      "accuracy = 0.8513612950699043 e predict demorou 0.06 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 26 ....\n",
      "accuracy = 0.8513612950699043 e predict demorou 0.07 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 27 ....\n",
      "accuracy = 0.8513612950699043 e predict demorou 0.07 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 28 ....\n",
      "accuracy = 0.8392200147167035 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 29 ....\n",
      "accuracy = 0.8392200147167035 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 30 ....\n",
      "accuracy = 0.8392200147167035 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 31 ....\n",
      "accuracy = 0.8381162619573216 e predict demorou 0.03 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 32 ....\n",
      "accuracy = 0.8381162619573216 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 33 ....\n",
      "accuracy = 0.8381162619573216 e predict demorou 0.01 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 34 ....\n",
      "accuracy = 0.8401398086828551 e predict demorou 0.03 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 35 ....\n",
      "accuracy = 0.8401398086828551 e predict demorou 0.02 segundos \n",
      "\n",
      "Avaliando modelo MLPClassifier 36 ....\n",
      "accuracy = 0.8401398086828551 e predict demorou 0.02 segundos \n",
      "\n",
      "tempo para rodar toda a planilha é aproximadamente 159.0 minutos\n"
     ]
    }
   ],
   "source": [
    "dataframe_metricas_modelos = pd.concat([dataframe_metricas_modelos, \n",
    "                                        avalia_lista_modelos(clf_MLP_fit, \n",
    "                                                             clf_MLP_fit_time,\n",
    "                                                             testX, \n",
    "                                                             testY)], \n",
    "                                       axis=0)\n",
    "# dataframe_metricas_modelos.tail(len(clf_MLP_fit)).dropna().reset_index(drop=False)\n",
    "tempo_para_rodar = dataframe_metricas_modelos.tail(len(clf_MLP_fit))[\"tempo fit\"].sum()\n",
    "print(f\"tempo para rodar toda a planilha é aproximadamente {round(tempo_para_rodar/60,0)} minutos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T21:17:55.934018Z",
     "start_time": "2020-09-20T21:17:55.930031Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T21:29:14.029346Z",
     "start_time": "2020-09-20T21:29:03.104247Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1150"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = decision_tree1.cost_complexity_pruning_path(trainX, trainY)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "len(ccp_alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Documentação RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)\n",
    "\n",
    "#### [Documentação ExtraTreesClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html#sklearn.ensemble.ExtraTreesClassifier)\n",
    "\n",
    "#### [Documentação AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier)\n",
    "\n",
    "#### [Documentação GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T21:42:45.403086Z",
     "start_time": "2020-09-20T21:42:45.387339Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ensemble_methods = (RandomForestClassifier(max_depth=100, random_state=42),\n",
    "#                      ExtraTreesClassifier(n_estimators=100, random_state=42),\n",
    "#                      AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "#                      GradientBoostingClassifier(random_state=42))\n",
    "\n",
    "\n",
    "Ensemble_methods1 = RandomForestClassifier(max_depth=1000, random_state=42, criterion= \"gini\", class_weight=None)\n",
    "Ensemble_methods2 = RandomForestClassifier(max_depth=1000, random_state=42, criterion= \"entropy\", class_weight=None)\n",
    "\n",
    "Ensemble_methods3 = RandomForestClassifier(max_depth=1000, random_state=42, criterion= \"gini\", class_weight = \"balanced\")\n",
    "Ensemble_methods4 = RandomForestClassifier(max_depth=1000, random_state=42, criterion= \"entropy\", class_weight = \"balanced\")\n",
    "\n",
    "Ensemble_methods5 = ExtraTreesClassifier(n_estimators=100, random_state=42, criterion= \"gini\", class_weight=None)\n",
    "Ensemble_methods6 = ExtraTreesClassifier(n_estimators=100, random_state=42, criterion= \"entropy\", class_weight=None)\n",
    "\n",
    "Ensemble_methods7 = ExtraTreesClassifier(n_estimators=100, random_state=42, criterion= \"gini\", class_weight = \"balanced\")\n",
    "Ensemble_methods8 = ExtraTreesClassifier(n_estimators=100, random_state=42, criterion= \"entropy\", class_weight = \"balanced\")\n",
    "\n",
    "Ensemble_methods9 = AdaBoostClassifier(n_estimators=100, random_state=42, algorithm=\"SAMME\", learning_rate= 1)\n",
    "Ensemble_methods10 = AdaBoostClassifier(n_estimators=100, random_state=42, algorithm=\"SAMME.R\", learning_rate= 1)\n",
    "\n",
    "Ensemble_methods11 = AdaBoostClassifier(n_estimators=100, random_state=42, algorithm=\"SAMME\", learning_rate= 2)\n",
    "Ensemble_methods12 = AdaBoostClassifier(n_estimators=100, random_state=42, algorithm=\"SAMME.R\", learning_rate= 2)\n",
    "\n",
    "Ensemble_methods13 = AdaBoostClassifier(n_estimators=100, random_state=42, algorithm=\"SAMME\", learning_rate= 0.5)\n",
    "Ensemble_methods14 = AdaBoostClassifier(n_estimators=100, random_state=42, algorithm=\"SAMME.R\", learning_rate= 0.5)\n",
    "\n",
    "Ensemble_methods15 = GradientBoostingClassifier(random_state=42,n_iter_no_change=3, loss= \"deviance\", criterion= \"friedman_mse\", tol=1e-2)\n",
    "Ensemble_methods16 = GradientBoostingClassifier(random_state=42,n_iter_no_change=3, loss= \"deviance\", criterion= \"friedman_mse\", tol=1e-4)\n",
    "Ensemble_methods17 = GradientBoostingClassifier(random_state=42,n_iter_no_change=3, loss= \"deviance\", criterion= \"friedman_mse\", tol=1e-6)\n",
    "\n",
    "Ensemble_methods18 = GradientBoostingClassifier(random_state=42,n_iter_no_change=3, loss= \"deviance\", criterion= \"mse\", tol=1e-2)\n",
    "Ensemble_methods19 = GradientBoostingClassifier(random_state=42,n_iter_no_change=3, loss= \"deviance\", criterion= \"mse\", tol=1e-4)\n",
    "Ensemble_methods20 = GradientBoostingClassifier(random_state=42,n_iter_no_change=3, loss= \"deviance\", criterion= \"mse\", tol=1e-6)\n",
    "\n",
    "##Fica mmuito custoso utilizar a metrica MAE, demora muito e não é esperado que tenha um resultado melhor\n",
    "# Ensemble_methods21 = GradientBoostingClassifier(random_state=42,n_iter_no_change=3, loss= \"deviance\", criterion= \"mae\")\n",
    "# Ensemble_methods22 = GradientBoostingClassifier(random_state=42,n_iter_no_change=2, loss= \"exponential\", criterion= \"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T22:27:40.501832Z",
     "start_time": "2020-09-20T21:42:46.289474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treinando RandomForestClassifier 1 . . . \n",
      "demorou 20.48 segundos \n",
      "\n",
      "treinando RandomForestClassifier 2 . . . \n",
      "demorou 32.84 segundos \n",
      "\n",
      "treinando RandomForestClassifier 3 . . . \n",
      "demorou 22.35 segundos \n",
      "\n",
      "treinando RandomForestClassifier 4 . . . \n",
      "demorou 34.58 segundos \n",
      "\n",
      "treinando ExtraTreesClassifier 5 . . . \n",
      "demorou 8.06 segundos \n",
      "\n",
      "treinando ExtraTreesClassifier 6 . . . \n",
      "demorou 8.23 segundos \n",
      "\n",
      "treinando ExtraTreesClassifier 7 . . . \n",
      "demorou 8.44 segundos \n",
      "\n",
      "treinando ExtraTreesClassifier 8 . . . \n",
      "demorou 8.42 segundos \n",
      "\n",
      "treinando AdaBoostClassifier 9 . . . \n",
      "demorou 1.14 minutos \n",
      "\n",
      "treinando AdaBoostClassifier 10 . . . \n",
      "demorou 1.14 minutos \n",
      "\n",
      "treinando AdaBoostClassifier 11 . . . \n",
      "demorou 1.12 minutos \n",
      "\n",
      "treinando AdaBoostClassifier 12 . . . \n",
      "demorou 1.11 minutos \n",
      "\n",
      "treinando AdaBoostClassifier 13 . . . \n",
      "demorou 1.06 minutos \n",
      "\n",
      "treinando AdaBoostClassifier 14 . . . \n",
      "demorou 1.07 minutos \n",
      "\n",
      "treinando GradientBoostingClassifier 15 . . . \n",
      "demorou 2.76 minutos \n",
      "\n",
      "treinando GradientBoostingClassifier 16 . . . \n",
      "demorou 7.62 minutos \n",
      "\n",
      "treinando GradientBoostingClassifier 17 . . . \n",
      "demorou 7.62 minutos \n",
      "\n",
      "treinando GradientBoostingClassifier 18 . . . \n",
      "demorou 2.64 minutos \n",
      "\n",
      "treinando GradientBoostingClassifier 19 . . . \n",
      "demorou 7.66 minutos \n",
      "\n",
      "treinando GradientBoostingClassifier 20 . . . \n",
      "demorou 7.59 minutos \n",
      "\n",
      "done!! :)\n"
     ]
    }
   ],
   "source": [
    "models_Ensemble_methods_fit = [Ensemble_methods1,\n",
    "                               Ensemble_methods2,\n",
    "                               Ensemble_methods3,\n",
    "                               Ensemble_methods4,\n",
    "                               Ensemble_methods5,\n",
    "                               Ensemble_methods6,\n",
    "                               Ensemble_methods7,\n",
    "                               Ensemble_methods8,\n",
    "                               Ensemble_methods9,\n",
    "                               Ensemble_methods10,\n",
    "                               Ensemble_methods11,\n",
    "                               Ensemble_methods12,\n",
    "                               Ensemble_methods13,\n",
    "                               Ensemble_methods14,\n",
    "                               Ensemble_methods15,\n",
    "                               Ensemble_methods16,\n",
    "                               Ensemble_methods17,\n",
    "                               Ensemble_methods18,\n",
    "                               Ensemble_methods19,\n",
    "                               Ensemble_methods20]\n",
    "\n",
    "models_Ensemble_methods_fit, models_Ensemble_methods_fit_time = treinar_modelos(models_Ensemble_methods_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T22:27:48.293748Z",
     "start_time": "2020-09-20T22:27:40.503826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliando modelo RandomForestClassifier 1 ....\n",
      "accuracy = 0.8303899926416483 e predict demorou 0.21 segundos \n",
      "\n",
      "Avaliando modelo RandomForestClassifier 2 ....\n",
      "accuracy = 0.8309418690213393 e predict demorou 0.18 segundos \n",
      "\n",
      "Avaliando modelo RandomForestClassifier 3 ....\n",
      "accuracy = 0.8340691685062546 e predict demorou 0.19 segundos \n",
      "\n",
      "Avaliando modelo RandomForestClassifier 4 ....\n",
      "accuracy = 0.8305739514348786 e predict demorou 0.16 segundos \n",
      "\n",
      "Avaliando modelo ExtraTreesClassifier 5 ....\n",
      "accuracy = 0.8252391464311994 e predict demorou 0.2 segundos \n",
      "\n",
      "Avaliando modelo ExtraTreesClassifier 6 ....\n",
      "accuracy = 0.8300220750551877 e predict demorou 0.2 segundos \n",
      "\n",
      "Avaliando modelo ExtraTreesClassifier 7 ....\n",
      "accuracy = 0.8309418690213393 e predict demorou 0.2 segundos \n",
      "\n",
      "Avaliando modelo ExtraTreesClassifier 8 ....\n",
      "accuracy = 0.8296541574687271 e predict demorou 0.21 segundos \n",
      "\n",
      "Avaliando modelo AdaBoostClassifier 9 ....\n",
      "accuracy = 0.7593818984547461 e predict demorou 0.89 segundos \n",
      "\n",
      "Avaliando modelo AdaBoostClassifier 10 ....\n",
      "accuracy = 0.7838484179543782 e predict demorou 0.92 segundos \n",
      "\n",
      "Avaliando modelo AdaBoostClassifier 11 ....\n",
      "accuracy = 0.7124724061810155 e predict demorou 0.91 segundos \n",
      "\n",
      "Avaliando modelo AdaBoostClassifier 12 ....\n",
      "accuracy = 0.6598601913171449 e predict demorou 0.99 segundos \n",
      "\n",
      "Avaliando modelo AdaBoostClassifier 13 ....\n",
      "accuracy = 0.743009565857248 e predict demorou 0.96 segundos \n",
      "\n",
      "Avaliando modelo AdaBoostClassifier 14 ....\n",
      "accuracy = 0.7842163355408388 e predict demorou 0.93 segundos \n",
      "\n",
      "Avaliando modelo GradientBoostingClassifier 15 ....\n",
      "accuracy = 0.7970934510669611 e predict demorou 0.05 segundos \n",
      "\n",
      "Avaliando modelo GradientBoostingClassifier 16 ....\n",
      "accuracy = 0.8296541574687271 e predict demorou 0.08 segundos \n",
      "\n",
      "Avaliando modelo GradientBoostingClassifier 17 ....\n",
      "accuracy = 0.8296541574687271 e predict demorou 0.08 segundos \n",
      "\n",
      "Avaliando modelo GradientBoostingClassifier 18 ....\n",
      "accuracy = 0.7970934510669611 e predict demorou 0.05 segundos \n",
      "\n",
      "Avaliando modelo GradientBoostingClassifier 19 ....\n",
      "accuracy = 0.8296541574687271 e predict demorou 0.07 segundos \n",
      "\n",
      "Avaliando modelo GradientBoostingClassifier 20 ....\n",
      "accuracy = 0.8296541574687271 e predict demorou 0.08 segundos \n",
      "\n",
      "tempo para rodar toda a planilha é aproximadamente 45.0 minutos\n"
     ]
    }
   ],
   "source": [
    "dataframe_metricas_modelos = pd.concat([dataframe_metricas_modelos, \n",
    "                                        avalia_lista_modelos(models_Ensemble_methods_fit, \n",
    "                                                             models_Ensemble_methods_fit_time,\n",
    "                                                             testX, \n",
    "                                                             testY)], \n",
    "                                       axis=0)\n",
    "# dataframe_metricas_modelos.tail(len(models_Ensemble_methods_fit)).dropna().reset_index(drop=False)\n",
    "tempo_para_rodar = dataframe_metricas_modelos.tail(len(models_Ensemble_methods_fit))[\"tempo fit\"].sum()\n",
    "print(f\"tempo para rodar toda a planilha é aproximadamente {round(tempo_para_rodar/60,0)} minutos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T01:18:32.020965Z",
     "start_time": "2020-09-21T01:18:32.014009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tempo para treinar e predizer é aproximadamente 32 horas e 30.2 minutos\n"
     ]
    }
   ],
   "source": [
    "tempo_para_rodar_fit_total = dataframe_metricas_modelos[\"tempo fit\"].sum()\n",
    "tempo_para_rodar_predict_total = dataframe_metricas_modelos[\"tempo predict\"].sum()\n",
    "Tempo_treinamento_e_predict = (tempo_para_rodar_fit_total+tempo_para_rodar_predict_total)/60\n",
    "print(f\"tempo para treinar e predizer é aproximadamente {int(Tempo_treinamento_e_predict/60)} horas e {round(Tempo_treinamento_e_predict%60,1)} minutos\")\n",
    "fimGeral = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T01:18:43.556230Z",
     "start_time": "2020-09-21T01:18:43.551218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2713.0147833744686\n",
      "tempo para rodar todo o Notebook é aproximadamente 45 horas e 13.0 minutos\n"
     ]
    }
   ],
   "source": [
    "tempo_Total = (fimGeral-inicioGeral)/60\n",
    "print(tempo_Total)\n",
    "print(f\"tempo para rodar todo o Notebook é aproximadamente {int(tempo_Total/60)} horas e {round(tempo_Total%60,1)} minutos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T01:18:59.905873Z",
     "start_time": "2020-09-21T01:18:59.875921Z"
    }
   },
   "outputs": [],
   "source": [
    "#remove as linhas nulas e as que possuem acuracia abaixo de 60%\n",
    "dataframe_metricas_modelos = dataframe_metricas_modelos.dropna()\n",
    "dataframe_metricas_modelos.to_csv(\"metricas_modelos_classificacao_sem_nulos2.csv\")\n",
    "dataframe_metricas_modelos = dataframe_metricas_modelos[dataframe_metricas_modelos['accuracy']>0.60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T01:19:20.464733Z",
     "start_time": "2020-09-21T01:19:20.459772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187, 10)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_metricas_modelos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50 melhores acurácia geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T01:19:37.635500Z",
     "start_time": "2020-09-21T01:19:37.606578Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>media precision</th>\n",
       "      <th>media recall</th>\n",
       "      <th>media f1-score</th>\n",
       "      <th>media ponderada precision</th>\n",
       "      <th>media ponderada recall</th>\n",
       "      <th>media ponderada f1-score</th>\n",
       "      <th>tempo fit</th>\n",
       "      <th>tempo predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.876904</td>\n",
       "      <td>0.874532</td>\n",
       "      <td>0.875048</td>\n",
       "      <td>0.881079</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.879332</td>\n",
       "      <td>0.029968</td>\n",
       "      <td>52.743143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.876904</td>\n",
       "      <td>0.874532</td>\n",
       "      <td>0.875048</td>\n",
       "      <td>0.881079</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.879332</td>\n",
       "      <td>2.650857</td>\n",
       "      <td>59.318689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.876904</td>\n",
       "      <td>0.874532</td>\n",
       "      <td>0.875048</td>\n",
       "      <td>0.881079</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.879332</td>\n",
       "      <td>0.028922</td>\n",
       "      <td>52.933302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.876904</td>\n",
       "      <td>0.874532</td>\n",
       "      <td>0.875048</td>\n",
       "      <td>0.881079</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.879332</td>\n",
       "      <td>2.657073</td>\n",
       "      <td>59.128510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871357</td>\n",
       "      <td>0.865837</td>\n",
       "      <td>0.867745</td>\n",
       "      <td>0.873307</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871305</td>\n",
       "      <td>2.737489</td>\n",
       "      <td>59.118438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>91</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871357</td>\n",
       "      <td>0.865837</td>\n",
       "      <td>0.867745</td>\n",
       "      <td>0.873307</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871305</td>\n",
       "      <td>0.035696</td>\n",
       "      <td>53.158206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>89</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871357</td>\n",
       "      <td>0.865837</td>\n",
       "      <td>0.867745</td>\n",
       "      <td>0.873307</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871305</td>\n",
       "      <td>2.536995</td>\n",
       "      <td>59.317578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>87</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871357</td>\n",
       "      <td>0.865837</td>\n",
       "      <td>0.867745</td>\n",
       "      <td>0.873307</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871305</td>\n",
       "      <td>0.036204</td>\n",
       "      <td>52.918117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>0.026929</td>\n",
       "      <td>1.939642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>2.581278</td>\n",
       "      <td>59.302167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>3.626131</td>\n",
       "      <td>81.499483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>0.026941</td>\n",
       "      <td>2.180462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>2.654883</td>\n",
       "      <td>59.306390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>0.026942</td>\n",
       "      <td>2.032678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>3.631866</td>\n",
       "      <td>81.687822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>2.563508</td>\n",
       "      <td>59.151893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>3.674905</td>\n",
       "      <td>81.441552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>0.031952</td>\n",
       "      <td>50.991324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>2.646696</td>\n",
       "      <td>57.516279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>3.574337</td>\n",
       "      <td>68.646640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>26</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>2.615837</td>\n",
       "      <td>57.614316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>66</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>2.622460</td>\n",
       "      <td>57.814443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>30</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>0.027902</td>\n",
       "      <td>50.809997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>32</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>2.548194</td>\n",
       "      <td>57.532639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>34</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>3.615981</td>\n",
       "      <td>68.346582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>3.602903</td>\n",
       "      <td>68.463909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>36</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>0.026929</td>\n",
       "      <td>50.943763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>74</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>3.596777</td>\n",
       "      <td>68.264100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>68</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>3.638504</td>\n",
       "      <td>68.354701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>72</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>2.547346</td>\n",
       "      <td>57.543360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>70</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>0.026961</td>\n",
       "      <td>51.084528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>76</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>0.027922</td>\n",
       "      <td>51.050041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>11</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.860762</td>\n",
       "      <td>0.857728</td>\n",
       "      <td>0.858958</td>\n",
       "      <td>0.862484</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.862535</td>\n",
       "      <td>142.108870</td>\n",
       "      <td>0.015042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.860762</td>\n",
       "      <td>0.857728</td>\n",
       "      <td>0.858958</td>\n",
       "      <td>0.862484</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.862535</td>\n",
       "      <td>141.549502</td>\n",
       "      <td>0.009053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>12</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.860762</td>\n",
       "      <td>0.857728</td>\n",
       "      <td>0.858958</td>\n",
       "      <td>0.862484</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.862535</td>\n",
       "      <td>143.133405</td>\n",
       "      <td>0.015623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.860762</td>\n",
       "      <td>0.857728</td>\n",
       "      <td>0.858958</td>\n",
       "      <td>0.862484</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.862535</td>\n",
       "      <td>143.343545</td>\n",
       "      <td>0.023934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.860762</td>\n",
       "      <td>0.857728</td>\n",
       "      <td>0.858958</td>\n",
       "      <td>0.862484</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.862535</td>\n",
       "      <td>141.878605</td>\n",
       "      <td>0.008004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.860762</td>\n",
       "      <td>0.857728</td>\n",
       "      <td>0.858958</td>\n",
       "      <td>0.862484</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.862535</td>\n",
       "      <td>141.153272</td>\n",
       "      <td>0.029755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>84</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.858519</td>\n",
       "      <td>0.855271</td>\n",
       "      <td>0.856723</td>\n",
       "      <td>0.861420</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.861185</td>\n",
       "      <td>0.027959</td>\n",
       "      <td>99.976362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>82</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.858519</td>\n",
       "      <td>0.855271</td>\n",
       "      <td>0.856723</td>\n",
       "      <td>0.861420</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.861185</td>\n",
       "      <td>2.719545</td>\n",
       "      <td>108.352238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>80</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.858519</td>\n",
       "      <td>0.855271</td>\n",
       "      <td>0.856723</td>\n",
       "      <td>0.861420</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.861185</td>\n",
       "      <td>0.032888</td>\n",
       "      <td>100.127405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>78</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.858519</td>\n",
       "      <td>0.855271</td>\n",
       "      <td>0.856723</td>\n",
       "      <td>0.861420</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.861185</td>\n",
       "      <td>2.639398</td>\n",
       "      <td>108.707143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>35</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>0.041656</td>\n",
       "      <td>51.460521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>75</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>0.038763</td>\n",
       "      <td>51.064413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>29</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>0.036803</td>\n",
       "      <td>50.997628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>27</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>3.556415</td>\n",
       "      <td>68.502458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>25</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>2.552751</td>\n",
       "      <td>57.553232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>33</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>3.607504</td>\n",
       "      <td>68.303281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>67</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>3.718259</td>\n",
       "      <td>68.543370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>71</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>2.662820</td>\n",
       "      <td>58.174034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                  model  accuracy  media precision  media recall  \\\n",
       "0      92  KNeighborsClassifier   0.878771         0.876904      0.874532   \n",
       "1      90  KNeighborsClassifier   0.878771         0.876904      0.874532   \n",
       "2      88  KNeighborsClassifier   0.878771         0.876904      0.874532   \n",
       "3      86  KNeighborsClassifier   0.878771         0.876904      0.874532   \n",
       "4      85  KNeighborsClassifier   0.870861         0.871357      0.865837   \n",
       "5      91  KNeighborsClassifier   0.870861         0.871357      0.865837   \n",
       "6      89  KNeighborsClassifier   0.870861         0.871357      0.865837   \n",
       "7      87  KNeighborsClassifier   0.870861         0.871357      0.865837   \n",
       "8      12  KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "9      20  KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "10     22  KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "11     24  KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "12     14  KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "13     18  KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "14     10  KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "15      8   KNeighborsClassifier  0.865710         0.861384      0.861755   \n",
       "16     16  KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "17      6   KNeighborsClassifier  0.865526         0.860896      0.861536   \n",
       "18      2   KNeighborsClassifier  0.865526         0.860896      0.861536   \n",
       "19     28  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "20     26  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "21     66  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "22     30  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "23     32  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "24     34  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "25      4   KNeighborsClassifier  0.865526         0.860896      0.861536   \n",
       "26     36  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "27     74  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "28     68  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "29     72  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "30     70  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "31     76  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "32     11         MLPClassifier   0.863135         0.860762      0.857728   \n",
       "33     10         MLPClassifier   0.863135         0.860762      0.857728   \n",
       "34     12         MLPClassifier   0.863135         0.860762      0.857728   \n",
       "35      3          MLPClassifier  0.863135         0.860762      0.857728   \n",
       "36      2          MLPClassifier  0.863135         0.860762      0.857728   \n",
       "37      1          MLPClassifier  0.863135         0.860762      0.857728   \n",
       "38     84  KNeighborsClassifier   0.861295         0.858519      0.855271   \n",
       "39     82  KNeighborsClassifier   0.861295         0.858519      0.855271   \n",
       "40     80  KNeighborsClassifier   0.861295         0.858519      0.855271   \n",
       "41     78  KNeighborsClassifier   0.861295         0.858519      0.855271   \n",
       "42     35  KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "43     75  KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "44     29  KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "45     27  KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "46     25  KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "47     33  KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "48     67  KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "49     71  KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "\n",
       "    media f1-score  media ponderada precision  media ponderada recall  \\\n",
       "0         0.875048                   0.881079                0.878771   \n",
       "1         0.875048                   0.881079                0.878771   \n",
       "2         0.875048                   0.881079                0.878771   \n",
       "3         0.875048                   0.881079                0.878771   \n",
       "4         0.867745                   0.873307                0.870861   \n",
       "5         0.867745                   0.873307                0.870861   \n",
       "6         0.867745                   0.873307                0.870861   \n",
       "7         0.867745                   0.873307                0.870861   \n",
       "8         0.861432                   0.866630                0.865710   \n",
       "9         0.861432                   0.866630                0.865710   \n",
       "10        0.861432                   0.866630                0.865710   \n",
       "11        0.861432                   0.866630                0.865710   \n",
       "12        0.861432                   0.866630                0.865710   \n",
       "13        0.861432                   0.866630                0.865710   \n",
       "14        0.861432                   0.866630                0.865710   \n",
       "15        0.861432                   0.866630                0.865710   \n",
       "16        0.861432                   0.866630                0.865710   \n",
       "17        0.861201                   0.865854                0.865526   \n",
       "18        0.861201                   0.865854                0.865526   \n",
       "19        0.861201                   0.865854                0.865526   \n",
       "20        0.861201                   0.865854                0.865526   \n",
       "21        0.861201                   0.865854                0.865526   \n",
       "22        0.861201                   0.865854                0.865526   \n",
       "23        0.861201                   0.865854                0.865526   \n",
       "24        0.861201                   0.865854                0.865526   \n",
       "25        0.861201                   0.865854                0.865526   \n",
       "26        0.861201                   0.865854                0.865526   \n",
       "27        0.861201                   0.865854                0.865526   \n",
       "28        0.861201                   0.865854                0.865526   \n",
       "29        0.861201                   0.865854                0.865526   \n",
       "30        0.861201                   0.865854                0.865526   \n",
       "31        0.861201                   0.865854                0.865526   \n",
       "32        0.858958                   0.862484                0.863135   \n",
       "33        0.858958                   0.862484                0.863135   \n",
       "34        0.858958                   0.862484                0.863135   \n",
       "35        0.858958                   0.862484                0.863135   \n",
       "36        0.858958                   0.862484                0.863135   \n",
       "37        0.858958                   0.862484                0.863135   \n",
       "38        0.856723                   0.861420                0.861295   \n",
       "39        0.856723                   0.861420                0.861295   \n",
       "40        0.856723                   0.861420                0.861295   \n",
       "41        0.856723                   0.861420                0.861295   \n",
       "42        0.854429                   0.858018                0.858168   \n",
       "43        0.854429                   0.858018                0.858168   \n",
       "44        0.854429                   0.858018                0.858168   \n",
       "45        0.854429                   0.858018                0.858168   \n",
       "46        0.854429                   0.858018                0.858168   \n",
       "47        0.854429                   0.858018                0.858168   \n",
       "48        0.854429                   0.858018                0.858168   \n",
       "49        0.854429                   0.858018                0.858168   \n",
       "\n",
       "    media ponderada f1-score   tempo fit  tempo predict  \n",
       "0                   0.879332    0.029968      52.743143  \n",
       "1                   0.879332    2.650857      59.318689  \n",
       "2                   0.879332    0.028922      52.933302  \n",
       "3                   0.879332    2.657073      59.128510  \n",
       "4                   0.871305    2.737489      59.118438  \n",
       "5                   0.871305    0.035696      53.158206  \n",
       "6                   0.871305    2.536995      59.317578  \n",
       "7                   0.871305    0.036204      52.918117  \n",
       "8                   0.866047    0.026929       1.939642  \n",
       "9                   0.866047    2.581278      59.302167  \n",
       "10                  0.866047    3.626131      81.499483  \n",
       "11                  0.866047    0.026941       2.180462  \n",
       "12                  0.866047    2.654883      59.306390  \n",
       "13                  0.866047    0.026942       2.032678  \n",
       "14                  0.866047    3.631866      81.687822  \n",
       "15                  0.866047    2.563508      59.151893  \n",
       "16                  0.866047    3.674905      81.441552  \n",
       "17                  0.865675    0.031952      50.991324  \n",
       "18                  0.865675    2.646696      57.516279  \n",
       "19                  0.865675    3.574337      68.646640  \n",
       "20                  0.865675    2.615837      57.614316  \n",
       "21                  0.865675    2.622460      57.814443  \n",
       "22                  0.865675    0.027902      50.809997  \n",
       "23                  0.865675    2.548194      57.532639  \n",
       "24                  0.865675    3.615981      68.346582  \n",
       "25                  0.865675    3.602903      68.463909  \n",
       "26                  0.865675    0.026929      50.943763  \n",
       "27                  0.865675    3.596777      68.264100  \n",
       "28                  0.865675    3.638504      68.354701  \n",
       "29                  0.865675    2.547346      57.543360  \n",
       "30                  0.865675    0.026961      51.084528  \n",
       "31                  0.865675    0.027922      51.050041  \n",
       "32                  0.862535  142.108870       0.015042  \n",
       "33                  0.862535  141.549502       0.009053  \n",
       "34                  0.862535  143.133405       0.015623  \n",
       "35                  0.862535  143.343545       0.023934  \n",
       "36                  0.862535  141.878605       0.008004  \n",
       "37                  0.862535  141.153272       0.029755  \n",
       "38                  0.861185    0.027959      99.976362  \n",
       "39                  0.861185    2.719545     108.352238  \n",
       "40                  0.861185    0.032888     100.127405  \n",
       "41                  0.861185    2.639398     108.707143  \n",
       "42                  0.857959    0.041656      51.460521  \n",
       "43                  0.857959    0.038763      51.064413  \n",
       "44                  0.857959    0.036803      50.997628  \n",
       "45                  0.857959    3.556415      68.502458  \n",
       "46                  0.857959    2.552751      57.553232  \n",
       "47                  0.857959    3.607504      68.303281  \n",
       "48                  0.857959    3.718259      68.543370  \n",
       "49                  0.857959    2.662820      58.174034  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_metricas_modelos.sort_values(by=['accuracy'],ascending=False).reset_index(drop=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50 melhores f1-score geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T01:19:47.302591Z",
     "start_time": "2020-09-21T01:19:47.275687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>media precision</th>\n",
       "      <th>media recall</th>\n",
       "      <th>media f1-score</th>\n",
       "      <th>media ponderada precision</th>\n",
       "      <th>media ponderada recall</th>\n",
       "      <th>media ponderada f1-score</th>\n",
       "      <th>tempo fit</th>\n",
       "      <th>tempo predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.876904</td>\n",
       "      <td>0.874532</td>\n",
       "      <td>0.875048</td>\n",
       "      <td>0.881079</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.879332</td>\n",
       "      <td>0.029968</td>\n",
       "      <td>52.743143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.876904</td>\n",
       "      <td>0.874532</td>\n",
       "      <td>0.875048</td>\n",
       "      <td>0.881079</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.879332</td>\n",
       "      <td>2.650857</td>\n",
       "      <td>59.318689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.876904</td>\n",
       "      <td>0.874532</td>\n",
       "      <td>0.875048</td>\n",
       "      <td>0.881079</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.879332</td>\n",
       "      <td>0.028922</td>\n",
       "      <td>52.933302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.876904</td>\n",
       "      <td>0.874532</td>\n",
       "      <td>0.875048</td>\n",
       "      <td>0.881079</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.879332</td>\n",
       "      <td>2.657073</td>\n",
       "      <td>59.128510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871357</td>\n",
       "      <td>0.865837</td>\n",
       "      <td>0.867745</td>\n",
       "      <td>0.873307</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871305</td>\n",
       "      <td>2.737489</td>\n",
       "      <td>59.118438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>91</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871357</td>\n",
       "      <td>0.865837</td>\n",
       "      <td>0.867745</td>\n",
       "      <td>0.873307</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871305</td>\n",
       "      <td>0.035696</td>\n",
       "      <td>53.158206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>89</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871357</td>\n",
       "      <td>0.865837</td>\n",
       "      <td>0.867745</td>\n",
       "      <td>0.873307</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871305</td>\n",
       "      <td>2.536995</td>\n",
       "      <td>59.317578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>87</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871357</td>\n",
       "      <td>0.865837</td>\n",
       "      <td>0.867745</td>\n",
       "      <td>0.873307</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871305</td>\n",
       "      <td>0.036204</td>\n",
       "      <td>52.918117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>2.654883</td>\n",
       "      <td>59.306390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>0.026941</td>\n",
       "      <td>2.180462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>0.026942</td>\n",
       "      <td>2.032678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>3.674905</td>\n",
       "      <td>81.441552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>3.626131</td>\n",
       "      <td>81.499483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>0.026929</td>\n",
       "      <td>1.939642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>3.631866</td>\n",
       "      <td>81.687822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>2.563508</td>\n",
       "      <td>59.151893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>2.581278</td>\n",
       "      <td>59.302167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>2.646696</td>\n",
       "      <td>57.516279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>66</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>2.622460</td>\n",
       "      <td>57.814443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>2.615837</td>\n",
       "      <td>57.614316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>28</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>3.574337</td>\n",
       "      <td>68.646640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>3.602903</td>\n",
       "      <td>68.463909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>30</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>0.027902</td>\n",
       "      <td>50.809997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>32</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>2.548194</td>\n",
       "      <td>57.532639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>34</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>3.615981</td>\n",
       "      <td>68.346582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>0.031952</td>\n",
       "      <td>50.991324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>36</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>0.026929</td>\n",
       "      <td>50.943763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>74</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>3.596777</td>\n",
       "      <td>68.264100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>72</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>2.547346</td>\n",
       "      <td>57.543360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>76</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>0.027922</td>\n",
       "      <td>51.050041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>70</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>0.026961</td>\n",
       "      <td>51.084528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>68</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>3.638504</td>\n",
       "      <td>68.354701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>12</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.860762</td>\n",
       "      <td>0.857728</td>\n",
       "      <td>0.858958</td>\n",
       "      <td>0.862484</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.862535</td>\n",
       "      <td>143.133405</td>\n",
       "      <td>0.015623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.860762</td>\n",
       "      <td>0.857728</td>\n",
       "      <td>0.858958</td>\n",
       "      <td>0.862484</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.862535</td>\n",
       "      <td>141.549502</td>\n",
       "      <td>0.009053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>11</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.860762</td>\n",
       "      <td>0.857728</td>\n",
       "      <td>0.858958</td>\n",
       "      <td>0.862484</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.862535</td>\n",
       "      <td>142.108870</td>\n",
       "      <td>0.015042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.860762</td>\n",
       "      <td>0.857728</td>\n",
       "      <td>0.858958</td>\n",
       "      <td>0.862484</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.862535</td>\n",
       "      <td>141.153272</td>\n",
       "      <td>0.029755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.860762</td>\n",
       "      <td>0.857728</td>\n",
       "      <td>0.858958</td>\n",
       "      <td>0.862484</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.862535</td>\n",
       "      <td>141.878605</td>\n",
       "      <td>0.008004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.860762</td>\n",
       "      <td>0.857728</td>\n",
       "      <td>0.858958</td>\n",
       "      <td>0.862484</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.862535</td>\n",
       "      <td>143.343545</td>\n",
       "      <td>0.023934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>84</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.858519</td>\n",
       "      <td>0.855271</td>\n",
       "      <td>0.856723</td>\n",
       "      <td>0.861420</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.861185</td>\n",
       "      <td>0.027959</td>\n",
       "      <td>99.976362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>80</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.858519</td>\n",
       "      <td>0.855271</td>\n",
       "      <td>0.856723</td>\n",
       "      <td>0.861420</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.861185</td>\n",
       "      <td>0.032888</td>\n",
       "      <td>100.127405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>78</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.858519</td>\n",
       "      <td>0.855271</td>\n",
       "      <td>0.856723</td>\n",
       "      <td>0.861420</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.861185</td>\n",
       "      <td>2.639398</td>\n",
       "      <td>108.707143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>82</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.858519</td>\n",
       "      <td>0.855271</td>\n",
       "      <td>0.856723</td>\n",
       "      <td>0.861420</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.861185</td>\n",
       "      <td>2.719545</td>\n",
       "      <td>108.352238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>31</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>2.629065</td>\n",
       "      <td>57.619833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>33</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>3.607504</td>\n",
       "      <td>68.303281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>35</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>0.041656</td>\n",
       "      <td>51.460521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>27</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>3.556415</td>\n",
       "      <td>68.502458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>25</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>2.552751</td>\n",
       "      <td>57.553232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>75</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>0.038763</td>\n",
       "      <td>51.064413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>73</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>3.652772</td>\n",
       "      <td>68.309524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>69</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>0.036127</td>\n",
       "      <td>51.156095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                  model  accuracy  media precision  media recall  \\\n",
       "0      92  KNeighborsClassifier   0.878771         0.876904      0.874532   \n",
       "1      90  KNeighborsClassifier   0.878771         0.876904      0.874532   \n",
       "2      88  KNeighborsClassifier   0.878771         0.876904      0.874532   \n",
       "3      86  KNeighborsClassifier   0.878771         0.876904      0.874532   \n",
       "4      85  KNeighborsClassifier   0.870861         0.871357      0.865837   \n",
       "5      91  KNeighborsClassifier   0.870861         0.871357      0.865837   \n",
       "6      89  KNeighborsClassifier   0.870861         0.871357      0.865837   \n",
       "7      87  KNeighborsClassifier   0.870861         0.871357      0.865837   \n",
       "8      14  KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "9      24  KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "10     18  KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "11     16  KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "12     22  KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "13     12  KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "14     10  KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "15      8   KNeighborsClassifier  0.865710         0.861384      0.861755   \n",
       "16     20  KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "17      2   KNeighborsClassifier  0.865526         0.860896      0.861536   \n",
       "18     66  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "19     26  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "20     28  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "21      4   KNeighborsClassifier  0.865526         0.860896      0.861536   \n",
       "22     30  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "23     32  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "24     34  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "25      6   KNeighborsClassifier  0.865526         0.860896      0.861536   \n",
       "26     36  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "27     74  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "28     72  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "29     76  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "30     70  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "31     68  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "32     12         MLPClassifier   0.863135         0.860762      0.857728   \n",
       "33     10         MLPClassifier   0.863135         0.860762      0.857728   \n",
       "34     11         MLPClassifier   0.863135         0.860762      0.857728   \n",
       "35      1          MLPClassifier  0.863135         0.860762      0.857728   \n",
       "36      2          MLPClassifier  0.863135         0.860762      0.857728   \n",
       "37      3          MLPClassifier  0.863135         0.860762      0.857728   \n",
       "38     84  KNeighborsClassifier   0.861295         0.858519      0.855271   \n",
       "39     80  KNeighborsClassifier   0.861295         0.858519      0.855271   \n",
       "40     78  KNeighborsClassifier   0.861295         0.858519      0.855271   \n",
       "41     82  KNeighborsClassifier   0.861295         0.858519      0.855271   \n",
       "42     31  KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "43     33  KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "44     35  KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "45     27  KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "46     25  KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "47     75  KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "48     73  KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "49     69  KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "\n",
       "    media f1-score  media ponderada precision  media ponderada recall  \\\n",
       "0         0.875048                   0.881079                0.878771   \n",
       "1         0.875048                   0.881079                0.878771   \n",
       "2         0.875048                   0.881079                0.878771   \n",
       "3         0.875048                   0.881079                0.878771   \n",
       "4         0.867745                   0.873307                0.870861   \n",
       "5         0.867745                   0.873307                0.870861   \n",
       "6         0.867745                   0.873307                0.870861   \n",
       "7         0.867745                   0.873307                0.870861   \n",
       "8         0.861432                   0.866630                0.865710   \n",
       "9         0.861432                   0.866630                0.865710   \n",
       "10        0.861432                   0.866630                0.865710   \n",
       "11        0.861432                   0.866630                0.865710   \n",
       "12        0.861432                   0.866630                0.865710   \n",
       "13        0.861432                   0.866630                0.865710   \n",
       "14        0.861432                   0.866630                0.865710   \n",
       "15        0.861432                   0.866630                0.865710   \n",
       "16        0.861432                   0.866630                0.865710   \n",
       "17        0.861201                   0.865854                0.865526   \n",
       "18        0.861201                   0.865854                0.865526   \n",
       "19        0.861201                   0.865854                0.865526   \n",
       "20        0.861201                   0.865854                0.865526   \n",
       "21        0.861201                   0.865854                0.865526   \n",
       "22        0.861201                   0.865854                0.865526   \n",
       "23        0.861201                   0.865854                0.865526   \n",
       "24        0.861201                   0.865854                0.865526   \n",
       "25        0.861201                   0.865854                0.865526   \n",
       "26        0.861201                   0.865854                0.865526   \n",
       "27        0.861201                   0.865854                0.865526   \n",
       "28        0.861201                   0.865854                0.865526   \n",
       "29        0.861201                   0.865854                0.865526   \n",
       "30        0.861201                   0.865854                0.865526   \n",
       "31        0.861201                   0.865854                0.865526   \n",
       "32        0.858958                   0.862484                0.863135   \n",
       "33        0.858958                   0.862484                0.863135   \n",
       "34        0.858958                   0.862484                0.863135   \n",
       "35        0.858958                   0.862484                0.863135   \n",
       "36        0.858958                   0.862484                0.863135   \n",
       "37        0.858958                   0.862484                0.863135   \n",
       "38        0.856723                   0.861420                0.861295   \n",
       "39        0.856723                   0.861420                0.861295   \n",
       "40        0.856723                   0.861420                0.861295   \n",
       "41        0.856723                   0.861420                0.861295   \n",
       "42        0.854429                   0.858018                0.858168   \n",
       "43        0.854429                   0.858018                0.858168   \n",
       "44        0.854429                   0.858018                0.858168   \n",
       "45        0.854429                   0.858018                0.858168   \n",
       "46        0.854429                   0.858018                0.858168   \n",
       "47        0.854429                   0.858018                0.858168   \n",
       "48        0.854429                   0.858018                0.858168   \n",
       "49        0.854429                   0.858018                0.858168   \n",
       "\n",
       "    media ponderada f1-score   tempo fit  tempo predict  \n",
       "0                   0.879332    0.029968      52.743143  \n",
       "1                   0.879332    2.650857      59.318689  \n",
       "2                   0.879332    0.028922      52.933302  \n",
       "3                   0.879332    2.657073      59.128510  \n",
       "4                   0.871305    2.737489      59.118438  \n",
       "5                   0.871305    0.035696      53.158206  \n",
       "6                   0.871305    2.536995      59.317578  \n",
       "7                   0.871305    0.036204      52.918117  \n",
       "8                   0.866047    2.654883      59.306390  \n",
       "9                   0.866047    0.026941       2.180462  \n",
       "10                  0.866047    0.026942       2.032678  \n",
       "11                  0.866047    3.674905      81.441552  \n",
       "12                  0.866047    3.626131      81.499483  \n",
       "13                  0.866047    0.026929       1.939642  \n",
       "14                  0.866047    3.631866      81.687822  \n",
       "15                  0.866047    2.563508      59.151893  \n",
       "16                  0.866047    2.581278      59.302167  \n",
       "17                  0.865675    2.646696      57.516279  \n",
       "18                  0.865675    2.622460      57.814443  \n",
       "19                  0.865675    2.615837      57.614316  \n",
       "20                  0.865675    3.574337      68.646640  \n",
       "21                  0.865675    3.602903      68.463909  \n",
       "22                  0.865675    0.027902      50.809997  \n",
       "23                  0.865675    2.548194      57.532639  \n",
       "24                  0.865675    3.615981      68.346582  \n",
       "25                  0.865675    0.031952      50.991324  \n",
       "26                  0.865675    0.026929      50.943763  \n",
       "27                  0.865675    3.596777      68.264100  \n",
       "28                  0.865675    2.547346      57.543360  \n",
       "29                  0.865675    0.027922      51.050041  \n",
       "30                  0.865675    0.026961      51.084528  \n",
       "31                  0.865675    3.638504      68.354701  \n",
       "32                  0.862535  143.133405       0.015623  \n",
       "33                  0.862535  141.549502       0.009053  \n",
       "34                  0.862535  142.108870       0.015042  \n",
       "35                  0.862535  141.153272       0.029755  \n",
       "36                  0.862535  141.878605       0.008004  \n",
       "37                  0.862535  143.343545       0.023934  \n",
       "38                  0.861185    0.027959      99.976362  \n",
       "39                  0.861185    0.032888     100.127405  \n",
       "40                  0.861185    2.639398     108.707143  \n",
       "41                  0.861185    2.719545     108.352238  \n",
       "42                  0.857959    2.629065      57.619833  \n",
       "43                  0.857959    3.607504      68.303281  \n",
       "44                  0.857959    0.041656      51.460521  \n",
       "45                  0.857959    3.556415      68.502458  \n",
       "46                  0.857959    2.552751      57.553232  \n",
       "47                  0.857959    0.038763      51.064413  \n",
       "48                  0.857959    3.652772      68.309524  \n",
       "49                  0.857959    0.036127      51.156095  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_metricas_modelos.sort_values(by=['media f1-score'],ascending=False).reset_index(drop=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 piores acurácia geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T17:09:46.682601Z",
     "start_time": "2020-09-21T17:09:46.648692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>media precision</th>\n",
       "      <th>media recall</th>\n",
       "      <th>media f1-score</th>\n",
       "      <th>media ponderada precision</th>\n",
       "      <th>media ponderada recall</th>\n",
       "      <th>media ponderada f1-score</th>\n",
       "      <th>tempo fit</th>\n",
       "      <th>tempo predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.854537</td>\n",
       "      <td>0.851830</td>\n",
       "      <td>0.852997</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.856932</td>\n",
       "      <td>3.602799</td>\n",
       "      <td>81.478564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.854537</td>\n",
       "      <td>0.851830</td>\n",
       "      <td>0.852997</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.856932</td>\n",
       "      <td>2.621779</td>\n",
       "      <td>59.485099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>21</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.854537</td>\n",
       "      <td>0.851830</td>\n",
       "      <td>0.852997</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.856932</td>\n",
       "      <td>3.614048</td>\n",
       "      <td>82.147169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>15</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.854537</td>\n",
       "      <td>0.851830</td>\n",
       "      <td>0.852997</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.856932</td>\n",
       "      <td>3.536194</td>\n",
       "      <td>81.705079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>19</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.854537</td>\n",
       "      <td>0.851830</td>\n",
       "      <td>0.852997</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.856932</td>\n",
       "      <td>2.674072</td>\n",
       "      <td>59.336886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>17</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.854537</td>\n",
       "      <td>0.851830</td>\n",
       "      <td>0.852997</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.856932</td>\n",
       "      <td>0.027099</td>\n",
       "      <td>2.162479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>79</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.853017</td>\n",
       "      <td>0.854480</td>\n",
       "      <td>0.845563</td>\n",
       "      <td>0.849229</td>\n",
       "      <td>0.853952</td>\n",
       "      <td>0.853017</td>\n",
       "      <td>0.852657</td>\n",
       "      <td>0.035496</td>\n",
       "      <td>100.371877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>81</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.853017</td>\n",
       "      <td>0.854480</td>\n",
       "      <td>0.845563</td>\n",
       "      <td>0.849229</td>\n",
       "      <td>0.853952</td>\n",
       "      <td>0.853017</td>\n",
       "      <td>0.852657</td>\n",
       "      <td>2.524588</td>\n",
       "      <td>108.853681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>83</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.853017</td>\n",
       "      <td>0.854480</td>\n",
       "      <td>0.845563</td>\n",
       "      <td>0.849229</td>\n",
       "      <td>0.853952</td>\n",
       "      <td>0.853017</td>\n",
       "      <td>0.852657</td>\n",
       "      <td>0.037769</td>\n",
       "      <td>100.132839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>77</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.853017</td>\n",
       "      <td>0.854480</td>\n",
       "      <td>0.845563</td>\n",
       "      <td>0.849229</td>\n",
       "      <td>0.853952</td>\n",
       "      <td>0.853017</td>\n",
       "      <td>0.852657</td>\n",
       "      <td>2.582238</td>\n",
       "      <td>108.852259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>27</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.851361</td>\n",
       "      <td>0.848440</td>\n",
       "      <td>0.848566</td>\n",
       "      <td>0.848252</td>\n",
       "      <td>0.852962</td>\n",
       "      <td>0.851361</td>\n",
       "      <td>0.851935</td>\n",
       "      <td>295.903128</td>\n",
       "      <td>0.065385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>26</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.851361</td>\n",
       "      <td>0.848440</td>\n",
       "      <td>0.848566</td>\n",
       "      <td>0.848252</td>\n",
       "      <td>0.852962</td>\n",
       "      <td>0.851361</td>\n",
       "      <td>0.851935</td>\n",
       "      <td>296.846067</td>\n",
       "      <td>0.068062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>25</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.851361</td>\n",
       "      <td>0.848440</td>\n",
       "      <td>0.848566</td>\n",
       "      <td>0.848252</td>\n",
       "      <td>0.852962</td>\n",
       "      <td>0.851361</td>\n",
       "      <td>0.851935</td>\n",
       "      <td>298.643817</td>\n",
       "      <td>0.055504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>23</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.846762</td>\n",
       "      <td>0.843349</td>\n",
       "      <td>0.843441</td>\n",
       "      <td>0.843359</td>\n",
       "      <td>0.847245</td>\n",
       "      <td>0.846762</td>\n",
       "      <td>0.846971</td>\n",
       "      <td>781.179155</td>\n",
       "      <td>0.028593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>24</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.846762</td>\n",
       "      <td>0.843349</td>\n",
       "      <td>0.843441</td>\n",
       "      <td>0.843359</td>\n",
       "      <td>0.847245</td>\n",
       "      <td>0.846762</td>\n",
       "      <td>0.846971</td>\n",
       "      <td>782.790426</td>\n",
       "      <td>0.018706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>22</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.846762</td>\n",
       "      <td>0.843349</td>\n",
       "      <td>0.843441</td>\n",
       "      <td>0.843359</td>\n",
       "      <td>0.847245</td>\n",
       "      <td>0.846762</td>\n",
       "      <td>0.846971</td>\n",
       "      <td>778.936612</td>\n",
       "      <td>0.034014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>21</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.843819</td>\n",
       "      <td>0.839330</td>\n",
       "      <td>0.841394</td>\n",
       "      <td>0.840253</td>\n",
       "      <td>0.844736</td>\n",
       "      <td>0.843819</td>\n",
       "      <td>0.844164</td>\n",
       "      <td>795.160889</td>\n",
       "      <td>0.028470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>19</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.843819</td>\n",
       "      <td>0.839330</td>\n",
       "      <td>0.841394</td>\n",
       "      <td>0.840253</td>\n",
       "      <td>0.844736</td>\n",
       "      <td>0.843819</td>\n",
       "      <td>0.844164</td>\n",
       "      <td>796.420286</td>\n",
       "      <td>0.015622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>20</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.843819</td>\n",
       "      <td>0.839330</td>\n",
       "      <td>0.841394</td>\n",
       "      <td>0.840253</td>\n",
       "      <td>0.844736</td>\n",
       "      <td>0.843819</td>\n",
       "      <td>0.844164</td>\n",
       "      <td>795.091718</td>\n",
       "      <td>0.015624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>41</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.842347</td>\n",
       "      <td>0.843451</td>\n",
       "      <td>0.843335</td>\n",
       "      <td>0.841000</td>\n",
       "      <td>0.849975</td>\n",
       "      <td>0.842347</td>\n",
       "      <td>0.843951</td>\n",
       "      <td>5.503305</td>\n",
       "      <td>0.021775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>43</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.841611</td>\n",
       "      <td>0.842675</td>\n",
       "      <td>0.842552</td>\n",
       "      <td>0.840258</td>\n",
       "      <td>0.849185</td>\n",
       "      <td>0.841611</td>\n",
       "      <td>0.843222</td>\n",
       "      <td>6.422049</td>\n",
       "      <td>0.008978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>44</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.841244</td>\n",
       "      <td>0.842240</td>\n",
       "      <td>0.842142</td>\n",
       "      <td>0.839821</td>\n",
       "      <td>0.848847</td>\n",
       "      <td>0.841244</td>\n",
       "      <td>0.842855</td>\n",
       "      <td>19.012440</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.842159</td>\n",
       "      <td>0.840436</td>\n",
       "      <td>0.839503</td>\n",
       "      <td>0.847241</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.842535</td>\n",
       "      <td>5.576324</td>\n",
       "      <td>0.008976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.842091</td>\n",
       "      <td>0.840380</td>\n",
       "      <td>0.839454</td>\n",
       "      <td>0.847183</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.842518</td>\n",
       "      <td>21.771908</td>\n",
       "      <td>0.014956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>45</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840876</td>\n",
       "      <td>0.841909</td>\n",
       "      <td>0.840224</td>\n",
       "      <td>0.839291</td>\n",
       "      <td>0.847018</td>\n",
       "      <td>0.840876</td>\n",
       "      <td>0.842348</td>\n",
       "      <td>5.340970</td>\n",
       "      <td>0.015642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>46</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840876</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>0.840112</td>\n",
       "      <td>0.839207</td>\n",
       "      <td>0.846964</td>\n",
       "      <td>0.840876</td>\n",
       "      <td>0.842328</td>\n",
       "      <td>18.464855</td>\n",
       "      <td>0.015623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>28</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840876</td>\n",
       "      <td>0.841909</td>\n",
       "      <td>0.840224</td>\n",
       "      <td>0.839291</td>\n",
       "      <td>0.847018</td>\n",
       "      <td>0.840876</td>\n",
       "      <td>0.842348</td>\n",
       "      <td>5.417488</td>\n",
       "      <td>0.012994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>42</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840876</td>\n",
       "      <td>0.841805</td>\n",
       "      <td>0.841719</td>\n",
       "      <td>0.839428</td>\n",
       "      <td>0.848411</td>\n",
       "      <td>0.840876</td>\n",
       "      <td>0.842486</td>\n",
       "      <td>18.351558</td>\n",
       "      <td>0.013175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>23</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.841386</td>\n",
       "      <td>0.839653</td>\n",
       "      <td>0.838769</td>\n",
       "      <td>0.846408</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>23.224741</td>\n",
       "      <td>0.009976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.840558</td>\n",
       "      <td>0.839573</td>\n",
       "      <td>0.838628</td>\n",
       "      <td>0.845438</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.841585</td>\n",
       "      <td>15.506856</td>\n",
       "      <td>0.012964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.840558</td>\n",
       "      <td>0.839573</td>\n",
       "      <td>0.838628</td>\n",
       "      <td>0.845438</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.841585</td>\n",
       "      <td>12.305233</td>\n",
       "      <td>0.010972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>36</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.840558</td>\n",
       "      <td>0.839573</td>\n",
       "      <td>0.838628</td>\n",
       "      <td>0.845438</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.841585</td>\n",
       "      <td>14.098923</td>\n",
       "      <td>0.015635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>16</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.840558</td>\n",
       "      <td>0.839573</td>\n",
       "      <td>0.838628</td>\n",
       "      <td>0.845438</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.841585</td>\n",
       "      <td>13.989051</td>\n",
       "      <td>0.015855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>21</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.840558</td>\n",
       "      <td>0.839573</td>\n",
       "      <td>0.838628</td>\n",
       "      <td>0.845438</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.841585</td>\n",
       "      <td>14.308930</td>\n",
       "      <td>0.013964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>17</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.839368</td>\n",
       "      <td>0.838427</td>\n",
       "      <td>0.845295</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.841408</td>\n",
       "      <td>12.718502</td>\n",
       "      <td>0.010938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>35</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.839368</td>\n",
       "      <td>0.838427</td>\n",
       "      <td>0.845295</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.841408</td>\n",
       "      <td>200.899283</td>\n",
       "      <td>0.015624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>22</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.839368</td>\n",
       "      <td>0.838427</td>\n",
       "      <td>0.845295</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.841408</td>\n",
       "      <td>9.799134</td>\n",
       "      <td>0.009973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>36</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.839368</td>\n",
       "      <td>0.838427</td>\n",
       "      <td>0.845295</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.841408</td>\n",
       "      <td>200.049276</td>\n",
       "      <td>0.015622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>34</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.839368</td>\n",
       "      <td>0.838427</td>\n",
       "      <td>0.845295</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.841408</td>\n",
       "      <td>199.692308</td>\n",
       "      <td>0.031241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>37</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.839368</td>\n",
       "      <td>0.838427</td>\n",
       "      <td>0.845295</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.841408</td>\n",
       "      <td>12.603086</td>\n",
       "      <td>0.010977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>28</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.838435</td>\n",
       "      <td>0.837423</td>\n",
       "      <td>0.844282</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.840482</td>\n",
       "      <td>88.161083</td>\n",
       "      <td>0.015623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>29</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.838435</td>\n",
       "      <td>0.837423</td>\n",
       "      <td>0.844282</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.840482</td>\n",
       "      <td>87.565507</td>\n",
       "      <td>0.015622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>30</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.838435</td>\n",
       "      <td>0.837423</td>\n",
       "      <td>0.844282</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.840482</td>\n",
       "      <td>88.687985</td>\n",
       "      <td>0.015621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>40</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>38.394788</td>\n",
       "      <td>0.015597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>25</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>38.557558</td>\n",
       "      <td>0.010088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>24</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>17.293534</td>\n",
       "      <td>0.013934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>39</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>17.269594</td>\n",
       "      <td>0.015649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>20</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>38.496215</td>\n",
       "      <td>0.011003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>19</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>17.515083</td>\n",
       "      <td>0.010834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>68.931366</td>\n",
       "      <td>0.010004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>38.598322</td>\n",
       "      <td>0.008978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>17.214075</td>\n",
       "      <td>0.009957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>30</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>82.306628</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>32</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.838116</td>\n",
       "      <td>0.838511</td>\n",
       "      <td>0.837372</td>\n",
       "      <td>0.836459</td>\n",
       "      <td>0.843368</td>\n",
       "      <td>0.838116</td>\n",
       "      <td>0.839407</td>\n",
       "      <td>247.462588</td>\n",
       "      <td>0.023083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>31</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.838116</td>\n",
       "      <td>0.838511</td>\n",
       "      <td>0.837372</td>\n",
       "      <td>0.836459</td>\n",
       "      <td>0.843368</td>\n",
       "      <td>0.838116</td>\n",
       "      <td>0.839407</td>\n",
       "      <td>248.236446</td>\n",
       "      <td>0.034918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>33</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.838116</td>\n",
       "      <td>0.838511</td>\n",
       "      <td>0.837372</td>\n",
       "      <td>0.836459</td>\n",
       "      <td>0.843368</td>\n",
       "      <td>0.838116</td>\n",
       "      <td>0.839407</td>\n",
       "      <td>247.590544</td>\n",
       "      <td>0.012203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>16</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.836093</td>\n",
       "      <td>0.837645</td>\n",
       "      <td>0.831404</td>\n",
       "      <td>0.833585</td>\n",
       "      <td>0.839010</td>\n",
       "      <td>0.836093</td>\n",
       "      <td>0.836690</td>\n",
       "      <td>4.029616</td>\n",
       "      <td>0.014935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.834069</td>\n",
       "      <td>0.834626</td>\n",
       "      <td>0.836840</td>\n",
       "      <td>0.832263</td>\n",
       "      <td>0.844515</td>\n",
       "      <td>0.834069</td>\n",
       "      <td>0.835920</td>\n",
       "      <td>22.352235</td>\n",
       "      <td>0.191946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.830942</td>\n",
       "      <td>0.829928</td>\n",
       "      <td>0.831651</td>\n",
       "      <td>0.828433</td>\n",
       "      <td>0.839454</td>\n",
       "      <td>0.830942</td>\n",
       "      <td>0.832917</td>\n",
       "      <td>8.440806</td>\n",
       "      <td>0.200967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.830942</td>\n",
       "      <td>0.831682</td>\n",
       "      <td>0.834008</td>\n",
       "      <td>0.829157</td>\n",
       "      <td>0.842568</td>\n",
       "      <td>0.830942</td>\n",
       "      <td>0.833112</td>\n",
       "      <td>32.840074</td>\n",
       "      <td>0.184439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                   model  accuracy  media precision  media recall  \\\n",
       "60       9    KNeighborsClassifier  0.856880         0.854537      0.851830   \n",
       "61       7    KNeighborsClassifier  0.856880         0.854537      0.851830   \n",
       "62      21   KNeighborsClassifier   0.856880         0.854537      0.851830   \n",
       "63      15   KNeighborsClassifier   0.856880         0.854537      0.851830   \n",
       "64      19   KNeighborsClassifier   0.856880         0.854537      0.851830   \n",
       "65      17   KNeighborsClassifier   0.856880         0.854537      0.851830   \n",
       "66      79   KNeighborsClassifier   0.853017         0.854480      0.845563   \n",
       "67      81   KNeighborsClassifier   0.853017         0.854480      0.845563   \n",
       "68      83   KNeighborsClassifier   0.853017         0.854480      0.845563   \n",
       "69      77   KNeighborsClassifier   0.853017         0.854480      0.845563   \n",
       "70      27          MLPClassifier   0.851361         0.848440      0.848566   \n",
       "71      26          MLPClassifier   0.851361         0.848440      0.848566   \n",
       "72      25          MLPClassifier   0.851361         0.848440      0.848566   \n",
       "73      23          MLPClassifier   0.846762         0.843349      0.843441   \n",
       "74      24          MLPClassifier   0.846762         0.843349      0.843441   \n",
       "75      22          MLPClassifier   0.846762         0.843349      0.843441   \n",
       "76      21          MLPClassifier   0.843819         0.839330      0.841394   \n",
       "77      19          MLPClassifier   0.843819         0.839330      0.841394   \n",
       "78      20          MLPClassifier   0.843819         0.839330      0.841394   \n",
       "79      41     LogisticRegression   0.842347         0.843451      0.843335   \n",
       "80      43     LogisticRegression   0.841611         0.842675      0.842552   \n",
       "81      44     LogisticRegression   0.841244         0.842240      0.842142   \n",
       "82       8      LogisticRegression  0.841060         0.842159      0.840436   \n",
       "83       3      LogisticRegression  0.841060         0.842091      0.840380   \n",
       "84      45     LogisticRegression   0.840876         0.841909      0.840224   \n",
       "85      46     LogisticRegression   0.840876         0.841838      0.840112   \n",
       "86      28     LogisticRegression   0.840876         0.841909      0.840224   \n",
       "87      42     LogisticRegression   0.840876         0.841805      0.841719   \n",
       "88      23     LogisticRegression   0.840324         0.841386      0.839653   \n",
       "89       1      LogisticRegression  0.840324         0.840558      0.839573   \n",
       "90       2      LogisticRegression  0.840324         0.840558      0.839573   \n",
       "91      36     LogisticRegression   0.840324         0.840558      0.839573   \n",
       "92      16     LogisticRegression   0.840324         0.840558      0.839573   \n",
       "93      21     LogisticRegression   0.840324         0.840558      0.839573   \n",
       "94      17     LogisticRegression   0.840140         0.840395      0.839368   \n",
       "95      35          MLPClassifier   0.840140         0.840395      0.839368   \n",
       "96      22     LogisticRegression   0.840140         0.840395      0.839368   \n",
       "97      36          MLPClassifier   0.840140         0.840395      0.839368   \n",
       "98      34          MLPClassifier   0.840140         0.840395      0.839368   \n",
       "99      37     LogisticRegression   0.840140         0.840395      0.839368   \n",
       "100     28          MLPClassifier   0.839220         0.839220      0.838435   \n",
       "101     29          MLPClassifier   0.839220         0.839220      0.838435   \n",
       "102     30          MLPClassifier   0.839220         0.839220      0.838435   \n",
       "103     40     LogisticRegression   0.839036         0.839229      0.838130   \n",
       "104     25     LogisticRegression   0.839036         0.839229      0.838130   \n",
       "105     24     LogisticRegression   0.839036         0.839229      0.838130   \n",
       "106     39     LogisticRegression   0.839036         0.839229      0.838130   \n",
       "107     20     LogisticRegression   0.839036         0.839229      0.838130   \n",
       "108     19     LogisticRegression   0.839036         0.839229      0.838130   \n",
       "109     10     LogisticRegression   0.839036         0.839229      0.838130   \n",
       "110      5      LogisticRegression  0.839036         0.839229      0.838130   \n",
       "111      4      LogisticRegression  0.839036         0.839229      0.838130   \n",
       "112     30     LogisticRegression   0.839036         0.839229      0.838130   \n",
       "113     32          MLPClassifier   0.838116         0.838511      0.837372   \n",
       "114     31          MLPClassifier   0.838116         0.838511      0.837372   \n",
       "115     33          MLPClassifier   0.838116         0.838511      0.837372   \n",
       "116     16          SGDClassifier   0.836093         0.837645      0.831404   \n",
       "117      3  RandomForestClassifier  0.834069         0.834626      0.836840   \n",
       "118      7    ExtraTreesClassifier  0.830942         0.829928      0.831651   \n",
       "119      2  RandomForestClassifier  0.830942         0.831682      0.834008   \n",
       "\n",
       "     media f1-score  media ponderada precision  media ponderada recall  \\\n",
       "60         0.852997                   0.857339                0.856880   \n",
       "61         0.852997                   0.857339                0.856880   \n",
       "62         0.852997                   0.857339                0.856880   \n",
       "63         0.852997                   0.857339                0.856880   \n",
       "64         0.852997                   0.857339                0.856880   \n",
       "65         0.852997                   0.857339                0.856880   \n",
       "66         0.849229                   0.853952                0.853017   \n",
       "67         0.849229                   0.853952                0.853017   \n",
       "68         0.849229                   0.853952                0.853017   \n",
       "69         0.849229                   0.853952                0.853017   \n",
       "70         0.848252                   0.852962                0.851361   \n",
       "71         0.848252                   0.852962                0.851361   \n",
       "72         0.848252                   0.852962                0.851361   \n",
       "73         0.843359                   0.847245                0.846762   \n",
       "74         0.843359                   0.847245                0.846762   \n",
       "75         0.843359                   0.847245                0.846762   \n",
       "76         0.840253                   0.844736                0.843819   \n",
       "77         0.840253                   0.844736                0.843819   \n",
       "78         0.840253                   0.844736                0.843819   \n",
       "79         0.841000                   0.849975                0.842347   \n",
       "80         0.840258                   0.849185                0.841611   \n",
       "81         0.839821                   0.848847                0.841244   \n",
       "82         0.839503                   0.847241                0.841060   \n",
       "83         0.839454                   0.847183                0.841060   \n",
       "84         0.839291                   0.847018                0.840876   \n",
       "85         0.839207                   0.846964                0.840876   \n",
       "86         0.839291                   0.847018                0.840876   \n",
       "87         0.839428                   0.848411                0.840876   \n",
       "88         0.838769                   0.846408                0.840324   \n",
       "89         0.838628                   0.845438                0.840324   \n",
       "90         0.838628                   0.845438                0.840324   \n",
       "91         0.838628                   0.845438                0.840324   \n",
       "92         0.838628                   0.845438                0.840324   \n",
       "93         0.838628                   0.845438                0.840324   \n",
       "94         0.838427                   0.845295                0.840140   \n",
       "95         0.838427                   0.845295                0.840140   \n",
       "96         0.838427                   0.845295                0.840140   \n",
       "97         0.838427                   0.845295                0.840140   \n",
       "98         0.838427                   0.845295                0.840140   \n",
       "99         0.838427                   0.845295                0.840140   \n",
       "100        0.837423                   0.844282                0.839220   \n",
       "101        0.837423                   0.844282                0.839220   \n",
       "102        0.837423                   0.844282                0.839220   \n",
       "103        0.837228                   0.844115                0.839036   \n",
       "104        0.837228                   0.844115                0.839036   \n",
       "105        0.837228                   0.844115                0.839036   \n",
       "106        0.837228                   0.844115                0.839036   \n",
       "107        0.837228                   0.844115                0.839036   \n",
       "108        0.837228                   0.844115                0.839036   \n",
       "109        0.837228                   0.844115                0.839036   \n",
       "110        0.837228                   0.844115                0.839036   \n",
       "111        0.837228                   0.844115                0.839036   \n",
       "112        0.837228                   0.844115                0.839036   \n",
       "113        0.836459                   0.843368                0.838116   \n",
       "114        0.836459                   0.843368                0.838116   \n",
       "115        0.836459                   0.843368                0.838116   \n",
       "116        0.833585                   0.839010                0.836093   \n",
       "117        0.832263                   0.844515                0.834069   \n",
       "118        0.828433                   0.839454                0.830942   \n",
       "119        0.829157                   0.842568                0.830942   \n",
       "\n",
       "     media ponderada f1-score   tempo fit  tempo predict  \n",
       "60                   0.856932    3.602799      81.478564  \n",
       "61                   0.856932    2.621779      59.485099  \n",
       "62                   0.856932    3.614048      82.147169  \n",
       "63                   0.856932    3.536194      81.705079  \n",
       "64                   0.856932    2.674072      59.336886  \n",
       "65                   0.856932    0.027099       2.162479  \n",
       "66                   0.852657    0.035496     100.371877  \n",
       "67                   0.852657    2.524588     108.853681  \n",
       "68                   0.852657    0.037769     100.132839  \n",
       "69                   0.852657    2.582238     108.852259  \n",
       "70                   0.851935  295.903128       0.065385  \n",
       "71                   0.851935  296.846067       0.068062  \n",
       "72                   0.851935  298.643817       0.055504  \n",
       "73                   0.846971  781.179155       0.028593  \n",
       "74                   0.846971  782.790426       0.018706  \n",
       "75                   0.846971  778.936612       0.034014  \n",
       "76                   0.844164  795.160889       0.028470  \n",
       "77                   0.844164  796.420286       0.015622  \n",
       "78                   0.844164  795.091718       0.015624  \n",
       "79                   0.843951    5.503305       0.021775  \n",
       "80                   0.843222    6.422049       0.008978  \n",
       "81                   0.842855   19.012440       0.000000  \n",
       "82                   0.842535    5.576324       0.008976  \n",
       "83                   0.842518   21.771908       0.014956  \n",
       "84                   0.842348    5.340970       0.015642  \n",
       "85                   0.842328   18.464855       0.015623  \n",
       "86                   0.842348    5.417488       0.012994  \n",
       "87                   0.842486   18.351558       0.013175  \n",
       "88                   0.841791   23.224741       0.009976  \n",
       "89                   0.841585   15.506856       0.012964  \n",
       "90                   0.841585   12.305233       0.010972  \n",
       "91                   0.841585   14.098923       0.015635  \n",
       "92                   0.841585   13.989051       0.015855  \n",
       "93                   0.841585   14.308930       0.013964  \n",
       "94                   0.841408   12.718502       0.010938  \n",
       "95                   0.841408  200.899283       0.015624  \n",
       "96                   0.841408    9.799134       0.009973  \n",
       "97                   0.841408  200.049276       0.015622  \n",
       "98                   0.841408  199.692308       0.031241  \n",
       "99                   0.841408   12.603086       0.010977  \n",
       "100                  0.840482   88.161083       0.015623  \n",
       "101                  0.840482   87.565507       0.015622  \n",
       "102                  0.840482   88.687985       0.015621  \n",
       "103                  0.840270   38.394788       0.015597  \n",
       "104                  0.840270   38.557558       0.010088  \n",
       "105                  0.840270   17.293534       0.013934  \n",
       "106                  0.840270   17.269594       0.015649  \n",
       "107                  0.840270   38.496215       0.011003  \n",
       "108                  0.840270   17.515083       0.010834  \n",
       "109                  0.840270   68.931366       0.010004  \n",
       "110                  0.840270   38.598322       0.008978  \n",
       "111                  0.840270   17.214075       0.009957  \n",
       "112                  0.840270   82.306628       0.000000  \n",
       "113                  0.839407  247.462588       0.023083  \n",
       "114                  0.839407  248.236446       0.034918  \n",
       "115                  0.839407  247.590544       0.012203  \n",
       "116                  0.836690    4.029616       0.014935  \n",
       "117                  0.835920   22.352235       0.191946  \n",
       "118                  0.832917    8.440806       0.200967  \n",
       "119                  0.833112   32.840074       0.184439  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_metricas_modelos.dropna().sort_values(by=['accuracy'],ascending=False).reset_index(drop=False)[60:120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 piores fi-score geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T01:19:48.782016Z",
     "start_time": "2020-09-21T01:19:48.763076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>media precision</th>\n",
       "      <th>media recall</th>\n",
       "      <th>media f1-score</th>\n",
       "      <th>media ponderada precision</th>\n",
       "      <th>media ponderada recall</th>\n",
       "      <th>media ponderada f1-score</th>\n",
       "      <th>tempo fit</th>\n",
       "      <th>tempo predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.655813</td>\n",
       "      <td>0.704017</td>\n",
       "      <td>0.682515</td>\n",
       "      <td>0.657349</td>\n",
       "      <td>0.726818</td>\n",
       "      <td>0.655813</td>\n",
       "      <td>0.651434</td>\n",
       "      <td>0.011921</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>4</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.655813</td>\n",
       "      <td>0.704017</td>\n",
       "      <td>0.682515</td>\n",
       "      <td>0.657349</td>\n",
       "      <td>0.726818</td>\n",
       "      <td>0.655813</td>\n",
       "      <td>0.651434</td>\n",
       "      <td>0.037762</td>\n",
       "      <td>0.009975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.662436</td>\n",
       "      <td>0.656639</td>\n",
       "      <td>0.657211</td>\n",
       "      <td>0.656877</td>\n",
       "      <td>0.663267</td>\n",
       "      <td>0.662436</td>\n",
       "      <td>0.662805</td>\n",
       "      <td>0.258929</td>\n",
       "      <td>0.015926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.657469</td>\n",
       "      <td>0.650561</td>\n",
       "      <td>0.651001</td>\n",
       "      <td>0.650693</td>\n",
       "      <td>0.658803</td>\n",
       "      <td>0.657469</td>\n",
       "      <td>0.658051</td>\n",
       "      <td>0.171860</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>14</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.645511</td>\n",
       "      <td>0.485123</td>\n",
       "      <td>0.600357</td>\n",
       "      <td>0.523310</td>\n",
       "      <td>0.495820</td>\n",
       "      <td>0.645511</td>\n",
       "      <td>0.546858</td>\n",
       "      <td>243.919468</td>\n",
       "      <td>0.044364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>15</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.645511</td>\n",
       "      <td>0.485123</td>\n",
       "      <td>0.600357</td>\n",
       "      <td>0.523310</td>\n",
       "      <td>0.495820</td>\n",
       "      <td>0.645511</td>\n",
       "      <td>0.546858</td>\n",
       "      <td>245.062117</td>\n",
       "      <td>0.029921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>13</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.645511</td>\n",
       "      <td>0.485123</td>\n",
       "      <td>0.600357</td>\n",
       "      <td>0.523310</td>\n",
       "      <td>0.495820</td>\n",
       "      <td>0.645511</td>\n",
       "      <td>0.546858</td>\n",
       "      <td>244.065341</td>\n",
       "      <td>0.031241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>4</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.645511</td>\n",
       "      <td>0.485123</td>\n",
       "      <td>0.600357</td>\n",
       "      <td>0.523310</td>\n",
       "      <td>0.495820</td>\n",
       "      <td>0.645511</td>\n",
       "      <td>0.546858</td>\n",
       "      <td>243.787861</td>\n",
       "      <td>0.031245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>5</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.645511</td>\n",
       "      <td>0.485123</td>\n",
       "      <td>0.600357</td>\n",
       "      <td>0.523310</td>\n",
       "      <td>0.495820</td>\n",
       "      <td>0.645511</td>\n",
       "      <td>0.546858</td>\n",
       "      <td>242.884969</td>\n",
       "      <td>0.031243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>6</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.645511</td>\n",
       "      <td>0.485123</td>\n",
       "      <td>0.600357</td>\n",
       "      <td>0.523310</td>\n",
       "      <td>0.495820</td>\n",
       "      <td>0.645511</td>\n",
       "      <td>0.546858</td>\n",
       "      <td>243.016130</td>\n",
       "      <td>0.036901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                   model  accuracy  media precision  media recall  \\\n",
       "177      2           MultinomialNB  0.655813         0.704017      0.682515   \n",
       "178      4           MultinomialNB  0.655813         0.704017      0.682515   \n",
       "179      6  DecisionTreeClassifier  0.662436         0.656639      0.657211   \n",
       "180      3  DecisionTreeClassifier  0.657469         0.650561      0.651001   \n",
       "181     14          MLPClassifier   0.645511         0.485123      0.600357   \n",
       "182     15          MLPClassifier   0.645511         0.485123      0.600357   \n",
       "183     13          MLPClassifier   0.645511         0.485123      0.600357   \n",
       "184      4           MLPClassifier  0.645511         0.485123      0.600357   \n",
       "185      5           MLPClassifier  0.645511         0.485123      0.600357   \n",
       "186      6           MLPClassifier  0.645511         0.485123      0.600357   \n",
       "\n",
       "     media f1-score  media ponderada precision  media ponderada recall  \\\n",
       "177        0.657349                   0.726818                0.655813   \n",
       "178        0.657349                   0.726818                0.655813   \n",
       "179        0.656877                   0.663267                0.662436   \n",
       "180        0.650693                   0.658803                0.657469   \n",
       "181        0.523310                   0.495820                0.645511   \n",
       "182        0.523310                   0.495820                0.645511   \n",
       "183        0.523310                   0.495820                0.645511   \n",
       "184        0.523310                   0.495820                0.645511   \n",
       "185        0.523310                   0.495820                0.645511   \n",
       "186        0.523310                   0.495820                0.645511   \n",
       "\n",
       "     media ponderada f1-score   tempo fit  tempo predict  \n",
       "177                  0.651434    0.011921       0.000000  \n",
       "178                  0.651434    0.037762       0.009975  \n",
       "179                  0.662805    0.258929       0.015926  \n",
       "180                  0.658051    0.171860       0.000000  \n",
       "181                  0.546858  243.919468       0.044364  \n",
       "182                  0.546858  245.062117       0.029921  \n",
       "183                  0.546858  244.065341       0.031241  \n",
       "184                  0.546858  243.787861       0.031245  \n",
       "185                  0.546858  242.884969       0.031243  \n",
       "186                  0.546858  243.016130       0.036901  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_metricas_modelos.sort_values(by=['media f1-score'],ascending=False).reset_index(drop=False).tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50 melhores tempos de fit geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T01:19:49.167926Z",
     "start_time": "2020-09-21T01:19:49.139835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>media precision</th>\n",
       "      <th>media recall</th>\n",
       "      <th>media f1-score</th>\n",
       "      <th>media ponderada precision</th>\n",
       "      <th>media ponderada recall</th>\n",
       "      <th>media ponderada f1-score</th>\n",
       "      <th>tempo fit</th>\n",
       "      <th>tempo predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.655813</td>\n",
       "      <td>0.704017</td>\n",
       "      <td>0.682515</td>\n",
       "      <td>0.657349</td>\n",
       "      <td>0.726818</td>\n",
       "      <td>0.655813</td>\n",
       "      <td>0.651434</td>\n",
       "      <td>0.011921</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.803716</td>\n",
       "      <td>0.800377</td>\n",
       "      <td>0.797787</td>\n",
       "      <td>0.798698</td>\n",
       "      <td>0.805042</td>\n",
       "      <td>0.803716</td>\n",
       "      <td>0.804033</td>\n",
       "      <td>0.025927</td>\n",
       "      <td>50.855635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.803716</td>\n",
       "      <td>0.800377</td>\n",
       "      <td>0.797787</td>\n",
       "      <td>0.798698</td>\n",
       "      <td>0.805042</td>\n",
       "      <td>0.803716</td>\n",
       "      <td>0.804033</td>\n",
       "      <td>0.026132</td>\n",
       "      <td>50.922834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>0.026929</td>\n",
       "      <td>50.943763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>0.026929</td>\n",
       "      <td>1.939642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>0.026941</td>\n",
       "      <td>2.180462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>0.026942</td>\n",
       "      <td>2.032678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>0.026961</td>\n",
       "      <td>51.084528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.854537</td>\n",
       "      <td>0.851830</td>\n",
       "      <td>0.852997</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.856932</td>\n",
       "      <td>0.027099</td>\n",
       "      <td>2.162479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.854537</td>\n",
       "      <td>0.851830</td>\n",
       "      <td>0.852997</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.856932</td>\n",
       "      <td>0.027233</td>\n",
       "      <td>2.006593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>0.027902</td>\n",
       "      <td>50.809997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>76</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>0.027922</td>\n",
       "      <td>51.050041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>84</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.858519</td>\n",
       "      <td>0.855271</td>\n",
       "      <td>0.856723</td>\n",
       "      <td>0.861420</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.861185</td>\n",
       "      <td>0.027959</td>\n",
       "      <td>99.976362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>47</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.794886</td>\n",
       "      <td>0.795669</td>\n",
       "      <td>0.787047</td>\n",
       "      <td>0.790345</td>\n",
       "      <td>0.796584</td>\n",
       "      <td>0.794886</td>\n",
       "      <td>0.794728</td>\n",
       "      <td>0.028122</td>\n",
       "      <td>51.102064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>88</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.876904</td>\n",
       "      <td>0.874532</td>\n",
       "      <td>0.875048</td>\n",
       "      <td>0.881079</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.879332</td>\n",
       "      <td>0.028922</td>\n",
       "      <td>52.933302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>92</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.876904</td>\n",
       "      <td>0.874532</td>\n",
       "      <td>0.875048</td>\n",
       "      <td>0.881079</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.879332</td>\n",
       "      <td>0.029968</td>\n",
       "      <td>52.743143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>0.030155</td>\n",
       "      <td>51.067972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.854537</td>\n",
       "      <td>0.851830</td>\n",
       "      <td>0.852997</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.856932</td>\n",
       "      <td>0.030532</td>\n",
       "      <td>2.145015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>0.671450</td>\n",
       "      <td>0.715326</td>\n",
       "      <td>0.696206</td>\n",
       "      <td>0.672266</td>\n",
       "      <td>0.740077</td>\n",
       "      <td>0.671450</td>\n",
       "      <td>0.668347</td>\n",
       "      <td>0.031245</td>\n",
       "      <td>0.009974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>0.031952</td>\n",
       "      <td>50.991324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>0.671450</td>\n",
       "      <td>0.715326</td>\n",
       "      <td>0.696206</td>\n",
       "      <td>0.672266</td>\n",
       "      <td>0.740077</td>\n",
       "      <td>0.671450</td>\n",
       "      <td>0.668347</td>\n",
       "      <td>0.032409</td>\n",
       "      <td>0.008981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>80</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.858519</td>\n",
       "      <td>0.855271</td>\n",
       "      <td>0.856723</td>\n",
       "      <td>0.861420</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.861185</td>\n",
       "      <td>0.032888</td>\n",
       "      <td>100.127405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>79</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.853017</td>\n",
       "      <td>0.854480</td>\n",
       "      <td>0.845563</td>\n",
       "      <td>0.849229</td>\n",
       "      <td>0.853952</td>\n",
       "      <td>0.853017</td>\n",
       "      <td>0.852657</td>\n",
       "      <td>0.035496</td>\n",
       "      <td>100.371877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>91</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871357</td>\n",
       "      <td>0.865837</td>\n",
       "      <td>0.867745</td>\n",
       "      <td>0.873307</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871305</td>\n",
       "      <td>0.035696</td>\n",
       "      <td>53.158206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>69</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>0.036127</td>\n",
       "      <td>51.156095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>87</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871357</td>\n",
       "      <td>0.865837</td>\n",
       "      <td>0.867745</td>\n",
       "      <td>0.873307</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871305</td>\n",
       "      <td>0.036204</td>\n",
       "      <td>52.918117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>29</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>0.036803</td>\n",
       "      <td>50.997628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.655813</td>\n",
       "      <td>0.704017</td>\n",
       "      <td>0.682515</td>\n",
       "      <td>0.657349</td>\n",
       "      <td>0.726818</td>\n",
       "      <td>0.655813</td>\n",
       "      <td>0.651434</td>\n",
       "      <td>0.037762</td>\n",
       "      <td>0.009975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>83</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.853017</td>\n",
       "      <td>0.854480</td>\n",
       "      <td>0.845563</td>\n",
       "      <td>0.849229</td>\n",
       "      <td>0.853952</td>\n",
       "      <td>0.853017</td>\n",
       "      <td>0.852657</td>\n",
       "      <td>0.037769</td>\n",
       "      <td>100.132839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>75</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>0.038763</td>\n",
       "      <td>51.064413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>41</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.794886</td>\n",
       "      <td>0.795669</td>\n",
       "      <td>0.787047</td>\n",
       "      <td>0.790345</td>\n",
       "      <td>0.796584</td>\n",
       "      <td>0.794886</td>\n",
       "      <td>0.794728</td>\n",
       "      <td>0.040032</td>\n",
       "      <td>51.129493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>35</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>0.041656</td>\n",
       "      <td>51.460521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.657469</td>\n",
       "      <td>0.650561</td>\n",
       "      <td>0.651001</td>\n",
       "      <td>0.650693</td>\n",
       "      <td>0.658803</td>\n",
       "      <td>0.657469</td>\n",
       "      <td>0.658051</td>\n",
       "      <td>0.171860</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.654709</td>\n",
       "      <td>0.701288</td>\n",
       "      <td>0.679464</td>\n",
       "      <td>0.659472</td>\n",
       "      <td>0.720004</td>\n",
       "      <td>0.654709</td>\n",
       "      <td>0.653697</td>\n",
       "      <td>0.206432</td>\n",
       "      <td>0.149932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.662436</td>\n",
       "      <td>0.656639</td>\n",
       "      <td>0.657211</td>\n",
       "      <td>0.656877</td>\n",
       "      <td>0.663267</td>\n",
       "      <td>0.662436</td>\n",
       "      <td>0.662805</td>\n",
       "      <td>0.258929</td>\n",
       "      <td>0.015926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.687270</td>\n",
       "      <td>0.681176</td>\n",
       "      <td>0.681094</td>\n",
       "      <td>0.681024</td>\n",
       "      <td>0.688472</td>\n",
       "      <td>0.687270</td>\n",
       "      <td>0.687771</td>\n",
       "      <td>0.431020</td>\n",
       "      <td>0.018953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.690397</td>\n",
       "      <td>0.683491</td>\n",
       "      <td>0.683747</td>\n",
       "      <td>0.683611</td>\n",
       "      <td>0.690317</td>\n",
       "      <td>0.690397</td>\n",
       "      <td>0.690350</td>\n",
       "      <td>0.541649</td>\n",
       "      <td>0.015926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>44</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.804820</td>\n",
       "      <td>0.801404</td>\n",
       "      <td>0.798851</td>\n",
       "      <td>0.799760</td>\n",
       "      <td>0.806104</td>\n",
       "      <td>0.804820</td>\n",
       "      <td>0.805131</td>\n",
       "      <td>2.521029</td>\n",
       "      <td>46.440407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>81</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.853017</td>\n",
       "      <td>0.854480</td>\n",
       "      <td>0.845563</td>\n",
       "      <td>0.849229</td>\n",
       "      <td>0.853952</td>\n",
       "      <td>0.853017</td>\n",
       "      <td>0.852657</td>\n",
       "      <td>2.524588</td>\n",
       "      <td>108.853681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>89</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871357</td>\n",
       "      <td>0.865837</td>\n",
       "      <td>0.867745</td>\n",
       "      <td>0.873307</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871305</td>\n",
       "      <td>2.536995</td>\n",
       "      <td>59.317578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>65</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>2.537957</td>\n",
       "      <td>57.757765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>72</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>2.547346</td>\n",
       "      <td>57.543360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>32</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>2.548194</td>\n",
       "      <td>57.532639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>25</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>2.552751</td>\n",
       "      <td>57.553232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.854537</td>\n",
       "      <td>0.851830</td>\n",
       "      <td>0.852997</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.856932</td>\n",
       "      <td>2.554566</td>\n",
       "      <td>59.358503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>2.563508</td>\n",
       "      <td>59.151893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>20</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>2.581278</td>\n",
       "      <td>59.302167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>77</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.853017</td>\n",
       "      <td>0.854480</td>\n",
       "      <td>0.845563</td>\n",
       "      <td>0.849229</td>\n",
       "      <td>0.853952</td>\n",
       "      <td>0.853017</td>\n",
       "      <td>0.852657</td>\n",
       "      <td>2.582238</td>\n",
       "      <td>108.852259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>2.594816</td>\n",
       "      <td>58.036513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>26</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>2.615837</td>\n",
       "      <td>57.614316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                   model  accuracy  media precision  media recall  \\\n",
       "0       2           MultinomialNB  0.655813         0.704017      0.682515   \n",
       "1      48   KNeighborsClassifier   0.803716         0.800377      0.797787   \n",
       "2      42   KNeighborsClassifier   0.803716         0.800377      0.797787   \n",
       "3      36   KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "4      12   KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "5      24   KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "6      18   KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "7      70   KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "8      17   KNeighborsClassifier   0.856880         0.854537      0.851830   \n",
       "9      23   KNeighborsClassifier   0.856880         0.854537      0.851830   \n",
       "10     30   KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "11     76   KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "12     84   KNeighborsClassifier   0.861295         0.858519      0.855271   \n",
       "13     47   KNeighborsClassifier   0.794886         0.795669      0.787047   \n",
       "14     88   KNeighborsClassifier   0.878771         0.876904      0.874532   \n",
       "15     92   KNeighborsClassifier   0.878771         0.876904      0.874532   \n",
       "16      5    KNeighborsClassifier  0.858168         0.856143      0.852967   \n",
       "17     11   KNeighborsClassifier   0.856880         0.854537      0.851830   \n",
       "18      3            ComplementNB  0.671450         0.715326      0.696206   \n",
       "19      6    KNeighborsClassifier  0.865526         0.860896      0.861536   \n",
       "20      5            ComplementNB  0.671450         0.715326      0.696206   \n",
       "21     80   KNeighborsClassifier   0.861295         0.858519      0.855271   \n",
       "22     79   KNeighborsClassifier   0.853017         0.854480      0.845563   \n",
       "23     91   KNeighborsClassifier   0.870861         0.871357      0.865837   \n",
       "24     69   KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "25     87   KNeighborsClassifier   0.870861         0.871357      0.865837   \n",
       "26     29   KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "27      4           MultinomialNB  0.655813         0.704017      0.682515   \n",
       "28     83   KNeighborsClassifier   0.853017         0.854480      0.845563   \n",
       "29     75   KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "30     41   KNeighborsClassifier   0.794886         0.795669      0.787047   \n",
       "31     35   KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "32      3  DecisionTreeClassifier  0.657469         0.650561      0.651001   \n",
       "33      1              GaussianNB  0.654709         0.701288      0.679464   \n",
       "34      6  DecisionTreeClassifier  0.662436         0.656639      0.657211   \n",
       "35      2  DecisionTreeClassifier  0.687270         0.681176      0.681094   \n",
       "36      5  DecisionTreeClassifier  0.690397         0.683491      0.683747   \n",
       "37     44   KNeighborsClassifier   0.804820         0.801404      0.798851   \n",
       "38     81   KNeighborsClassifier   0.853017         0.854480      0.845563   \n",
       "39     89   KNeighborsClassifier   0.870861         0.871357      0.865837   \n",
       "40     65   KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "41     72   KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "42     32   KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "43     25   KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "44     13   KNeighborsClassifier   0.856880         0.854537      0.851830   \n",
       "45      8    KNeighborsClassifier  0.865710         0.861384      0.861755   \n",
       "46     20   KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "47     77   KNeighborsClassifier   0.853017         0.854480      0.845563   \n",
       "48      1    KNeighborsClassifier  0.858168         0.856143      0.852967   \n",
       "49     26   KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "\n",
       "    media f1-score  media ponderada precision  media ponderada recall  \\\n",
       "0         0.657349                   0.726818                0.655813   \n",
       "1         0.798698                   0.805042                0.803716   \n",
       "2         0.798698                   0.805042                0.803716   \n",
       "3         0.861201                   0.865854                0.865526   \n",
       "4         0.861432                   0.866630                0.865710   \n",
       "5         0.861432                   0.866630                0.865710   \n",
       "6         0.861432                   0.866630                0.865710   \n",
       "7         0.861201                   0.865854                0.865526   \n",
       "8         0.852997                   0.857339                0.856880   \n",
       "9         0.852997                   0.857339                0.856880   \n",
       "10        0.861201                   0.865854                0.865526   \n",
       "11        0.861201                   0.865854                0.865526   \n",
       "12        0.856723                   0.861420                0.861295   \n",
       "13        0.790345                   0.796584                0.794886   \n",
       "14        0.875048                   0.881079                0.878771   \n",
       "15        0.875048                   0.881079                0.878771   \n",
       "16        0.854429                   0.858018                0.858168   \n",
       "17        0.852997                   0.857339                0.856880   \n",
       "18        0.672266                   0.740077                0.671450   \n",
       "19        0.861201                   0.865854                0.865526   \n",
       "20        0.672266                   0.740077                0.671450   \n",
       "21        0.856723                   0.861420                0.861295   \n",
       "22        0.849229                   0.853952                0.853017   \n",
       "23        0.867745                   0.873307                0.870861   \n",
       "24        0.854429                   0.858018                0.858168   \n",
       "25        0.867745                   0.873307                0.870861   \n",
       "26        0.854429                   0.858018                0.858168   \n",
       "27        0.657349                   0.726818                0.655813   \n",
       "28        0.849229                   0.853952                0.853017   \n",
       "29        0.854429                   0.858018                0.858168   \n",
       "30        0.790345                   0.796584                0.794886   \n",
       "31        0.854429                   0.858018                0.858168   \n",
       "32        0.650693                   0.658803                0.657469   \n",
       "33        0.659472                   0.720004                0.654709   \n",
       "34        0.656877                   0.663267                0.662436   \n",
       "35        0.681024                   0.688472                0.687270   \n",
       "36        0.683611                   0.690317                0.690397   \n",
       "37        0.799760                   0.806104                0.804820   \n",
       "38        0.849229                   0.853952                0.853017   \n",
       "39        0.867745                   0.873307                0.870861   \n",
       "40        0.854429                   0.858018                0.858168   \n",
       "41        0.861201                   0.865854                0.865526   \n",
       "42        0.861201                   0.865854                0.865526   \n",
       "43        0.854429                   0.858018                0.858168   \n",
       "44        0.852997                   0.857339                0.856880   \n",
       "45        0.861432                   0.866630                0.865710   \n",
       "46        0.861432                   0.866630                0.865710   \n",
       "47        0.849229                   0.853952                0.853017   \n",
       "48        0.854429                   0.858018                0.858168   \n",
       "49        0.861201                   0.865854                0.865526   \n",
       "\n",
       "    media ponderada f1-score  tempo fit  tempo predict  \n",
       "0                   0.651434   0.011921       0.000000  \n",
       "1                   0.804033   0.025927      50.855635  \n",
       "2                   0.804033   0.026132      50.922834  \n",
       "3                   0.865675   0.026929      50.943763  \n",
       "4                   0.866047   0.026929       1.939642  \n",
       "5                   0.866047   0.026941       2.180462  \n",
       "6                   0.866047   0.026942       2.032678  \n",
       "7                   0.865675   0.026961      51.084528  \n",
       "8                   0.856932   0.027099       2.162479  \n",
       "9                   0.856932   0.027233       2.006593  \n",
       "10                  0.865675   0.027902      50.809997  \n",
       "11                  0.865675   0.027922      51.050041  \n",
       "12                  0.861185   0.027959      99.976362  \n",
       "13                  0.794728   0.028122      51.102064  \n",
       "14                  0.879332   0.028922      52.933302  \n",
       "15                  0.879332   0.029968      52.743143  \n",
       "16                  0.857959   0.030155      51.067972  \n",
       "17                  0.856932   0.030532       2.145015  \n",
       "18                  0.668347   0.031245       0.009974  \n",
       "19                  0.865675   0.031952      50.991324  \n",
       "20                  0.668347   0.032409       0.008981  \n",
       "21                  0.861185   0.032888     100.127405  \n",
       "22                  0.852657   0.035496     100.371877  \n",
       "23                  0.871305   0.035696      53.158206  \n",
       "24                  0.857959   0.036127      51.156095  \n",
       "25                  0.871305   0.036204      52.918117  \n",
       "26                  0.857959   0.036803      50.997628  \n",
       "27                  0.651434   0.037762       0.009975  \n",
       "28                  0.852657   0.037769     100.132839  \n",
       "29                  0.857959   0.038763      51.064413  \n",
       "30                  0.794728   0.040032      51.129493  \n",
       "31                  0.857959   0.041656      51.460521  \n",
       "32                  0.658051   0.171860       0.000000  \n",
       "33                  0.653697   0.206432       0.149932  \n",
       "34                  0.662805   0.258929       0.015926  \n",
       "35                  0.687771   0.431020       0.018953  \n",
       "36                  0.690350   0.541649       0.015926  \n",
       "37                  0.805131   2.521029      46.440407  \n",
       "38                  0.852657   2.524588     108.853681  \n",
       "39                  0.871305   2.536995      59.317578  \n",
       "40                  0.857959   2.537957      57.757765  \n",
       "41                  0.865675   2.547346      57.543360  \n",
       "42                  0.865675   2.548194      57.532639  \n",
       "43                  0.857959   2.552751      57.553232  \n",
       "44                  0.856932   2.554566      59.358503  \n",
       "45                  0.866047   2.563508      59.151893  \n",
       "46                  0.866047   2.581278      59.302167  \n",
       "47                  0.852657   2.582238     108.852259  \n",
       "48                  0.857959   2.594816      58.036513  \n",
       "49                  0.865675   2.615837      57.614316  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_metricas_modelos.sort_values(by=['tempo fit'],ascending=True).reset_index(drop=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50 melhores tempos de predict geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T01:19:49.526921Z",
     "start_time": "2020-09-21T01:19:49.492687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>media precision</th>\n",
       "      <th>media recall</th>\n",
       "      <th>media f1-score</th>\n",
       "      <th>media ponderada precision</th>\n",
       "      <th>media ponderada recall</th>\n",
       "      <th>media ponderada f1-score</th>\n",
       "      <th>tempo fit</th>\n",
       "      <th>tempo predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>82.306628</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.841244</td>\n",
       "      <td>0.842240</td>\n",
       "      <td>0.842142</td>\n",
       "      <td>0.839821</td>\n",
       "      <td>0.848847</td>\n",
       "      <td>0.841244</td>\n",
       "      <td>0.842855</td>\n",
       "      <td>19.012440</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.657469</td>\n",
       "      <td>0.650561</td>\n",
       "      <td>0.651001</td>\n",
       "      <td>0.650693</td>\n",
       "      <td>0.658803</td>\n",
       "      <td>0.657469</td>\n",
       "      <td>0.658051</td>\n",
       "      <td>0.171860</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.811258</td>\n",
       "      <td>0.806286</td>\n",
       "      <td>0.807612</td>\n",
       "      <td>0.806837</td>\n",
       "      <td>0.812522</td>\n",
       "      <td>0.811258</td>\n",
       "      <td>0.811778</td>\n",
       "      <td>54.311285</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.655813</td>\n",
       "      <td>0.704017</td>\n",
       "      <td>0.682515</td>\n",
       "      <td>0.657349</td>\n",
       "      <td>0.726818</td>\n",
       "      <td>0.655813</td>\n",
       "      <td>0.651434</td>\n",
       "      <td>0.011921</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.860762</td>\n",
       "      <td>0.857728</td>\n",
       "      <td>0.858958</td>\n",
       "      <td>0.862484</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.862535</td>\n",
       "      <td>141.878605</td>\n",
       "      <td>0.008004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.842159</td>\n",
       "      <td>0.840436</td>\n",
       "      <td>0.839503</td>\n",
       "      <td>0.847241</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.842535</td>\n",
       "      <td>5.576324</td>\n",
       "      <td>0.008976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>38.598322</td>\n",
       "      <td>0.008978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>43</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.841611</td>\n",
       "      <td>0.842675</td>\n",
       "      <td>0.842552</td>\n",
       "      <td>0.840258</td>\n",
       "      <td>0.849185</td>\n",
       "      <td>0.841611</td>\n",
       "      <td>0.843222</td>\n",
       "      <td>6.422049</td>\n",
       "      <td>0.008978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.804084</td>\n",
       "      <td>0.799338</td>\n",
       "      <td>0.798517</td>\n",
       "      <td>0.798913</td>\n",
       "      <td>0.803798</td>\n",
       "      <td>0.804084</td>\n",
       "      <td>0.803925</td>\n",
       "      <td>58.237993</td>\n",
       "      <td>0.008979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>0.671450</td>\n",
       "      <td>0.715326</td>\n",
       "      <td>0.696206</td>\n",
       "      <td>0.672266</td>\n",
       "      <td>0.740077</td>\n",
       "      <td>0.671450</td>\n",
       "      <td>0.668347</td>\n",
       "      <td>0.032409</td>\n",
       "      <td>0.008981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.860762</td>\n",
       "      <td>0.857728</td>\n",
       "      <td>0.858958</td>\n",
       "      <td>0.862484</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.862535</td>\n",
       "      <td>141.549502</td>\n",
       "      <td>0.009053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>17.214075</td>\n",
       "      <td>0.009957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>22</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.839368</td>\n",
       "      <td>0.838427</td>\n",
       "      <td>0.845295</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.841408</td>\n",
       "      <td>9.799134</td>\n",
       "      <td>0.009973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>0.671450</td>\n",
       "      <td>0.715326</td>\n",
       "      <td>0.696206</td>\n",
       "      <td>0.672266</td>\n",
       "      <td>0.740077</td>\n",
       "      <td>0.671450</td>\n",
       "      <td>0.668347</td>\n",
       "      <td>0.031245</td>\n",
       "      <td>0.009974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.655813</td>\n",
       "      <td>0.704017</td>\n",
       "      <td>0.682515</td>\n",
       "      <td>0.657349</td>\n",
       "      <td>0.726818</td>\n",
       "      <td>0.655813</td>\n",
       "      <td>0.651434</td>\n",
       "      <td>0.037762</td>\n",
       "      <td>0.009975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>23</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.841386</td>\n",
       "      <td>0.839653</td>\n",
       "      <td>0.838769</td>\n",
       "      <td>0.846408</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>23.224741</td>\n",
       "      <td>0.009976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>68.931366</td>\n",
       "      <td>0.010004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.814386</td>\n",
       "      <td>0.816741</td>\n",
       "      <td>0.804264</td>\n",
       "      <td>0.808349</td>\n",
       "      <td>0.814772</td>\n",
       "      <td>0.814386</td>\n",
       "      <td>0.812426</td>\n",
       "      <td>10.927740</td>\n",
       "      <td>0.010056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>25</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>38.557558</td>\n",
       "      <td>0.010088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>17.515083</td>\n",
       "      <td>0.010834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>17</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.839368</td>\n",
       "      <td>0.838427</td>\n",
       "      <td>0.845295</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.841408</td>\n",
       "      <td>12.718502</td>\n",
       "      <td>0.010938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.840558</td>\n",
       "      <td>0.839573</td>\n",
       "      <td>0.838628</td>\n",
       "      <td>0.845438</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.841585</td>\n",
       "      <td>12.305233</td>\n",
       "      <td>0.010972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>37</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.839368</td>\n",
       "      <td>0.838427</td>\n",
       "      <td>0.845295</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.841408</td>\n",
       "      <td>12.603086</td>\n",
       "      <td>0.010977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>38.496215</td>\n",
       "      <td>0.011003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.834775</td>\n",
       "      <td>0.827934</td>\n",
       "      <td>0.822757</td>\n",
       "      <td>0.843891</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.824408</td>\n",
       "      <td>8.097779</td>\n",
       "      <td>0.011061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>33</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.838116</td>\n",
       "      <td>0.838511</td>\n",
       "      <td>0.837372</td>\n",
       "      <td>0.836459</td>\n",
       "      <td>0.843368</td>\n",
       "      <td>0.838116</td>\n",
       "      <td>0.839407</td>\n",
       "      <td>247.590544</td>\n",
       "      <td>0.012203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.840558</td>\n",
       "      <td>0.839573</td>\n",
       "      <td>0.838628</td>\n",
       "      <td>0.845438</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.841585</td>\n",
       "      <td>15.506856</td>\n",
       "      <td>0.012964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.808315</td>\n",
       "      <td>0.804124</td>\n",
       "      <td>0.802351</td>\n",
       "      <td>0.803169</td>\n",
       "      <td>0.807754</td>\n",
       "      <td>0.808315</td>\n",
       "      <td>0.807963</td>\n",
       "      <td>59.313666</td>\n",
       "      <td>0.012967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>28</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840876</td>\n",
       "      <td>0.841909</td>\n",
       "      <td>0.840224</td>\n",
       "      <td>0.839291</td>\n",
       "      <td>0.847018</td>\n",
       "      <td>0.840876</td>\n",
       "      <td>0.842348</td>\n",
       "      <td>5.417488</td>\n",
       "      <td>0.012994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.784400</td>\n",
       "      <td>0.790348</td>\n",
       "      <td>0.770603</td>\n",
       "      <td>0.774826</td>\n",
       "      <td>0.786064</td>\n",
       "      <td>0.784400</td>\n",
       "      <td>0.779693</td>\n",
       "      <td>6.012268</td>\n",
       "      <td>0.012997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.788815</td>\n",
       "      <td>0.796103</td>\n",
       "      <td>0.771925</td>\n",
       "      <td>0.772972</td>\n",
       "      <td>0.793282</td>\n",
       "      <td>0.788815</td>\n",
       "      <td>0.780787</td>\n",
       "      <td>6.687698</td>\n",
       "      <td>0.013131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>42</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840876</td>\n",
       "      <td>0.841805</td>\n",
       "      <td>0.841719</td>\n",
       "      <td>0.839428</td>\n",
       "      <td>0.848411</td>\n",
       "      <td>0.840876</td>\n",
       "      <td>0.842486</td>\n",
       "      <td>18.351558</td>\n",
       "      <td>0.013175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>24</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>17.293534</td>\n",
       "      <td>0.013934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>21</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.840558</td>\n",
       "      <td>0.839573</td>\n",
       "      <td>0.838628</td>\n",
       "      <td>0.845438</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.841585</td>\n",
       "      <td>14.308930</td>\n",
       "      <td>0.013964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.745401</td>\n",
       "      <td>0.757049</td>\n",
       "      <td>0.728619</td>\n",
       "      <td>0.718156</td>\n",
       "      <td>0.758928</td>\n",
       "      <td>0.745401</td>\n",
       "      <td>0.730324</td>\n",
       "      <td>6.059869</td>\n",
       "      <td>0.013968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>14</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.825706</td>\n",
       "      <td>0.830420</td>\n",
       "      <td>0.826170</td>\n",
       "      <td>0.834503</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.829226</td>\n",
       "      <td>18.485370</td>\n",
       "      <td>0.014082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>16</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.836093</td>\n",
       "      <td>0.837645</td>\n",
       "      <td>0.831404</td>\n",
       "      <td>0.833585</td>\n",
       "      <td>0.839010</td>\n",
       "      <td>0.836093</td>\n",
       "      <td>0.836690</td>\n",
       "      <td>4.029616</td>\n",
       "      <td>0.014935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.719647</td>\n",
       "      <td>0.714036</td>\n",
       "      <td>0.713175</td>\n",
       "      <td>0.713543</td>\n",
       "      <td>0.720183</td>\n",
       "      <td>0.719647</td>\n",
       "      <td>0.719859</td>\n",
       "      <td>10.546990</td>\n",
       "      <td>0.014935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.842091</td>\n",
       "      <td>0.840380</td>\n",
       "      <td>0.839454</td>\n",
       "      <td>0.847183</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.842518</td>\n",
       "      <td>21.771908</td>\n",
       "      <td>0.014956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>11</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.860762</td>\n",
       "      <td>0.857728</td>\n",
       "      <td>0.858958</td>\n",
       "      <td>0.862484</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.862535</td>\n",
       "      <td>142.108870</td>\n",
       "      <td>0.015042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>40</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>38.394788</td>\n",
       "      <td>0.015597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.714128</td>\n",
       "      <td>0.730229</td>\n",
       "      <td>0.694659</td>\n",
       "      <td>0.677315</td>\n",
       "      <td>0.732378</td>\n",
       "      <td>0.714128</td>\n",
       "      <td>0.692203</td>\n",
       "      <td>91.281964</td>\n",
       "      <td>0.015619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>12</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.816961</td>\n",
       "      <td>0.812689</td>\n",
       "      <td>0.815374</td>\n",
       "      <td>0.813903</td>\n",
       "      <td>0.817399</td>\n",
       "      <td>0.816961</td>\n",
       "      <td>0.817045</td>\n",
       "      <td>17.029957</td>\n",
       "      <td>0.015619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>9</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.809676</td>\n",
       "      <td>0.811562</td>\n",
       "      <td>0.810402</td>\n",
       "      <td>0.816345</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.815240</td>\n",
       "      <td>57.376844</td>\n",
       "      <td>0.015620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>30</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.838435</td>\n",
       "      <td>0.837423</td>\n",
       "      <td>0.844282</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.840482</td>\n",
       "      <td>88.687985</td>\n",
       "      <td>0.015621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>29</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.838435</td>\n",
       "      <td>0.837423</td>\n",
       "      <td>0.844282</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.840482</td>\n",
       "      <td>87.565507</td>\n",
       "      <td>0.015622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>19</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.843819</td>\n",
       "      <td>0.839330</td>\n",
       "      <td>0.841394</td>\n",
       "      <td>0.840253</td>\n",
       "      <td>0.844736</td>\n",
       "      <td>0.843819</td>\n",
       "      <td>0.844164</td>\n",
       "      <td>796.420286</td>\n",
       "      <td>0.015622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>36</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.839368</td>\n",
       "      <td>0.838427</td>\n",
       "      <td>0.845295</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.841408</td>\n",
       "      <td>200.049276</td>\n",
       "      <td>0.015622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>28</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.838435</td>\n",
       "      <td>0.837423</td>\n",
       "      <td>0.844282</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.840482</td>\n",
       "      <td>88.161083</td>\n",
       "      <td>0.015623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                   model  accuracy  media precision  media recall  \\\n",
       "0      30     LogisticRegression   0.839036         0.839229      0.838130   \n",
       "1      44     LogisticRegression   0.841244         0.842240      0.842142   \n",
       "2       3  DecisionTreeClassifier  0.657469         0.650561      0.651001   \n",
       "3       8           SGDClassifier  0.811258         0.806286      0.807612   \n",
       "4       2           MultinomialNB  0.655813         0.704017      0.682515   \n",
       "5       2           MLPClassifier  0.863135         0.860762      0.857728   \n",
       "6       8      LogisticRegression  0.841060         0.842159      0.840436   \n",
       "7       5      LogisticRegression  0.839036         0.839229      0.838130   \n",
       "8      43     LogisticRegression   0.841611         0.842675      0.842552   \n",
       "9       7           SGDClassifier  0.804084         0.799338      0.798517   \n",
       "10      5            ComplementNB  0.671450         0.715326      0.696206   \n",
       "11     10          MLPClassifier   0.863135         0.860762      0.857728   \n",
       "12      4      LogisticRegression  0.839036         0.839229      0.838130   \n",
       "13     22     LogisticRegression   0.840140         0.840395      0.839368   \n",
       "14      3            ComplementNB  0.671450         0.715326      0.696206   \n",
       "15      4           MultinomialNB  0.655813         0.704017      0.682515   \n",
       "16     23     LogisticRegression   0.840324         0.841386      0.839653   \n",
       "17     10     LogisticRegression   0.839036         0.839229      0.838130   \n",
       "18     17          SGDClassifier   0.814386         0.816741      0.804264   \n",
       "19     25     LogisticRegression   0.839036         0.839229      0.838130   \n",
       "20     19     LogisticRegression   0.839036         0.839229      0.838130   \n",
       "21     17     LogisticRegression   0.840140         0.840395      0.839368   \n",
       "22      2      LogisticRegression  0.840324         0.840558      0.839573   \n",
       "23     37     LogisticRegression   0.840140         0.840395      0.839368   \n",
       "24     20     LogisticRegression   0.839036         0.839229      0.838130   \n",
       "25      1           SGDClassifier  0.821192         0.834775      0.827934   \n",
       "26     33          MLPClassifier   0.838116         0.838511      0.837372   \n",
       "27      1      LogisticRegression  0.840324         0.840558      0.839573   \n",
       "28      6           SGDClassifier  0.808315         0.804124      0.802351   \n",
       "29     28     LogisticRegression   0.840876         0.841909      0.840224   \n",
       "30      4           SGDClassifier  0.784400         0.790348      0.770603   \n",
       "31      5           SGDClassifier  0.788815         0.796103      0.771925   \n",
       "32     42     LogisticRegression   0.840876         0.841805      0.841719   \n",
       "33     24     LogisticRegression   0.839036         0.839229      0.838130   \n",
       "34     21     LogisticRegression   0.840324         0.840558      0.839573   \n",
       "35      3           SGDClassifier  0.745401         0.757049      0.728619   \n",
       "36     14          SGDClassifier   0.827815         0.825706      0.830420   \n",
       "37     16          SGDClassifier   0.836093         0.837645      0.831404   \n",
       "38      4  DecisionTreeClassifier  0.719647         0.714036      0.713175   \n",
       "39      3      LogisticRegression  0.841060         0.842091      0.840380   \n",
       "40     11          MLPClassifier   0.863135         0.860762      0.857728   \n",
       "41     40     LogisticRegression   0.839036         0.839229      0.838130   \n",
       "42      3               LinearSVC  0.714128         0.730229      0.694659   \n",
       "43     12          SGDClassifier   0.816961         0.812689      0.815374   \n",
       "44      9           SGDClassifier  0.814570         0.809676      0.811562   \n",
       "45     30          MLPClassifier   0.839220         0.839220      0.838435   \n",
       "46     29          MLPClassifier   0.839220         0.839220      0.838435   \n",
       "47     19          MLPClassifier   0.843819         0.839330      0.841394   \n",
       "48     36          MLPClassifier   0.840140         0.840395      0.839368   \n",
       "49     28          MLPClassifier   0.839220         0.839220      0.838435   \n",
       "\n",
       "    media f1-score  media ponderada precision  media ponderada recall  \\\n",
       "0         0.837228                   0.844115                0.839036   \n",
       "1         0.839821                   0.848847                0.841244   \n",
       "2         0.650693                   0.658803                0.657469   \n",
       "3         0.806837                   0.812522                0.811258   \n",
       "4         0.657349                   0.726818                0.655813   \n",
       "5         0.858958                   0.862484                0.863135   \n",
       "6         0.839503                   0.847241                0.841060   \n",
       "7         0.837228                   0.844115                0.839036   \n",
       "8         0.840258                   0.849185                0.841611   \n",
       "9         0.798913                   0.803798                0.804084   \n",
       "10        0.672266                   0.740077                0.671450   \n",
       "11        0.858958                   0.862484                0.863135   \n",
       "12        0.837228                   0.844115                0.839036   \n",
       "13        0.838427                   0.845295                0.840140   \n",
       "14        0.672266                   0.740077                0.671450   \n",
       "15        0.657349                   0.726818                0.655813   \n",
       "16        0.838769                   0.846408                0.840324   \n",
       "17        0.837228                   0.844115                0.839036   \n",
       "18        0.808349                   0.814772                0.814386   \n",
       "19        0.837228                   0.844115                0.839036   \n",
       "20        0.837228                   0.844115                0.839036   \n",
       "21        0.838427                   0.845295                0.840140   \n",
       "22        0.838628                   0.845438                0.840324   \n",
       "23        0.838427                   0.845295                0.840140   \n",
       "24        0.837228                   0.844115                0.839036   \n",
       "25        0.822757                   0.843891                0.821192   \n",
       "26        0.836459                   0.843368                0.838116   \n",
       "27        0.838628                   0.845438                0.840324   \n",
       "28        0.803169                   0.807754                0.808315   \n",
       "29        0.839291                   0.847018                0.840876   \n",
       "30        0.774826                   0.786064                0.784400   \n",
       "31        0.772972                   0.793282                0.788815   \n",
       "32        0.839428                   0.848411                0.840876   \n",
       "33        0.837228                   0.844115                0.839036   \n",
       "34        0.838628                   0.845438                0.840324   \n",
       "35        0.718156                   0.758928                0.745401   \n",
       "36        0.826170                   0.834503                0.827815   \n",
       "37        0.833585                   0.839010                0.836093   \n",
       "38        0.713543                   0.720183                0.719647   \n",
       "39        0.839454                   0.847183                0.841060   \n",
       "40        0.858958                   0.862484                0.863135   \n",
       "41        0.837228                   0.844115                0.839036   \n",
       "42        0.677315                   0.732378                0.714128   \n",
       "43        0.813903                   0.817399                0.816961   \n",
       "44        0.810402                   0.816345                0.814570   \n",
       "45        0.837423                   0.844282                0.839220   \n",
       "46        0.837423                   0.844282                0.839220   \n",
       "47        0.840253                   0.844736                0.843819   \n",
       "48        0.838427                   0.845295                0.840140   \n",
       "49        0.837423                   0.844282                0.839220   \n",
       "\n",
       "    media ponderada f1-score   tempo fit  tempo predict  \n",
       "0                   0.840270   82.306628       0.000000  \n",
       "1                   0.842855   19.012440       0.000000  \n",
       "2                   0.658051    0.171860       0.000000  \n",
       "3                   0.811778   54.311285       0.000000  \n",
       "4                   0.651434    0.011921       0.000000  \n",
       "5                   0.862535  141.878605       0.008004  \n",
       "6                   0.842535    5.576324       0.008976  \n",
       "7                   0.840270   38.598322       0.008978  \n",
       "8                   0.843222    6.422049       0.008978  \n",
       "9                   0.803925   58.237993       0.008979  \n",
       "10                  0.668347    0.032409       0.008981  \n",
       "11                  0.862535  141.549502       0.009053  \n",
       "12                  0.840270   17.214075       0.009957  \n",
       "13                  0.841408    9.799134       0.009973  \n",
       "14                  0.668347    0.031245       0.009974  \n",
       "15                  0.651434    0.037762       0.009975  \n",
       "16                  0.841791   23.224741       0.009976  \n",
       "17                  0.840270   68.931366       0.010004  \n",
       "18                  0.812426   10.927740       0.010056  \n",
       "19                  0.840270   38.557558       0.010088  \n",
       "20                  0.840270   17.515083       0.010834  \n",
       "21                  0.841408   12.718502       0.010938  \n",
       "22                  0.841585   12.305233       0.010972  \n",
       "23                  0.841408   12.603086       0.010977  \n",
       "24                  0.840270   38.496215       0.011003  \n",
       "25                  0.824408    8.097779       0.011061  \n",
       "26                  0.839407  247.590544       0.012203  \n",
       "27                  0.841585   15.506856       0.012964  \n",
       "28                  0.807963   59.313666       0.012967  \n",
       "29                  0.842348    5.417488       0.012994  \n",
       "30                  0.779693    6.012268       0.012997  \n",
       "31                  0.780787    6.687698       0.013131  \n",
       "32                  0.842486   18.351558       0.013175  \n",
       "33                  0.840270   17.293534       0.013934  \n",
       "34                  0.841585   14.308930       0.013964  \n",
       "35                  0.730324    6.059869       0.013968  \n",
       "36                  0.829226   18.485370       0.014082  \n",
       "37                  0.836690    4.029616       0.014935  \n",
       "38                  0.719859   10.546990       0.014935  \n",
       "39                  0.842518   21.771908       0.014956  \n",
       "40                  0.862535  142.108870       0.015042  \n",
       "41                  0.840270   38.394788       0.015597  \n",
       "42                  0.692203   91.281964       0.015619  \n",
       "43                  0.817045   17.029957       0.015619  \n",
       "44                  0.815240   57.376844       0.015620  \n",
       "45                  0.840482   88.687985       0.015621  \n",
       "46                  0.840482   87.565507       0.015622  \n",
       "47                  0.844164  796.420286       0.015622  \n",
       "48                  0.841408  200.049276       0.015622  \n",
       "49                  0.840482   88.161083       0.015623  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_metricas_modelos.sort_values(by=[\"tempo predict\"],ascending=True).reset_index(drop=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50 melhores tempos de fit para acurácia acima de 82%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T16:55:02.318642Z",
     "start_time": "2020-09-21T16:55:02.286698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>media precision</th>\n",
       "      <th>media recall</th>\n",
       "      <th>media f1-score</th>\n",
       "      <th>media ponderada precision</th>\n",
       "      <th>media ponderada recall</th>\n",
       "      <th>media ponderada f1-score</th>\n",
       "      <th>tempo fit</th>\n",
       "      <th>tempo predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>0.026929</td>\n",
       "      <td>50.943763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>0.026929</td>\n",
       "      <td>1.939642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>0.026941</td>\n",
       "      <td>2.180462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>0.026942</td>\n",
       "      <td>2.032678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>0.026961</td>\n",
       "      <td>51.084528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.854537</td>\n",
       "      <td>0.851830</td>\n",
       "      <td>0.852997</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.856932</td>\n",
       "      <td>0.027099</td>\n",
       "      <td>2.162479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.854537</td>\n",
       "      <td>0.851830</td>\n",
       "      <td>0.852997</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.856932</td>\n",
       "      <td>0.027233</td>\n",
       "      <td>2.006593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>0.027902</td>\n",
       "      <td>50.809997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>76</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>0.027922</td>\n",
       "      <td>51.050041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.858519</td>\n",
       "      <td>0.855271</td>\n",
       "      <td>0.856723</td>\n",
       "      <td>0.861420</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.861185</td>\n",
       "      <td>0.027959</td>\n",
       "      <td>99.976362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>88</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.876904</td>\n",
       "      <td>0.874532</td>\n",
       "      <td>0.875048</td>\n",
       "      <td>0.881079</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.879332</td>\n",
       "      <td>0.028922</td>\n",
       "      <td>52.933302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>92</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.876904</td>\n",
       "      <td>0.874532</td>\n",
       "      <td>0.875048</td>\n",
       "      <td>0.881079</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.879332</td>\n",
       "      <td>0.029968</td>\n",
       "      <td>52.743143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>0.030155</td>\n",
       "      <td>51.067972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.854537</td>\n",
       "      <td>0.851830</td>\n",
       "      <td>0.852997</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.856932</td>\n",
       "      <td>0.030532</td>\n",
       "      <td>2.145015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>0.031952</td>\n",
       "      <td>50.991324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>80</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.858519</td>\n",
       "      <td>0.855271</td>\n",
       "      <td>0.856723</td>\n",
       "      <td>0.861420</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.861185</td>\n",
       "      <td>0.032888</td>\n",
       "      <td>100.127405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>79</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.853017</td>\n",
       "      <td>0.854480</td>\n",
       "      <td>0.845563</td>\n",
       "      <td>0.849229</td>\n",
       "      <td>0.853952</td>\n",
       "      <td>0.853017</td>\n",
       "      <td>0.852657</td>\n",
       "      <td>0.035496</td>\n",
       "      <td>100.371877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>91</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871357</td>\n",
       "      <td>0.865837</td>\n",
       "      <td>0.867745</td>\n",
       "      <td>0.873307</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871305</td>\n",
       "      <td>0.035696</td>\n",
       "      <td>53.158206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>69</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>0.036127</td>\n",
       "      <td>51.156095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>87</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871357</td>\n",
       "      <td>0.865837</td>\n",
       "      <td>0.867745</td>\n",
       "      <td>0.873307</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871305</td>\n",
       "      <td>0.036204</td>\n",
       "      <td>52.918117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>29</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>0.036803</td>\n",
       "      <td>50.997628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>83</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.853017</td>\n",
       "      <td>0.854480</td>\n",
       "      <td>0.845563</td>\n",
       "      <td>0.849229</td>\n",
       "      <td>0.853952</td>\n",
       "      <td>0.853017</td>\n",
       "      <td>0.852657</td>\n",
       "      <td>0.037769</td>\n",
       "      <td>100.132839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>75</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>0.038763</td>\n",
       "      <td>51.064413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>35</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>0.041656</td>\n",
       "      <td>51.460521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>81</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.853017</td>\n",
       "      <td>0.854480</td>\n",
       "      <td>0.845563</td>\n",
       "      <td>0.849229</td>\n",
       "      <td>0.853952</td>\n",
       "      <td>0.853017</td>\n",
       "      <td>0.852657</td>\n",
       "      <td>2.524588</td>\n",
       "      <td>108.853681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>89</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871357</td>\n",
       "      <td>0.865837</td>\n",
       "      <td>0.867745</td>\n",
       "      <td>0.873307</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871305</td>\n",
       "      <td>2.536995</td>\n",
       "      <td>59.317578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>65</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>2.537957</td>\n",
       "      <td>57.757765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>72</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>2.547346</td>\n",
       "      <td>57.543360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>32</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>2.548194</td>\n",
       "      <td>57.532639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>25</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>2.552751</td>\n",
       "      <td>57.553232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.854537</td>\n",
       "      <td>0.851830</td>\n",
       "      <td>0.852997</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.856932</td>\n",
       "      <td>2.554566</td>\n",
       "      <td>59.358503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>2.563508</td>\n",
       "      <td>59.151893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>2.581278</td>\n",
       "      <td>59.302167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>77</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.853017</td>\n",
       "      <td>0.854480</td>\n",
       "      <td>0.845563</td>\n",
       "      <td>0.849229</td>\n",
       "      <td>0.853952</td>\n",
       "      <td>0.853017</td>\n",
       "      <td>0.852657</td>\n",
       "      <td>2.582238</td>\n",
       "      <td>108.852259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>2.594816</td>\n",
       "      <td>58.036513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>26</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>2.615837</td>\n",
       "      <td>57.614316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.854537</td>\n",
       "      <td>0.851830</td>\n",
       "      <td>0.852997</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.856932</td>\n",
       "      <td>2.621779</td>\n",
       "      <td>59.485099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>66</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>2.622460</td>\n",
       "      <td>57.814443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>31</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>2.629065</td>\n",
       "      <td>57.619833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>78</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.858519</td>\n",
       "      <td>0.855271</td>\n",
       "      <td>0.856723</td>\n",
       "      <td>0.861420</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.861185</td>\n",
       "      <td>2.639398</td>\n",
       "      <td>108.707143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.860896</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>2.646696</td>\n",
       "      <td>57.516279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>90</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.876904</td>\n",
       "      <td>0.874532</td>\n",
       "      <td>0.875048</td>\n",
       "      <td>0.881079</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.879332</td>\n",
       "      <td>2.650857</td>\n",
       "      <td>59.318689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.861755</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.866630</td>\n",
       "      <td>0.865710</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>2.654883</td>\n",
       "      <td>59.306390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>86</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.876904</td>\n",
       "      <td>0.874532</td>\n",
       "      <td>0.875048</td>\n",
       "      <td>0.881079</td>\n",
       "      <td>0.878771</td>\n",
       "      <td>0.879332</td>\n",
       "      <td>2.657073</td>\n",
       "      <td>59.128510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>71</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>2.662820</td>\n",
       "      <td>58.174034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>19</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.854537</td>\n",
       "      <td>0.851830</td>\n",
       "      <td>0.852997</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.856932</td>\n",
       "      <td>2.674072</td>\n",
       "      <td>59.336886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>82</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.858519</td>\n",
       "      <td>0.855271</td>\n",
       "      <td>0.856723</td>\n",
       "      <td>0.861420</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.861185</td>\n",
       "      <td>2.719545</td>\n",
       "      <td>108.352238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>85</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871357</td>\n",
       "      <td>0.865837</td>\n",
       "      <td>0.867745</td>\n",
       "      <td>0.873307</td>\n",
       "      <td>0.870861</td>\n",
       "      <td>0.871305</td>\n",
       "      <td>2.737489</td>\n",
       "      <td>59.118438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>15</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.854537</td>\n",
       "      <td>0.851830</td>\n",
       "      <td>0.852997</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>0.856932</td>\n",
       "      <td>3.536194</td>\n",
       "      <td>81.705079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.858018</td>\n",
       "      <td>0.858168</td>\n",
       "      <td>0.857959</td>\n",
       "      <td>3.537591</td>\n",
       "      <td>68.764618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                  model  accuracy  media precision  media recall  \\\n",
       "0      36  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "1      12  KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "2      24  KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "3      18  KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "4      70  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "5      17  KNeighborsClassifier   0.856880         0.854537      0.851830   \n",
       "6      23  KNeighborsClassifier   0.856880         0.854537      0.851830   \n",
       "7      30  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "8      76  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "9      84  KNeighborsClassifier   0.861295         0.858519      0.855271   \n",
       "10     88  KNeighborsClassifier   0.878771         0.876904      0.874532   \n",
       "11     92  KNeighborsClassifier   0.878771         0.876904      0.874532   \n",
       "12      5   KNeighborsClassifier  0.858168         0.856143      0.852967   \n",
       "13     11  KNeighborsClassifier   0.856880         0.854537      0.851830   \n",
       "14      6   KNeighborsClassifier  0.865526         0.860896      0.861536   \n",
       "15     80  KNeighborsClassifier   0.861295         0.858519      0.855271   \n",
       "16     79  KNeighborsClassifier   0.853017         0.854480      0.845563   \n",
       "17     91  KNeighborsClassifier   0.870861         0.871357      0.865837   \n",
       "18     69  KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "19     87  KNeighborsClassifier   0.870861         0.871357      0.865837   \n",
       "20     29  KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "21     83  KNeighborsClassifier   0.853017         0.854480      0.845563   \n",
       "22     75  KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "23     35  KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "24     81  KNeighborsClassifier   0.853017         0.854480      0.845563   \n",
       "25     89  KNeighborsClassifier   0.870861         0.871357      0.865837   \n",
       "26     65  KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "27     72  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "28     32  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "29     25  KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "30     13  KNeighborsClassifier   0.856880         0.854537      0.851830   \n",
       "31      8   KNeighborsClassifier  0.865710         0.861384      0.861755   \n",
       "32     20  KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "33     77  KNeighborsClassifier   0.853017         0.854480      0.845563   \n",
       "34      1   KNeighborsClassifier  0.858168         0.856143      0.852967   \n",
       "35     26  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "36      7   KNeighborsClassifier  0.856880         0.854537      0.851830   \n",
       "37     66  KNeighborsClassifier   0.865526         0.860896      0.861536   \n",
       "38     31  KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "39     78  KNeighborsClassifier   0.861295         0.858519      0.855271   \n",
       "40      2   KNeighborsClassifier  0.865526         0.860896      0.861536   \n",
       "41     90  KNeighborsClassifier   0.878771         0.876904      0.874532   \n",
       "42     14  KNeighborsClassifier   0.865710         0.861384      0.861755   \n",
       "43     86  KNeighborsClassifier   0.878771         0.876904      0.874532   \n",
       "44     71  KNeighborsClassifier   0.858168         0.856143      0.852967   \n",
       "45     19  KNeighborsClassifier   0.856880         0.854537      0.851830   \n",
       "46     82  KNeighborsClassifier   0.861295         0.858519      0.855271   \n",
       "47     85  KNeighborsClassifier   0.870861         0.871357      0.865837   \n",
       "48     15  KNeighborsClassifier   0.856880         0.854537      0.851830   \n",
       "49      3   KNeighborsClassifier  0.858168         0.856143      0.852967   \n",
       "\n",
       "    media f1-score  media ponderada precision  media ponderada recall  \\\n",
       "0         0.861201                   0.865854                0.865526   \n",
       "1         0.861432                   0.866630                0.865710   \n",
       "2         0.861432                   0.866630                0.865710   \n",
       "3         0.861432                   0.866630                0.865710   \n",
       "4         0.861201                   0.865854                0.865526   \n",
       "5         0.852997                   0.857339                0.856880   \n",
       "6         0.852997                   0.857339                0.856880   \n",
       "7         0.861201                   0.865854                0.865526   \n",
       "8         0.861201                   0.865854                0.865526   \n",
       "9         0.856723                   0.861420                0.861295   \n",
       "10        0.875048                   0.881079                0.878771   \n",
       "11        0.875048                   0.881079                0.878771   \n",
       "12        0.854429                   0.858018                0.858168   \n",
       "13        0.852997                   0.857339                0.856880   \n",
       "14        0.861201                   0.865854                0.865526   \n",
       "15        0.856723                   0.861420                0.861295   \n",
       "16        0.849229                   0.853952                0.853017   \n",
       "17        0.867745                   0.873307                0.870861   \n",
       "18        0.854429                   0.858018                0.858168   \n",
       "19        0.867745                   0.873307                0.870861   \n",
       "20        0.854429                   0.858018                0.858168   \n",
       "21        0.849229                   0.853952                0.853017   \n",
       "22        0.854429                   0.858018                0.858168   \n",
       "23        0.854429                   0.858018                0.858168   \n",
       "24        0.849229                   0.853952                0.853017   \n",
       "25        0.867745                   0.873307                0.870861   \n",
       "26        0.854429                   0.858018                0.858168   \n",
       "27        0.861201                   0.865854                0.865526   \n",
       "28        0.861201                   0.865854                0.865526   \n",
       "29        0.854429                   0.858018                0.858168   \n",
       "30        0.852997                   0.857339                0.856880   \n",
       "31        0.861432                   0.866630                0.865710   \n",
       "32        0.861432                   0.866630                0.865710   \n",
       "33        0.849229                   0.853952                0.853017   \n",
       "34        0.854429                   0.858018                0.858168   \n",
       "35        0.861201                   0.865854                0.865526   \n",
       "36        0.852997                   0.857339                0.856880   \n",
       "37        0.861201                   0.865854                0.865526   \n",
       "38        0.854429                   0.858018                0.858168   \n",
       "39        0.856723                   0.861420                0.861295   \n",
       "40        0.861201                   0.865854                0.865526   \n",
       "41        0.875048                   0.881079                0.878771   \n",
       "42        0.861432                   0.866630                0.865710   \n",
       "43        0.875048                   0.881079                0.878771   \n",
       "44        0.854429                   0.858018                0.858168   \n",
       "45        0.852997                   0.857339                0.856880   \n",
       "46        0.856723                   0.861420                0.861295   \n",
       "47        0.867745                   0.873307                0.870861   \n",
       "48        0.852997                   0.857339                0.856880   \n",
       "49        0.854429                   0.858018                0.858168   \n",
       "\n",
       "    media ponderada f1-score  tempo fit  tempo predict  \n",
       "0                   0.865675   0.026929      50.943763  \n",
       "1                   0.866047   0.026929       1.939642  \n",
       "2                   0.866047   0.026941       2.180462  \n",
       "3                   0.866047   0.026942       2.032678  \n",
       "4                   0.865675   0.026961      51.084528  \n",
       "5                   0.856932   0.027099       2.162479  \n",
       "6                   0.856932   0.027233       2.006593  \n",
       "7                   0.865675   0.027902      50.809997  \n",
       "8                   0.865675   0.027922      51.050041  \n",
       "9                   0.861185   0.027959      99.976362  \n",
       "10                  0.879332   0.028922      52.933302  \n",
       "11                  0.879332   0.029968      52.743143  \n",
       "12                  0.857959   0.030155      51.067972  \n",
       "13                  0.856932   0.030532       2.145015  \n",
       "14                  0.865675   0.031952      50.991324  \n",
       "15                  0.861185   0.032888     100.127405  \n",
       "16                  0.852657   0.035496     100.371877  \n",
       "17                  0.871305   0.035696      53.158206  \n",
       "18                  0.857959   0.036127      51.156095  \n",
       "19                  0.871305   0.036204      52.918117  \n",
       "20                  0.857959   0.036803      50.997628  \n",
       "21                  0.852657   0.037769     100.132839  \n",
       "22                  0.857959   0.038763      51.064413  \n",
       "23                  0.857959   0.041656      51.460521  \n",
       "24                  0.852657   2.524588     108.853681  \n",
       "25                  0.871305   2.536995      59.317578  \n",
       "26                  0.857959   2.537957      57.757765  \n",
       "27                  0.865675   2.547346      57.543360  \n",
       "28                  0.865675   2.548194      57.532639  \n",
       "29                  0.857959   2.552751      57.553232  \n",
       "30                  0.856932   2.554566      59.358503  \n",
       "31                  0.866047   2.563508      59.151893  \n",
       "32                  0.866047   2.581278      59.302167  \n",
       "33                  0.852657   2.582238     108.852259  \n",
       "34                  0.857959   2.594816      58.036513  \n",
       "35                  0.865675   2.615837      57.614316  \n",
       "36                  0.856932   2.621779      59.485099  \n",
       "37                  0.865675   2.622460      57.814443  \n",
       "38                  0.857959   2.629065      57.619833  \n",
       "39                  0.861185   2.639398     108.707143  \n",
       "40                  0.865675   2.646696      57.516279  \n",
       "41                  0.879332   2.650857      59.318689  \n",
       "42                  0.866047   2.654883      59.306390  \n",
       "43                  0.879332   2.657073      59.128510  \n",
       "44                  0.857959   2.662820      58.174034  \n",
       "45                  0.856932   2.674072      59.336886  \n",
       "46                  0.861185   2.719545     108.352238  \n",
       "47                  0.871305   2.737489      59.118438  \n",
       "48                  0.856932   3.536194      81.705079  \n",
       "49                  0.857959   3.537591      68.764618  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_metricas_modelos[dataframe_metricas_modelos['accuracy']>0.82].sort_values(by=[\"tempo fit\"],ascending=True).reset_index(drop=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50 melhores tempos de predict para acurácia acima de 82%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T01:19:51.502639Z",
     "start_time": "2020-09-21T01:19:51.474714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>media precision</th>\n",
       "      <th>media recall</th>\n",
       "      <th>media f1-score</th>\n",
       "      <th>media ponderada precision</th>\n",
       "      <th>media ponderada recall</th>\n",
       "      <th>media ponderada f1-score</th>\n",
       "      <th>tempo fit</th>\n",
       "      <th>tempo predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.841244</td>\n",
       "      <td>0.842240</td>\n",
       "      <td>0.842142</td>\n",
       "      <td>0.839821</td>\n",
       "      <td>0.848847</td>\n",
       "      <td>0.841244</td>\n",
       "      <td>0.842855</td>\n",
       "      <td>19.012440</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>82.306628</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.860762</td>\n",
       "      <td>0.857728</td>\n",
       "      <td>0.858958</td>\n",
       "      <td>0.862484</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.862535</td>\n",
       "      <td>141.878605</td>\n",
       "      <td>0.008004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.842159</td>\n",
       "      <td>0.840436</td>\n",
       "      <td>0.839503</td>\n",
       "      <td>0.847241</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.842535</td>\n",
       "      <td>5.576324</td>\n",
       "      <td>0.008976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>38.598322</td>\n",
       "      <td>0.008978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>43</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.841611</td>\n",
       "      <td>0.842675</td>\n",
       "      <td>0.842552</td>\n",
       "      <td>0.840258</td>\n",
       "      <td>0.849185</td>\n",
       "      <td>0.841611</td>\n",
       "      <td>0.843222</td>\n",
       "      <td>6.422049</td>\n",
       "      <td>0.008978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.860762</td>\n",
       "      <td>0.857728</td>\n",
       "      <td>0.858958</td>\n",
       "      <td>0.862484</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.862535</td>\n",
       "      <td>141.549502</td>\n",
       "      <td>0.009053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>17.214075</td>\n",
       "      <td>0.009957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.839368</td>\n",
       "      <td>0.838427</td>\n",
       "      <td>0.845295</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.841408</td>\n",
       "      <td>9.799134</td>\n",
       "      <td>0.009973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.841386</td>\n",
       "      <td>0.839653</td>\n",
       "      <td>0.838769</td>\n",
       "      <td>0.846408</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>23.224741</td>\n",
       "      <td>0.009976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>68.931366</td>\n",
       "      <td>0.010004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>38.557558</td>\n",
       "      <td>0.010088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>17.515083</td>\n",
       "      <td>0.010834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.839368</td>\n",
       "      <td>0.838427</td>\n",
       "      <td>0.845295</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.841408</td>\n",
       "      <td>12.718502</td>\n",
       "      <td>0.010938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.840558</td>\n",
       "      <td>0.839573</td>\n",
       "      <td>0.838628</td>\n",
       "      <td>0.845438</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.841585</td>\n",
       "      <td>12.305233</td>\n",
       "      <td>0.010972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>37</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.839368</td>\n",
       "      <td>0.838427</td>\n",
       "      <td>0.845295</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.841408</td>\n",
       "      <td>12.603086</td>\n",
       "      <td>0.010977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>38.496215</td>\n",
       "      <td>0.011003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.834775</td>\n",
       "      <td>0.827934</td>\n",
       "      <td>0.822757</td>\n",
       "      <td>0.843891</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.824408</td>\n",
       "      <td>8.097779</td>\n",
       "      <td>0.011061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>33</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.838116</td>\n",
       "      <td>0.838511</td>\n",
       "      <td>0.837372</td>\n",
       "      <td>0.836459</td>\n",
       "      <td>0.843368</td>\n",
       "      <td>0.838116</td>\n",
       "      <td>0.839407</td>\n",
       "      <td>247.590544</td>\n",
       "      <td>0.012203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.840558</td>\n",
       "      <td>0.839573</td>\n",
       "      <td>0.838628</td>\n",
       "      <td>0.845438</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.841585</td>\n",
       "      <td>15.506856</td>\n",
       "      <td>0.012964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>28</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840876</td>\n",
       "      <td>0.841909</td>\n",
       "      <td>0.840224</td>\n",
       "      <td>0.839291</td>\n",
       "      <td>0.847018</td>\n",
       "      <td>0.840876</td>\n",
       "      <td>0.842348</td>\n",
       "      <td>5.417488</td>\n",
       "      <td>0.012994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>42</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840876</td>\n",
       "      <td>0.841805</td>\n",
       "      <td>0.841719</td>\n",
       "      <td>0.839428</td>\n",
       "      <td>0.848411</td>\n",
       "      <td>0.840876</td>\n",
       "      <td>0.842486</td>\n",
       "      <td>18.351558</td>\n",
       "      <td>0.013175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>17.293534</td>\n",
       "      <td>0.013934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>21</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.840558</td>\n",
       "      <td>0.839573</td>\n",
       "      <td>0.838628</td>\n",
       "      <td>0.845438</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.841585</td>\n",
       "      <td>14.308930</td>\n",
       "      <td>0.013964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>14</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.825706</td>\n",
       "      <td>0.830420</td>\n",
       "      <td>0.826170</td>\n",
       "      <td>0.834503</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.829226</td>\n",
       "      <td>18.485370</td>\n",
       "      <td>0.014082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.836093</td>\n",
       "      <td>0.837645</td>\n",
       "      <td>0.831404</td>\n",
       "      <td>0.833585</td>\n",
       "      <td>0.839010</td>\n",
       "      <td>0.836093</td>\n",
       "      <td>0.836690</td>\n",
       "      <td>4.029616</td>\n",
       "      <td>0.014935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.842091</td>\n",
       "      <td>0.840380</td>\n",
       "      <td>0.839454</td>\n",
       "      <td>0.847183</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.842518</td>\n",
       "      <td>21.771908</td>\n",
       "      <td>0.014956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.860762</td>\n",
       "      <td>0.857728</td>\n",
       "      <td>0.858958</td>\n",
       "      <td>0.862484</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.862535</td>\n",
       "      <td>142.108870</td>\n",
       "      <td>0.015042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>40</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>38.394788</td>\n",
       "      <td>0.015597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.838435</td>\n",
       "      <td>0.837423</td>\n",
       "      <td>0.844282</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.840482</td>\n",
       "      <td>88.687985</td>\n",
       "      <td>0.015621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>29</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.838435</td>\n",
       "      <td>0.837423</td>\n",
       "      <td>0.844282</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.840482</td>\n",
       "      <td>87.565507</td>\n",
       "      <td>0.015622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>19</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.843819</td>\n",
       "      <td>0.839330</td>\n",
       "      <td>0.841394</td>\n",
       "      <td>0.840253</td>\n",
       "      <td>0.844736</td>\n",
       "      <td>0.843819</td>\n",
       "      <td>0.844164</td>\n",
       "      <td>796.420286</td>\n",
       "      <td>0.015622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>36</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.839368</td>\n",
       "      <td>0.838427</td>\n",
       "      <td>0.845295</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.841408</td>\n",
       "      <td>200.049276</td>\n",
       "      <td>0.015622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>28</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.838435</td>\n",
       "      <td>0.837423</td>\n",
       "      <td>0.844282</td>\n",
       "      <td>0.839220</td>\n",
       "      <td>0.840482</td>\n",
       "      <td>88.161083</td>\n",
       "      <td>0.015623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>46</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840876</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>0.840112</td>\n",
       "      <td>0.839207</td>\n",
       "      <td>0.846964</td>\n",
       "      <td>0.840876</td>\n",
       "      <td>0.842328</td>\n",
       "      <td>18.464855</td>\n",
       "      <td>0.015623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>12</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.860762</td>\n",
       "      <td>0.857728</td>\n",
       "      <td>0.858958</td>\n",
       "      <td>0.862484</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.862535</td>\n",
       "      <td>143.133405</td>\n",
       "      <td>0.015623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>35</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.839368</td>\n",
       "      <td>0.838427</td>\n",
       "      <td>0.845295</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.841408</td>\n",
       "      <td>200.899283</td>\n",
       "      <td>0.015624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>20</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.843819</td>\n",
       "      <td>0.839330</td>\n",
       "      <td>0.841394</td>\n",
       "      <td>0.840253</td>\n",
       "      <td>0.844736</td>\n",
       "      <td>0.843819</td>\n",
       "      <td>0.844164</td>\n",
       "      <td>795.091718</td>\n",
       "      <td>0.015624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>11</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.823216</td>\n",
       "      <td>0.829535</td>\n",
       "      <td>0.832264</td>\n",
       "      <td>0.823694</td>\n",
       "      <td>0.842221</td>\n",
       "      <td>0.823216</td>\n",
       "      <td>0.825334</td>\n",
       "      <td>21.503879</td>\n",
       "      <td>0.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>36</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.840558</td>\n",
       "      <td>0.839573</td>\n",
       "      <td>0.838628</td>\n",
       "      <td>0.845438</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.841585</td>\n",
       "      <td>14.098923</td>\n",
       "      <td>0.015635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>45</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840876</td>\n",
       "      <td>0.841909</td>\n",
       "      <td>0.840224</td>\n",
       "      <td>0.839291</td>\n",
       "      <td>0.847018</td>\n",
       "      <td>0.840876</td>\n",
       "      <td>0.842348</td>\n",
       "      <td>5.340970</td>\n",
       "      <td>0.015642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>39</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.839229</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>0.837228</td>\n",
       "      <td>0.844115</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.840270</td>\n",
       "      <td>17.269594</td>\n",
       "      <td>0.015649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>16</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.840558</td>\n",
       "      <td>0.839573</td>\n",
       "      <td>0.838628</td>\n",
       "      <td>0.845438</td>\n",
       "      <td>0.840324</td>\n",
       "      <td>0.841585</td>\n",
       "      <td>13.989051</td>\n",
       "      <td>0.015855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>24</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.846762</td>\n",
       "      <td>0.843349</td>\n",
       "      <td>0.843441</td>\n",
       "      <td>0.843359</td>\n",
       "      <td>0.847245</td>\n",
       "      <td>0.846762</td>\n",
       "      <td>0.846971</td>\n",
       "      <td>782.790426</td>\n",
       "      <td>0.018706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>41</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.842347</td>\n",
       "      <td>0.843451</td>\n",
       "      <td>0.843335</td>\n",
       "      <td>0.841000</td>\n",
       "      <td>0.849975</td>\n",
       "      <td>0.842347</td>\n",
       "      <td>0.843951</td>\n",
       "      <td>5.503305</td>\n",
       "      <td>0.021775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>32</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.838116</td>\n",
       "      <td>0.838511</td>\n",
       "      <td>0.837372</td>\n",
       "      <td>0.836459</td>\n",
       "      <td>0.843368</td>\n",
       "      <td>0.838116</td>\n",
       "      <td>0.839407</td>\n",
       "      <td>247.462588</td>\n",
       "      <td>0.023083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.860762</td>\n",
       "      <td>0.857728</td>\n",
       "      <td>0.858958</td>\n",
       "      <td>0.862484</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.862535</td>\n",
       "      <td>143.343545</td>\n",
       "      <td>0.023934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>13</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.828918</td>\n",
       "      <td>0.830379</td>\n",
       "      <td>0.826207</td>\n",
       "      <td>0.826968</td>\n",
       "      <td>0.833109</td>\n",
       "      <td>0.828918</td>\n",
       "      <td>0.829841</td>\n",
       "      <td>22.507247</td>\n",
       "      <td>0.025776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>21</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.843819</td>\n",
       "      <td>0.839330</td>\n",
       "      <td>0.841394</td>\n",
       "      <td>0.840253</td>\n",
       "      <td>0.844736</td>\n",
       "      <td>0.843819</td>\n",
       "      <td>0.844164</td>\n",
       "      <td>795.160889</td>\n",
       "      <td>0.028470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>23</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.846762</td>\n",
       "      <td>0.843349</td>\n",
       "      <td>0.843441</td>\n",
       "      <td>0.843359</td>\n",
       "      <td>0.847245</td>\n",
       "      <td>0.846762</td>\n",
       "      <td>0.846971</td>\n",
       "      <td>781.179155</td>\n",
       "      <td>0.028593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                model  accuracy  media precision  media recall  \\\n",
       "0      44  LogisticRegression   0.841244         0.842240      0.842142   \n",
       "1      30  LogisticRegression   0.839036         0.839229      0.838130   \n",
       "2       2        MLPClassifier  0.863135         0.860762      0.857728   \n",
       "3       8   LogisticRegression  0.841060         0.842159      0.840436   \n",
       "4       5   LogisticRegression  0.839036         0.839229      0.838130   \n",
       "5      43  LogisticRegression   0.841611         0.842675      0.842552   \n",
       "6      10       MLPClassifier   0.863135         0.860762      0.857728   \n",
       "7       4   LogisticRegression  0.839036         0.839229      0.838130   \n",
       "8      22  LogisticRegression   0.840140         0.840395      0.839368   \n",
       "9      23  LogisticRegression   0.840324         0.841386      0.839653   \n",
       "10     10  LogisticRegression   0.839036         0.839229      0.838130   \n",
       "11     25  LogisticRegression   0.839036         0.839229      0.838130   \n",
       "12     19  LogisticRegression   0.839036         0.839229      0.838130   \n",
       "13     17  LogisticRegression   0.840140         0.840395      0.839368   \n",
       "14      2   LogisticRegression  0.840324         0.840558      0.839573   \n",
       "15     37  LogisticRegression   0.840140         0.840395      0.839368   \n",
       "16     20  LogisticRegression   0.839036         0.839229      0.838130   \n",
       "17      1        SGDClassifier  0.821192         0.834775      0.827934   \n",
       "18     33       MLPClassifier   0.838116         0.838511      0.837372   \n",
       "19      1   LogisticRegression  0.840324         0.840558      0.839573   \n",
       "20     28  LogisticRegression   0.840876         0.841909      0.840224   \n",
       "21     42  LogisticRegression   0.840876         0.841805      0.841719   \n",
       "22     24  LogisticRegression   0.839036         0.839229      0.838130   \n",
       "23     21  LogisticRegression   0.840324         0.840558      0.839573   \n",
       "24     14       SGDClassifier   0.827815         0.825706      0.830420   \n",
       "25     16       SGDClassifier   0.836093         0.837645      0.831404   \n",
       "26      3   LogisticRegression  0.841060         0.842091      0.840380   \n",
       "27     11       MLPClassifier   0.863135         0.860762      0.857728   \n",
       "28     40  LogisticRegression   0.839036         0.839229      0.838130   \n",
       "29     30       MLPClassifier   0.839220         0.839220      0.838435   \n",
       "30     29       MLPClassifier   0.839220         0.839220      0.838435   \n",
       "31     19       MLPClassifier   0.843819         0.839330      0.841394   \n",
       "32     36       MLPClassifier   0.840140         0.840395      0.839368   \n",
       "33     28       MLPClassifier   0.839220         0.839220      0.838435   \n",
       "34     46  LogisticRegression   0.840876         0.841838      0.840112   \n",
       "35     12       MLPClassifier   0.863135         0.860762      0.857728   \n",
       "36     35       MLPClassifier   0.840140         0.840395      0.839368   \n",
       "37     20       MLPClassifier   0.843819         0.839330      0.841394   \n",
       "38     11       SGDClassifier   0.823216         0.829535      0.832264   \n",
       "39     36  LogisticRegression   0.840324         0.840558      0.839573   \n",
       "40     45  LogisticRegression   0.840876         0.841909      0.840224   \n",
       "41     39  LogisticRegression   0.839036         0.839229      0.838130   \n",
       "42     16  LogisticRegression   0.840324         0.840558      0.839573   \n",
       "43     24       MLPClassifier   0.846762         0.843349      0.843441   \n",
       "44     41  LogisticRegression   0.842347         0.843451      0.843335   \n",
       "45     32       MLPClassifier   0.838116         0.838511      0.837372   \n",
       "46      3        MLPClassifier  0.863135         0.860762      0.857728   \n",
       "47     13       SGDClassifier   0.828918         0.830379      0.826207   \n",
       "48     21       MLPClassifier   0.843819         0.839330      0.841394   \n",
       "49     23       MLPClassifier   0.846762         0.843349      0.843441   \n",
       "\n",
       "    media f1-score  media ponderada precision  media ponderada recall  \\\n",
       "0         0.839821                   0.848847                0.841244   \n",
       "1         0.837228                   0.844115                0.839036   \n",
       "2         0.858958                   0.862484                0.863135   \n",
       "3         0.839503                   0.847241                0.841060   \n",
       "4         0.837228                   0.844115                0.839036   \n",
       "5         0.840258                   0.849185                0.841611   \n",
       "6         0.858958                   0.862484                0.863135   \n",
       "7         0.837228                   0.844115                0.839036   \n",
       "8         0.838427                   0.845295                0.840140   \n",
       "9         0.838769                   0.846408                0.840324   \n",
       "10        0.837228                   0.844115                0.839036   \n",
       "11        0.837228                   0.844115                0.839036   \n",
       "12        0.837228                   0.844115                0.839036   \n",
       "13        0.838427                   0.845295                0.840140   \n",
       "14        0.838628                   0.845438                0.840324   \n",
       "15        0.838427                   0.845295                0.840140   \n",
       "16        0.837228                   0.844115                0.839036   \n",
       "17        0.822757                   0.843891                0.821192   \n",
       "18        0.836459                   0.843368                0.838116   \n",
       "19        0.838628                   0.845438                0.840324   \n",
       "20        0.839291                   0.847018                0.840876   \n",
       "21        0.839428                   0.848411                0.840876   \n",
       "22        0.837228                   0.844115                0.839036   \n",
       "23        0.838628                   0.845438                0.840324   \n",
       "24        0.826170                   0.834503                0.827815   \n",
       "25        0.833585                   0.839010                0.836093   \n",
       "26        0.839454                   0.847183                0.841060   \n",
       "27        0.858958                   0.862484                0.863135   \n",
       "28        0.837228                   0.844115                0.839036   \n",
       "29        0.837423                   0.844282                0.839220   \n",
       "30        0.837423                   0.844282                0.839220   \n",
       "31        0.840253                   0.844736                0.843819   \n",
       "32        0.838427                   0.845295                0.840140   \n",
       "33        0.837423                   0.844282                0.839220   \n",
       "34        0.839207                   0.846964                0.840876   \n",
       "35        0.858958                   0.862484                0.863135   \n",
       "36        0.838427                   0.845295                0.840140   \n",
       "37        0.840253                   0.844736                0.843819   \n",
       "38        0.823694                   0.842221                0.823216   \n",
       "39        0.838628                   0.845438                0.840324   \n",
       "40        0.839291                   0.847018                0.840876   \n",
       "41        0.837228                   0.844115                0.839036   \n",
       "42        0.838628                   0.845438                0.840324   \n",
       "43        0.843359                   0.847245                0.846762   \n",
       "44        0.841000                   0.849975                0.842347   \n",
       "45        0.836459                   0.843368                0.838116   \n",
       "46        0.858958                   0.862484                0.863135   \n",
       "47        0.826968                   0.833109                0.828918   \n",
       "48        0.840253                   0.844736                0.843819   \n",
       "49        0.843359                   0.847245                0.846762   \n",
       "\n",
       "    media ponderada f1-score   tempo fit  tempo predict  \n",
       "0                   0.842855   19.012440       0.000000  \n",
       "1                   0.840270   82.306628       0.000000  \n",
       "2                   0.862535  141.878605       0.008004  \n",
       "3                   0.842535    5.576324       0.008976  \n",
       "4                   0.840270   38.598322       0.008978  \n",
       "5                   0.843222    6.422049       0.008978  \n",
       "6                   0.862535  141.549502       0.009053  \n",
       "7                   0.840270   17.214075       0.009957  \n",
       "8                   0.841408    9.799134       0.009973  \n",
       "9                   0.841791   23.224741       0.009976  \n",
       "10                  0.840270   68.931366       0.010004  \n",
       "11                  0.840270   38.557558       0.010088  \n",
       "12                  0.840270   17.515083       0.010834  \n",
       "13                  0.841408   12.718502       0.010938  \n",
       "14                  0.841585   12.305233       0.010972  \n",
       "15                  0.841408   12.603086       0.010977  \n",
       "16                  0.840270   38.496215       0.011003  \n",
       "17                  0.824408    8.097779       0.011061  \n",
       "18                  0.839407  247.590544       0.012203  \n",
       "19                  0.841585   15.506856       0.012964  \n",
       "20                  0.842348    5.417488       0.012994  \n",
       "21                  0.842486   18.351558       0.013175  \n",
       "22                  0.840270   17.293534       0.013934  \n",
       "23                  0.841585   14.308930       0.013964  \n",
       "24                  0.829226   18.485370       0.014082  \n",
       "25                  0.836690    4.029616       0.014935  \n",
       "26                  0.842518   21.771908       0.014956  \n",
       "27                  0.862535  142.108870       0.015042  \n",
       "28                  0.840270   38.394788       0.015597  \n",
       "29                  0.840482   88.687985       0.015621  \n",
       "30                  0.840482   87.565507       0.015622  \n",
       "31                  0.844164  796.420286       0.015622  \n",
       "32                  0.841408  200.049276       0.015622  \n",
       "33                  0.840482   88.161083       0.015623  \n",
       "34                  0.842328   18.464855       0.015623  \n",
       "35                  0.862535  143.133405       0.015623  \n",
       "36                  0.841408  200.899283       0.015624  \n",
       "37                  0.844164  795.091718       0.015624  \n",
       "38                  0.825334   21.503879       0.015625  \n",
       "39                  0.841585   14.098923       0.015635  \n",
       "40                  0.842348    5.340970       0.015642  \n",
       "41                  0.840270   17.269594       0.015649  \n",
       "42                  0.841585   13.989051       0.015855  \n",
       "43                  0.846971  782.790426       0.018706  \n",
       "44                  0.843951    5.503305       0.021775  \n",
       "45                  0.839407  247.462588       0.023083  \n",
       "46                  0.862535  143.343545       0.023934  \n",
       "47                  0.829841   22.507247       0.025776  \n",
       "48                  0.844164  795.160889       0.028470  \n",
       "49                  0.846971  781.179155       0.028593  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_metricas_modelos[dataframe_metricas_modelos['accuracy']>0.82].sort_values(by=[\"tempo predict\"],ascending=True).reset_index(drop=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T18:14:21.209410Z",
     "start_time": "2020-09-22T18:14:21.163534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>media precision</th>\n",
       "      <th>media recall</th>\n",
       "      <th>media f1-score</th>\n",
       "      <th>media ponderada precision</th>\n",
       "      <th>media ponderada recall</th>\n",
       "      <th>media ponderada f1-score</th>\n",
       "      <th>tempo fit</th>\n",
       "      <th>tempo predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.861172</td>\n",
       "      <td>0.857953</td>\n",
       "      <td>0.856547</td>\n",
       "      <td>0.857146</td>\n",
       "      <td>0.861436</td>\n",
       "      <td>0.861172</td>\n",
       "      <td>0.861201</td>\n",
       "      <td>2.359133</td>\n",
       "      <td>61.661797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.851669</td>\n",
       "      <td>0.849318</td>\n",
       "      <td>0.846425</td>\n",
       "      <td>0.847539</td>\n",
       "      <td>0.852470</td>\n",
       "      <td>0.851669</td>\n",
       "      <td>0.851748</td>\n",
       "      <td>1.864382</td>\n",
       "      <td>57.349736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.840637</td>\n",
       "      <td>0.839370</td>\n",
       "      <td>0.838445</td>\n",
       "      <td>0.845588</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.841460</td>\n",
       "      <td>18.495453</td>\n",
       "      <td>0.011134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840123</td>\n",
       "      <td>0.840632</td>\n",
       "      <td>0.839628</td>\n",
       "      <td>0.838457</td>\n",
       "      <td>0.845861</td>\n",
       "      <td>0.840123</td>\n",
       "      <td>0.841476</td>\n",
       "      <td>22.637263</td>\n",
       "      <td>0.011937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.831494</td>\n",
       "      <td>0.832221</td>\n",
       "      <td>0.834532</td>\n",
       "      <td>0.829712</td>\n",
       "      <td>0.842888</td>\n",
       "      <td>0.831494</td>\n",
       "      <td>0.833584</td>\n",
       "      <td>27.562878</td>\n",
       "      <td>0.187485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.828964</td>\n",
       "      <td>0.827474</td>\n",
       "      <td>0.830388</td>\n",
       "      <td>0.826334</td>\n",
       "      <td>0.838109</td>\n",
       "      <td>0.828964</td>\n",
       "      <td>0.830954</td>\n",
       "      <td>8.286375</td>\n",
       "      <td>0.200713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.821008</td>\n",
       "      <td>0.799391</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.803305</td>\n",
       "      <td>0.804524</td>\n",
       "      <td>0.821008</td>\n",
       "      <td>0.809220</td>\n",
       "      <td>349.548159</td>\n",
       "      <td>0.027282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.818801</td>\n",
       "      <td>0.822087</td>\n",
       "      <td>0.823021</td>\n",
       "      <td>0.818307</td>\n",
       "      <td>0.831095</td>\n",
       "      <td>0.818801</td>\n",
       "      <td>0.820834</td>\n",
       "      <td>358.823953</td>\n",
       "      <td>0.067276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.808453</td>\n",
       "      <td>0.814904</td>\n",
       "      <td>0.802872</td>\n",
       "      <td>0.802212</td>\n",
       "      <td>0.816551</td>\n",
       "      <td>0.808453</td>\n",
       "      <td>0.806075</td>\n",
       "      <td>21.767559</td>\n",
       "      <td>0.018263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.797339</td>\n",
       "      <td>0.797991</td>\n",
       "      <td>0.789177</td>\n",
       "      <td>0.789754</td>\n",
       "      <td>0.800500</td>\n",
       "      <td>0.797339</td>\n",
       "      <td>0.795509</td>\n",
       "      <td>86.793537</td>\n",
       "      <td>11.631763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.794927</td>\n",
       "      <td>0.800838</td>\n",
       "      <td>0.786072</td>\n",
       "      <td>0.786356</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>0.794927</td>\n",
       "      <td>0.791979</td>\n",
       "      <td>29.250371</td>\n",
       "      <td>0.012056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.759382</td>\n",
       "      <td>0.762685</td>\n",
       "      <td>0.759025</td>\n",
       "      <td>0.758852</td>\n",
       "      <td>0.766565</td>\n",
       "      <td>0.759382</td>\n",
       "      <td>0.761181</td>\n",
       "      <td>68.243217</td>\n",
       "      <td>0.888968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.754323</td>\n",
       "      <td>0.672942</td>\n",
       "      <td>0.729043</td>\n",
       "      <td>0.691134</td>\n",
       "      <td>0.679152</td>\n",
       "      <td>0.754323</td>\n",
       "      <td>0.704696</td>\n",
       "      <td>192.677397</td>\n",
       "      <td>0.026847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.752575</td>\n",
       "      <td>0.759474</td>\n",
       "      <td>0.745287</td>\n",
       "      <td>0.732619</td>\n",
       "      <td>0.767162</td>\n",
       "      <td>0.752575</td>\n",
       "      <td>0.741983</td>\n",
       "      <td>91.050403</td>\n",
       "      <td>0.023761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.736681</td>\n",
       "      <td>0.747666</td>\n",
       "      <td>0.741024</td>\n",
       "      <td>0.736931</td>\n",
       "      <td>0.755578</td>\n",
       "      <td>0.736681</td>\n",
       "      <td>0.739004</td>\n",
       "      <td>65.921680</td>\n",
       "      <td>0.941525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.689845</td>\n",
       "      <td>0.683559</td>\n",
       "      <td>0.683568</td>\n",
       "      <td>0.683504</td>\n",
       "      <td>0.690575</td>\n",
       "      <td>0.689845</td>\n",
       "      <td>0.690155</td>\n",
       "      <td>3.796798</td>\n",
       "      <td>0.013948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>0.671450</td>\n",
       "      <td>0.715326</td>\n",
       "      <td>0.696206</td>\n",
       "      <td>0.672266</td>\n",
       "      <td>0.740077</td>\n",
       "      <td>0.671450</td>\n",
       "      <td>0.668347</td>\n",
       "      <td>0.031827</td>\n",
       "      <td>0.009477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.655813</td>\n",
       "      <td>0.704017</td>\n",
       "      <td>0.682515</td>\n",
       "      <td>0.657349</td>\n",
       "      <td>0.726818</td>\n",
       "      <td>0.655813</td>\n",
       "      <td>0.651434</td>\n",
       "      <td>0.024841</td>\n",
       "      <td>0.004987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.654709</td>\n",
       "      <td>0.701288</td>\n",
       "      <td>0.679464</td>\n",
       "      <td>0.659472</td>\n",
       "      <td>0.720004</td>\n",
       "      <td>0.654709</td>\n",
       "      <td>0.653697</td>\n",
       "      <td>0.206432</td>\n",
       "      <td>0.149932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  accuracy  media precision  media recall  \\\n",
       "0          KNeighborsClassifier  0.861172         0.857953      0.856547   \n",
       "1         KNeighborsClassifier   0.851669         0.849318      0.846425   \n",
       "2            LogisticRegression  0.840140         0.840637      0.839370   \n",
       "3           LogisticRegression   0.840123         0.840632      0.839628   \n",
       "4        RandomForestClassifier  0.831494         0.832221      0.834532   \n",
       "5          ExtraTreesClassifier  0.828964         0.827474      0.830388   \n",
       "6                MLPClassifier   0.821008         0.799391      0.813333   \n",
       "7   GradientBoostingClassifier   0.818801         0.822087      0.823021   \n",
       "8                SGDClassifier   0.808453         0.814904      0.802872   \n",
       "9                           SVC  0.797339         0.797991      0.789177   \n",
       "10                SGDClassifier  0.794927         0.800838      0.786072   \n",
       "11           AdaBoostClassifier  0.759382         0.762685      0.759025   \n",
       "12                MLPClassifier  0.754323         0.672942      0.729043   \n",
       "13                    LinearSVC  0.752575         0.759474      0.745287   \n",
       "14          AdaBoostClassifier   0.736681         0.747666      0.741024   \n",
       "15       DecisionTreeClassifier  0.689845         0.683559      0.683568   \n",
       "16                 ComplementNB  0.671450         0.715326      0.696206   \n",
       "17                MultinomialNB  0.655813         0.704017      0.682515   \n",
       "18                   GaussianNB  0.654709         0.701288      0.679464   \n",
       "\n",
       "    media f1-score  media ponderada precision  media ponderada recall  \\\n",
       "0         0.857146                   0.861436                0.861172   \n",
       "1         0.847539                   0.852470                0.851669   \n",
       "2         0.838445                   0.845588                0.840140   \n",
       "3         0.838457                   0.845861                0.840123   \n",
       "4         0.829712                   0.842888                0.831494   \n",
       "5         0.826334                   0.838109                0.828964   \n",
       "6         0.803305                   0.804524                0.821008   \n",
       "7         0.818307                   0.831095                0.818801   \n",
       "8         0.802212                   0.816551                0.808453   \n",
       "9         0.789754                   0.800500                0.797339   \n",
       "10        0.786356                   0.802355                0.794927   \n",
       "11        0.758852                   0.766565                0.759382   \n",
       "12        0.691134                   0.679152                0.754323   \n",
       "13        0.732619                   0.767162                0.752575   \n",
       "14        0.736931                   0.755578                0.736681   \n",
       "15        0.683504                   0.690575                0.689845   \n",
       "16        0.672266                   0.740077                0.671450   \n",
       "17        0.657349                   0.726818                0.655813   \n",
       "18        0.659472                   0.720004                0.654709   \n",
       "\n",
       "    media ponderada f1-score   tempo fit  tempo predict  \n",
       "0                   0.861201    2.359133      61.661797  \n",
       "1                   0.851748    1.864382      57.349736  \n",
       "2                   0.841460   18.495453       0.011134  \n",
       "3                   0.841476   22.637263       0.011937  \n",
       "4                   0.833584   27.562878       0.187485  \n",
       "5                   0.830954    8.286375       0.200713  \n",
       "6                   0.809220  349.548159       0.027282  \n",
       "7                   0.820834  358.823953       0.067276  \n",
       "8                   0.806075   21.767559       0.018263  \n",
       "9                   0.795509   86.793537      11.631763  \n",
       "10                  0.791979   29.250371       0.012056  \n",
       "11                  0.761181   68.243217       0.888968  \n",
       "12                  0.704696  192.677397       0.026847  \n",
       "13                  0.741983   91.050403       0.023761  \n",
       "14                  0.739004   65.921680       0.941525  \n",
       "15                  0.690155    3.796798       0.013948  \n",
       "16                  0.668347    0.031827       0.009477  \n",
       "17                  0.651434    0.024841       0.004987  \n",
       "18                  0.653697    0.206432       0.149932  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_metricas_modelos.groupby(\"model\").mean().sort_values(by=['accuracy'],ascending=False).reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
