{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T17:29:08.050180Z",
     "start_time": "2020-10-04T17:29:04.024448Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import random as rand\n",
    "import os\n",
    "import xml.etree.ElementTree as et\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T17:29:08.060878Z",
     "start_time": "2020-10-04T17:29:08.050180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\FIA\\TCC\\BASES\\\n"
     ]
    }
   ],
   "source": [
    "bases_prontas_path = os.path.join(\"D:\\\\\",\"FIA\",\"TCC\",\"BASES\",\"\")\n",
    "print(bases_prontas_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar modelos com transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T17:29:11.422246Z",
     "start_time": "2020-10-04T17:29:08.062874Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\anaconda3\\envs\\py3_6_tensorflow2_1\\lib\\site-packages\\keras_applications\\mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    }
   ],
   "source": [
    "baseModel_MobileNetV2 = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "                        input_tensor=Input(shape=(64, 64, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T17:29:11.541895Z",
     "start_time": "2020-10-04T17:29:11.422246Z"
    }
   },
   "outputs": [],
   "source": [
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel_MobileNetV2 = baseModel_MobileNetV2.output\n",
    "# headModel_MobileNetV2 = AveragePooling2D(pool_size=(7, 7))(headModel_MobileNetV2)\n",
    "headModel_MobileNetV2 = AveragePooling2D(pool_size=(2, 2))(headModel_MobileNetV2)\n",
    "headModel_MobileNetV2 = Flatten(name=\"flatten\")(headModel_MobileNetV2)\n",
    "headModel_MobileNetV2 = Dense(12288, activation=\"relu\")(headModel_MobileNetV2)\n",
    "headModel_MobileNetV2 = Dropout(0.5)(headModel_MobileNetV2)\n",
    "headModel_MobileNetV2 = Dense(4096, activation=\"relu\")(headModel_MobileNetV2)\n",
    "headModel_MobileNetV2 = Dropout(0.5)(headModel_MobileNetV2)\n",
    "headModel_MobileNetV2 = Dense(64, activation=\"relu\")(headModel_MobileNetV2)\n",
    "headModel_MobileNetV2 = Dropout(0.5)(headModel_MobileNetV2)\n",
    "headModel_MobileNetV2 = Dense(3, activation=\"softmax\")(headModel_MobileNetV2)\n",
    "\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model_based_MobileNetV2 = Model(inputs=baseModel_MobileNetV2.input, outputs=headModel_MobileNetV2)\n",
    "\n",
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the first training process\n",
    "for layer in baseModel_MobileNetV2.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T17:29:13.360891Z",
     "start_time": "2020-10-04T17:29:11.541895Z"
    }
   },
   "outputs": [],
   "source": [
    "baseModel_MobileNetV2_224 = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "                        input_tensor=Input(shape=(224, 224, 3)))\n",
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel_MobileNetV2_224 = baseModel_MobileNetV2_224.output\n",
    "headModel_MobileNetV2_224 = AveragePooling2D(pool_size=(7, 7))(headModel_MobileNetV2_224)\n",
    "headModel_MobileNetV2_224 = Flatten(name=\"flatten\")(headModel_MobileNetV2_224)\n",
    "headModel_MobileNetV2_224 = Dense(12288, activation=\"relu\")(headModel_MobileNetV2_224)\n",
    "headModel_MobileNetV2_224 = Dropout(0.5)(headModel_MobileNetV2_224)\n",
    "headModel_MobileNetV2_224 = Dense(4096, activation=\"relu\")(headModel_MobileNetV2_224)\n",
    "headModel_MobileNetV2_224 = Dropout(0.5)(headModel_MobileNetV2_224)\n",
    "headModel_MobileNetV2_224 = Dense(224, activation=\"relu\")(headModel_MobileNetV2_224)\n",
    "headModel_MobileNetV2_224 = Dropout(0.5)(headModel_MobileNetV2_224)\n",
    "headModel_MobileNetV2_224 = Dense(3, activation=\"softmax\")(headModel_MobileNetV2_224)\n",
    "\n",
    "\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model_based_MobileNetV2_224 = Model(inputs=baseModel_MobileNetV2_224.input, outputs=headModel_MobileNetV2_224)\n",
    "\n",
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the first training process\n",
    "for layer in baseModel_MobileNetV2_224.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T17:29:13.366882Z",
     "start_time": "2020-10-04T17:29:13.360891Z"
    }
   },
   "outputs": [],
   "source": [
    "INIT_LR = 1e-10\n",
    "EPOCHS = 200\n",
    "BS = 1\n",
    "test_size_val = 0.45\n",
    "\n",
    "\n",
    "aug = ImageDataGenerator(\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.15,\n",
    "    fill_mode=\"nearest\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T17:29:13.378851Z",
     "start_time": "2020-10-04T17:29:13.368877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "opt1 = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "# opt2 = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilar e treinar os modelos criados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T17:29:16.501133Z",
     "start_time": "2020-10-04T17:29:13.381843Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = np.load(bases_prontas_path+'mask_dataset_mobilenet_v2_preprocess_input_64_64_3.npy')\n",
    "# dataset = np.load(bases_prontas_path+'mask_dataset_mobilenet_v2_preprocess_input_224_224_3_2_categorias.npy')\n",
    "target = np.load(bases_prontas_path+'mask_dataset_labels.npy')\n",
    "(trainX, testX, trainY, testY) = train_test_split(dataset, target,\n",
    "                                                  test_size=test_size_val, stratify=target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-04T17:29:04.038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training head...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 11959 steps, validate on 9785 samples\n",
      "Epoch 1/200\n",
      "11959/11959 [==============================] - 322s 27ms/step - loss: 1.0957 - accuracy: 0.3980 - val_loss: 1.0901 - val_accuracy: 0.3999\n",
      "Epoch 2/200\n",
      "11959/11959 [==============================] - 301s 25ms/step - loss: 1.0907 - accuracy: 0.3994 - val_loss: 1.0946 - val_accuracy: 0.3999\n",
      "Epoch 3/200\n",
      "11959/11959 [==============================] - 300s 25ms/step - loss: 1.0906 - accuracy: 0.4000 - val_loss: 1.0896 - val_accuracy: 0.3999\n",
      "Epoch 4/200\n",
      "11959/11959 [==============================] - 299s 25ms/step - loss: 1.0911 - accuracy: 0.3994 - val_loss: 1.0890 - val_accuracy: 0.3999\n",
      "Epoch 5/200\n",
      "11959/11959 [==============================] - 298s 25ms/step - loss: 1.0905 - accuracy: 0.3997 - val_loss: 1.0917 - val_accuracy: 0.3999\n",
      "Epoch 6/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0909 - accuracy: 0.3995 - val_loss: 1.0892 - val_accuracy: 0.3999\n",
      "Epoch 7/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0908 - accuracy: 0.3996 - val_loss: 1.0911 - val_accuracy: 0.3999\n",
      "Epoch 8/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0910 - accuracy: 0.3998 - val_loss: 1.0907 - val_accuracy: 0.3999\n",
      "Epoch 9/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0902 - accuracy: 0.3993 - val_loss: 1.0932 - val_accuracy: 0.3999\n",
      "Epoch 10/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0911 - accuracy: 0.3997 - val_loss: 1.0918 - val_accuracy: 0.3999\n",
      "Epoch 11/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0911 - accuracy: 0.3995 - val_loss: 1.0889 - val_accuracy: 0.3999\n",
      "Epoch 12/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0912 - accuracy: 0.3998 - val_loss: 1.0892 - val_accuracy: 0.3999\n",
      "Epoch 13/200\n",
      "11959/11959 [==============================] - 298s 25ms/step - loss: 1.0905 - accuracy: 0.3989 - val_loss: 1.0919 - val_accuracy: 0.3999\n",
      "Epoch 14/200\n",
      "11959/11959 [==============================] - 298s 25ms/step - loss: 1.0909 - accuracy: 0.3990 - val_loss: 1.0898 - val_accuracy: 0.3999\n",
      "Epoch 15/200\n",
      "11959/11959 [==============================] - 298s 25ms/step - loss: 1.0907 - accuracy: 0.3997 - val_loss: 1.0918 - val_accuracy: 0.3999\n",
      "Epoch 16/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0906 - accuracy: 0.3998 - val_loss: 1.0937 - val_accuracy: 0.3999\n",
      "Epoch 17/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0904 - accuracy: 0.3989 - val_loss: 1.0899 - val_accuracy: 0.3999\n",
      "Epoch 18/200\n",
      "11959/11959 [==============================] - 296s 25ms/step - loss: 1.0904 - accuracy: 0.3989 - val_loss: 1.0900 - val_accuracy: 0.3999\n",
      "Epoch 19/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0908 - accuracy: 0.3998 - val_loss: 1.0902 - val_accuracy: 0.3999\n",
      "Epoch 20/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0910 - accuracy: 0.3997 - val_loss: 1.0892 - val_accuracy: 0.3999\n",
      "Epoch 21/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0911 - accuracy: 0.3998 - val_loss: 1.0892 - val_accuracy: 0.3999\n",
      "Epoch 22/200\n",
      "11959/11959 [==============================] - 298s 25ms/step - loss: 1.0908 - accuracy: 0.3998 - val_loss: 1.0892 - val_accuracy: 0.3999\n",
      "Epoch 23/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0910 - accuracy: 0.3998 - val_loss: 1.0903 - val_accuracy: 0.3999\n",
      "Epoch 24/200\n",
      "11959/11959 [==============================] - 296s 25ms/step - loss: 1.0908 - accuracy: 0.3997 - val_loss: 1.0892 - val_accuracy: 0.3999\n",
      "Epoch 25/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0909 - accuracy: 0.3997 - val_loss: 1.0892 - val_accuracy: 0.3999\n",
      "Epoch 26/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0905 - accuracy: 0.3994 - val_loss: 1.0892 - val_accuracy: 0.3999\n",
      "Epoch 27/200\n",
      "11959/11959 [==============================] - 296s 25ms/step - loss: 1.0906 - accuracy: 0.3998 - val_loss: 1.0895 - val_accuracy: 0.3999\n",
      "Epoch 28/200\n",
      "11959/11959 [==============================] - 296s 25ms/step - loss: 1.0912 - accuracy: 0.3998 - val_loss: 1.0892 - val_accuracy: 0.3999\n",
      "Epoch 29/200\n",
      "11959/11959 [==============================] - 296s 25ms/step - loss: 1.0909 - accuracy: 0.3998 - val_loss: 1.0902 - val_accuracy: 0.3999\n",
      "Epoch 30/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0907 - accuracy: 0.3998 - val_loss: 1.0925 - val_accuracy: 0.3999\n",
      "Epoch 31/200\n",
      "11959/11959 [==============================] - 296s 25ms/step - loss: 1.0913 - accuracy: 0.3998 - val_loss: 1.0904 - val_accuracy: 0.3999\n",
      "Epoch 32/200\n",
      "11959/11959 [==============================] - 296s 25ms/step - loss: 1.0907 - accuracy: 0.3995 - val_loss: 1.0904 - val_accuracy: 0.3999\n",
      "Epoch 33/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0907 - accuracy: 0.3995 - val_loss: 1.0890 - val_accuracy: 0.3999\n",
      "Epoch 34/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0906 - accuracy: 0.3994 - val_loss: 1.0894 - val_accuracy: 0.3999\n",
      "Epoch 35/200\n",
      "11959/11959 [==============================] - 298s 25ms/step - loss: 1.0903 - accuracy: 0.3982 - val_loss: 1.0924 - val_accuracy: 0.3999\n",
      "Epoch 36/200\n",
      "11959/11959 [==============================] - 296s 25ms/step - loss: 1.0906 - accuracy: 0.3998 - val_loss: 1.0904 - val_accuracy: 0.3999\n",
      "Epoch 37/200\n",
      "11959/11959 [==============================] - 296s 25ms/step - loss: 1.0904 - accuracy: 0.3996 - val_loss: 1.0893 - val_accuracy: 0.3999\n",
      "Epoch 38/200\n",
      "11959/11959 [==============================] - 296s 25ms/step - loss: 1.0909 - accuracy: 0.3997 - val_loss: 1.0906 - val_accuracy: 0.3999\n",
      "Epoch 39/200\n",
      "11959/11959 [==============================] - 296s 25ms/step - loss: 1.0910 - accuracy: 0.3998 - val_loss: 1.0921 - val_accuracy: 0.3999\n",
      "Epoch 40/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0908 - accuracy: 0.3998 - val_loss: 1.0898 - val_accuracy: 0.3999\n",
      "Epoch 41/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0903 - accuracy: 0.3993 - val_loss: 1.0896 - val_accuracy: 0.3999\n",
      "Epoch 42/200\n",
      "11959/11959 [==============================] - 296s 25ms/step - loss: 1.0906 - accuracy: 0.3989 - val_loss: 1.0911 - val_accuracy: 0.3999\n",
      "Epoch 43/200\n",
      "11959/11959 [==============================] - 296s 25ms/step - loss: 1.0902 - accuracy: 0.3997 - val_loss: 1.0926 - val_accuracy: 0.3999\n",
      "Epoch 44/200\n",
      "11959/11959 [==============================] - 296s 25ms/step - loss: 1.0903 - accuracy: 0.3989 - val_loss: 1.0896 - val_accuracy: 0.3999\n",
      "Epoch 45/200\n",
      "11959/11959 [==============================] - 296s 25ms/step - loss: 1.0904 - accuracy: 0.3988 - val_loss: 1.0895 - val_accuracy: 0.3999\n",
      "Epoch 46/200\n",
      "11959/11959 [==============================] - 296s 25ms/step - loss: 1.0908 - accuracy: 0.3991 - val_loss: 1.0917 - val_accuracy: 0.3999\n",
      "Epoch 47/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0912 - accuracy: 0.3998 - val_loss: 1.0896 - val_accuracy: 0.3999\n",
      "Epoch 48/200\n",
      "11959/11959 [==============================] - 296s 25ms/step - loss: 1.0909 - accuracy: 0.3998 - val_loss: 1.0900 - val_accuracy: 0.3999\n",
      "Epoch 49/200\n",
      "11959/11959 [==============================] - 296s 25ms/step - loss: 1.0904 - accuracy: 0.3996 - val_loss: 1.0966 - val_accuracy: 0.3999\n",
      "Epoch 50/200\n",
      "11959/11959 [==============================] - 296s 25ms/step - loss: 1.0909 - accuracy: 0.3998 - val_loss: 1.0892 - val_accuracy: 0.3999\n",
      "Epoch 51/200\n",
      "11959/11959 [==============================] - 296s 25ms/step - loss: 1.0907 - accuracy: 0.3998 - val_loss: 1.0889 - val_accuracy: 0.3999\n",
      "Epoch 52/200\n",
      "11959/11959 [==============================] - 296s 25ms/step - loss: 1.0905 - accuracy: 0.3998 - val_loss: 1.0902 - val_accuracy: 0.3999\n",
      "Epoch 53/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0908 - accuracy: 0.3994 - val_loss: 1.0935 - val_accuracy: 0.3999\n",
      "Epoch 54/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11959/11959 [==============================] - 298s 25ms/step - loss: 1.0907 - accuracy: 0.3989 - val_loss: 1.0896 - val_accuracy: 0.3999\n",
      "Epoch 55/200\n",
      "11959/11959 [==============================] - 298s 25ms/step - loss: 1.0910 - accuracy: 0.3998 - val_loss: 1.0908 - val_accuracy: 0.3999\n",
      "Epoch 56/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0909 - accuracy: 0.3998 - val_loss: 1.0899 - val_accuracy: 0.3999\n",
      "Epoch 57/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0905 - accuracy: 0.3998 - val_loss: 1.0890 - val_accuracy: 0.3999\n",
      "Epoch 58/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0906 - accuracy: 0.3996 - val_loss: 1.0928 - val_accuracy: 0.3999\n",
      "Epoch 59/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0903 - accuracy: 0.3996 - val_loss: 1.0907 - val_accuracy: 0.3999\n",
      "Epoch 60/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0909 - accuracy: 0.3998 - val_loss: 1.0910 - val_accuracy: 0.3999\n",
      "Epoch 61/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0902 - accuracy: 0.3998 - val_loss: 1.0948 - val_accuracy: 0.3999\n",
      "Epoch 62/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0909 - accuracy: 0.3995 - val_loss: 1.0913 - val_accuracy: 0.3999\n",
      "Epoch 63/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0907 - accuracy: 0.3993 - val_loss: 1.0894 - val_accuracy: 0.3999\n",
      "Epoch 64/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0908 - accuracy: 0.3998 - val_loss: 1.0890 - val_accuracy: 0.3999\n",
      "Epoch 65/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0905 - accuracy: 0.3993 - val_loss: 1.0899 - val_accuracy: 0.3999\n",
      "Epoch 66/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0907 - accuracy: 0.3993 - val_loss: 1.0891 - val_accuracy: 0.3999\n",
      "Epoch 67/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0908 - accuracy: 0.3986 - val_loss: 1.0905 - val_accuracy: 0.3999\n",
      "Epoch 68/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0901 - accuracy: 0.3992 - val_loss: 1.0940 - val_accuracy: 0.3999\n",
      "Epoch 69/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0907 - accuracy: 0.3994 - val_loss: 1.0923 - val_accuracy: 0.3999\n",
      "Epoch 70/200\n",
      "11959/11959 [==============================] - 296s 25ms/step - loss: 1.0904 - accuracy: 0.3996 - val_loss: 1.0894 - val_accuracy: 0.3999\n",
      "Epoch 71/200\n",
      "11959/11959 [==============================] - 297s 25ms/step - loss: 1.0904 - accuracy: 0.3998 - val_loss: 1.0933 - val_accuracy: 0.3999\n",
      "Epoch 72/200\n",
      "11959/11959 [==============================] - 298s 25ms/step - loss: 1.0906 - accuracy: 0.3993 - val_loss: 1.0894 - val_accuracy: 0.3999\n",
      "Epoch 73/200\n",
      "11958/11959 [============================>.] - ETA: 0s - loss: 1.0906 - accuracy: 0.3987 ETA: 5s - loss: 1.0906 - accu"
     ]
    }
   ],
   "source": [
    "model_based_MobileNetV2.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# train the head of the network\n",
    "print(\"[INFO] training head...\")\n",
    "H_MobileNetV2 = model_based_MobileNetV2.fit(\n",
    "# rodar sem o aug para ter um baseline e depois avaliar se vale a pena ter o aug\n",
    "    aug.flow(trainX, trainY, batch_size=BS),\n",
    "#     trainX, trainY,\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    validation_data=(testX, testY),\n",
    "    validation_steps=len(testX) // BS,\n",
    "    epochs=EPOCHS)\n",
    "\n",
    "# executed in 3h 22m 7s, finished 01:31:26 2020-09-04  50 epocas 224, 224,3\n",
    "# executed in 5h 28m 54s, finished 20:06:13 2020-09-08 100 epocas 64,64,3\n",
    "\n",
    "\"\"\"\n",
    "opt1 = Adam\n",
    "Epoch 100/100\n",
    "15220/15220 [==============================] \n",
    "- 414s 27ms/sample - loss: 0.0435 \n",
    "- accuracy: 0.9865 \n",
    "- val_loss: 17.6436 \n",
    "- val_accuracy: 0.3173os \n",
    "- ETA: 54s \n",
    "- loss: 0 \n",
    "- ETA: 53s \n",
    "- loss: 0.0453 \n",
    "- ac - ETA: 52s \n",
    "- loss: 0.0452\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Epoch 100/100 - INIT_LR = 1e-8 - 8h 23m\n",
    "- loss: 0.2827 - accuracy: 0.8880 - val_loss: 5.9187 - val_accuracy: 0.2993\n",
    "Epoch 10/10 - INIT_LR = 1e-2\n",
    "loss: 1.0862 - accuracy: 0.3974 - val_loss: 1.1371 - val_accuracy: 0.3003\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-04T17:29:04.040Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset = np.load(bases_prontas_path+'mask_dataset_mobilenet_v2_preprocess_input_64_64_3.npy')\n",
    "dataset = np.load(bases_prontas_path+'mask_dataset_mobilenet_v2_preprocess_input_224_224_3.npy')\n",
    "target = np.load(bases_prontas_path+'mask_dataset_labels.npy')\n",
    "(trainX, testX, trainY, testY) = train_test_split(dataset, target,\n",
    "                                                  test_size=test_size_val, stratify=target, random_state=42)\n",
    "\n",
    "model_based_MobileNetV2_224.compile(loss=\"categorical_crossentropy\", optimizer=opt1,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# train the head of the network\n",
    "print(\"[INFO] training head...\")\n",
    "H_MobileNetV2_224 = model_based_MobileNetV2_224.fit(\n",
    "# rodar sem o aug para ter um baseline e depois avaliar se vale a pena ter o aug\n",
    "    aug.flow(trainX, trainY, batch_size=BS),\n",
    "#     trainX, trainY,\n",
    "    steps_per_epoch=len(trainX2) // BS,\n",
    "    validation_data=(testX2, testY2),\n",
    "    validation_steps=len(testX2) // BS,\n",
    "    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliar os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-04T17:29:04.042Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"[INFO] evaluating network...\")\n",
    "lb = [\"without_mask\",\"mask_weared_incorrect\",\"with_mask\"]\n",
    "def Avaliando_modelo(model, NWHead = None,x_test=testX, y_test=testY):\n",
    "    predIdxs = model.predict(x_test, batch_size=32)\n",
    "\n",
    "    # for each image in the testing set we need to find the index of the\n",
    "    # label with corresponding largest predicted probability\n",
    "    predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "    # show a nicely formatted classification report\n",
    "    print(classification_report(y_test.argmax(axis=1), predIdxs,\n",
    "                                target_names=lb))\n",
    "\n",
    "    # serialize the model to disk\n",
    "    print(\"[INFO] saving mask detector model...\")\n",
    "\n",
    "    if NWHead:\n",
    "        # plot the training loss and accuracy\n",
    "        N = EPOCHS\n",
    "        plt.style.use(\"ggplot\")\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(0, N), NWHead.history[\"loss\"], label=\"train_loss\")\n",
    "        plt.plot(np.arange(0, N), NWHead.history[\"val_loss\"], label=\"val_loss\")\n",
    "        plt.plot(np.arange(0, N), NWHead.history[\"accuracy\"], label=\"train_acc\")\n",
    "        plt.plot(np.arange(0, N), NWHead.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "        plt.title(\"Training Loss and Accuracy\")\n",
    "        plt.xlabel(\"Epoch #\")\n",
    "        plt.ylabel(\"Loss/Accuracy\")\n",
    "        plt.legend(loc=\"lower left\")\n",
    "        plt.show()\n",
    "    return classification_report(y_test.argmax(axis=1), predIdxs,\n",
    "                                target_names=lb,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-04T17:29:04.044Z"
    }
   },
   "outputs": [],
   "source": [
    "Avaliando_modelo(model_based_MobileNetV2, H_MobileNetV2, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-04T17:29:04.047Z"
    }
   },
   "outputs": [],
   "source": [
    "Avaliando_modelo(model_based_MobileNetV2_224, H_MobileNetV2_224, testX,  testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## salvar os pesos dos modelos para n√£o precisar salvar de novo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-04T17:29:04.050Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = os.path.join(\"D:\\\\\",\"FIA\",\"TCC\",\"Meus_Modelos\",\"\")\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-04T17:29:04.051Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/keras/save_and_load\n",
    "# Save the weights\n",
    "model_based_MobileNetV2.save_weights(model_path+'model_based_MobileNetV2_64_checkpoint')\n",
    "model_based_MobileNetV2_224.save_weights(model_path+'model_based_MobileNetV2_224_checkpoint')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
